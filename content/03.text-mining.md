## Building Biomedical Knowledge Graphs

1. Set up the context for relationship extraction
	1. Define the problem
	2. Talk about the importance of the problem (filling knowledge bases -> point researchers to relevant papers)
2. Give overview towards taxonomy of approaches (hand written rules, unsupervised machine learning, supervised machine learning etc.)

### Constructing Databases and Manual Curation

1. Talk about papers that construct knowledge graphs without text mining approaches
2. Discuss the positives and negatives for these methods

### Text Mining for Relationship Extraction

#### Rule-Based Natural Language Processing

1. Mention papers on hand written rules and expressions

#### Unsupervised Machine Learning

Unsupervised machine learning consists of finding hidden patterns within data without labels.
Common methods of unsupervised learning involve clustering, statistical calculations or neural network methods such as autoencoders.
In this section we discuss unsupervised methods used to identify relationship asserting sentences. 

Most unsupervised methods use a form of co-occurrence to detect sentences of interest (Table {@tbl:unsupervised-methods-text-mining}).
Co-occurrence methods exploit a uniform trend that two entities can appear together in text.
Two popular databases DISEASES [@doi:10.1016/j.ymeth.2014.11.020] and STRING [@doi:10.1093/nar/gku1003] were populated using a co-occurrence approach to extract disease-gene associations and protein-protein interactions from PubMed abstracts.
This approach successfully captured a significant amount of associations (high recall), but has a hard time capturing rare associations.
 
Besides PubMed abstracts there was a study that used a similar co-occurrence approach to mine full articles [@doi:10.1371/journal.pcbi.1005962] for protein-protein interactions and other protein related information.
Upon using full articles, the authors discovered that using full text significant improved performance compare to abstracts alone.
This improvement suggests that future text mining approaches should consider using full text to increase overall detection power.

Besides using co-occurence, one study used a clustering algorithm to detect relevant sentences. 
In this study authors generated dependency trees for every sentence contain in a PubMed abstract.
Once generated these dependency trees were clustered into groups using a  biclustering algorithm.
These groups were manually curated to determine the relationship each represented. [@doi:10.1093/bioinformatics/bty114].
This study was able to recall a significant amount of relationships.
Despite the success, the results suffered from technical issues such as parsing errors and under representation of certain dependency paths.
This under representation resulted in a failure to capture rare or under reported relationships.

Overall unsupervised methods provide a means to rapidly find relationship asserting sentneces without the need of annotated text.
From co-occurrence and clustering methods there has been much success in detected important sentences; however, many of these methods suffer in terms of detecting rare or under-reported cases.
Future methods should be able to handle or capture these rare cases.


| Study | Short Description |
| --- | --- |
| [@doi:10.1093/bioinformatics/btz490] | |
| [@doi:10.1109/bibm.2015.7359766] | | 
| [@doi:10.1371/journal.pcbi.1000943] | | 
| [@doi:10.1371/journal.pcbi.1005962]| |
| [@doi:10.1016/j.ymeth.2014.11.020] | |
| [@doi:10.1093/nar/gku1003]| | 
| [@doi:10.1371/journal.pcbi.1005017] | | 

Table: Table of approaches that mainly use a form of co-occurrence. {#tbl:unsupervised-methods-text-mining}

#### Supervised Machine Learning

1. Mention the availablility of publically available data
	1. PPI - 5 datasets 
	   1. 10.1016/j.artmed.2004.07.016 
	   2. 10.1186/1471-2105-8-50 
	   3. Learning language in logic - genic interaction extraction challenge
	   4. 10.1093/bioinformatics/btl616 
	   5. http://helix-web.stanford.edu/psb02/ding.pdf
	2. DaG - 3 datasets
	   1. 10.1016/j.jbi.2012.04.004 
	   2. 10.1186/s12859-015-0472-9
	   3. 10.1186/1471-2105-14-323 
	   4. 10.1186/1471-2105-13-161
	3. CiD 
	  1. 10.1093/database/baw068 
	4. CbG 
	  1. Biocreative VI track 5 - raw citation
	5. more if exists talk about deep learning methods
2. Mention the use of Support Vector Machines and other non deep learning classifiers
   1. Will have to mention that field has moved to deep learning.
   2. 10.1186/s13326-017-0168-3
   3. 10.1371/journal.pcbi.1004630
3. Mention deep learning methods
   1. 1901.06103v1
   2. 10.1016/j.knosys.2018.11.020
   3. 10.1177/0165551516673485
   4. 1706.01556v2
   5. ^^ A few papers here but a lot more will be put into place 
   6. Mention caveat which is the need for large annotated datasets
   7. Mention a direction the field is moving to which is weak supervision and more that info that will come in time.
