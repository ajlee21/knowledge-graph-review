## Building Biomedical Knowledge Graphs

1. Set up the context for relationship extraction
	1. Define the problem
	2. Talk about the importance of the problem (filling knowledge bases -> point researchers to relevant papers)
2. Give overview towards taxonomy of approaches (hand written rules, unsupervised machine learning, supervised machine learning etc.)

### Constructing Databases and Manual Curation

1. Talk about papers that construct knowledge graphs without text mining approaches
2. Discuss the positives and negatives for these methods

### Text Mining for Relationship Extraction

#### Rule-Based Relationship Extraction

Rule-based extraction consists of identifying sentences that contain important keywords or grammatical patterns that allude to relationships of interest. 
These keywords are established via expert knowledge or pre-existing ontologies.
Grammatical patterns are mainly constructed via experts curating part of speech tags or dependency path trees.
Most text mining approaches use the above methods to generate features for machine learning algorithms and are discussed in later sections.
For this section we focus on approaches that mainly use rule based extraction to detect sentences that assert a relationship.

Rules that use grammatical patterns can be used to simplify sentences for easy extraction.
One study used a set of grammar rules to reshape complex sentences with simpler versions.
These simplified versions were manually curated to determine the presence of a relationship.
By simplyfing sentences this approach achieved high recall, but had low precision [@pmid:21346999].
Another approach used similar kind of simplification technique to make extraction easier [@doi:10.1093/database/baw156].
Despite both successes, these kind of approaches rely heavily on manual curation and expert knowledge.
This dependency raises concern for scalability as a lot of english sentences tend to fluctuate in their structure.

Other studies focused on pattern matching to identify sentences.
Some patterns were constructed to match sentences based on their part of speech tags and keywords [@doi:10.1093/nar/gkx462; @doi:10.1186/s12859-018-2103-8; @doi:10.1371/journal.pone.0152725; @doi:10.1093/bioinformatics/btg449; @doi:10.1371/journal.pone.0152725; @doi:10.1186/1471-2105-14-181].
Besides using part of speech tags, some approaches used dependency path trees to construct patterns [@doi:10.1016/j.jbi.2015.08.008; @doi:10.1093/database/bay108].
Dependency path trees are data structures that depict how words modify one another (example shown in Figure {@fig:dependency-parse-tree-example}).
Approaches that used these trees achieved similar detection performance methods that focused on part of speech tags.
Similar to sentence simplification, these methods require a significant amount of manual effort and expert knowledge to work well.
One future direction is to find a way to automate the construction of these hand-crafted patterns.
By automating this process future effort could fix the reoccurring issue of scalability.

![
A visualization of a dependency parse tree using the following sentence as in example: "BRCA1 is associated with breast cancer".
The arrows depict the dependency shared between two words.
For example, the dependency between BRCA1 and associated is nsubjpass.
Nsubjpass stands for passive nominal subject, which means that BRCA1 is the subject that is being referred to by the word associated.
](images/dependency_parse_example.png){#fig:dependency-parse-tree-example}

#### Unsupervised Machine Learning

1. Mention Clustering Analysis
2. Mention Co-Occurrence approaches

#### Supervised Machine Learning

1. Mention the availablility of publically available data
	1. PPI - 5 datasets 
	   1. 10.1016/j.artmed.2004.07.016 
	   2. 10.1186/1471-2105-8-50 
	   3. Learning language in logic - genic interaction extraction challenge
	   4. 10.1093/bioinformatics/btl616 
	   5. http://helix-web.stanford.edu/psb02/ding.pdf
	2. DaG - 3 datasets
	   1. 10.1016/j.jbi.2012.04.004 
	   2. 10.1186/s12859-015-0472-9
	   3. 10.1186/1471-2105-14-323 
	   4. 10.1186/1471-2105-13-161
	3. CiD 
	  1. 10.1093/database/baw068 
	4. CbG 
	  1. Biocreative VI track 5 - raw citation
	5. more if exists talk about deep learning methods
2. Mention the use of Support Vector Machines and other non deep learning classifiers
   1. Will have to mention that field has moved to deep learning.
   2. 10.1186/s13326-017-0168-3
   3. 10.1371/journal.pcbi.1004630
3. Mention deep learning methods
   1. 1901.06103v1
   2. 10.1016/j.knosys.2018.11.020
   3. 10.1177/0165551516673485
   4. 1706.01556v2
   5. ^^ A few papers here but a lot more will be put into place 
   6. Mention caveat which is the need for large annotated datasets
   7. Mention a direction the field is moving to which is weak supervision and more that info that will come in time.
