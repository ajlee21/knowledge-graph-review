## Building Biomedical Knowledge Graphs

1. Set up the context for relationship extraction
	1. Define the problem
	2. Talk about the importance of the problem (filling knowledge bases -> point researchers to relevant papers)
2. Give overview towards taxonomy of approaches (hand written rules, unsupervised machine learning, supervised machine learning etc.)

### Constructing Databases and Manual Curation

1. Talk about papers that construct knowledge graphs without text mining approaches
2. Discuss the positives and negatives for these methods

### Text Mining for Relationship Extraction

#### Rule-Based Relationship Extraction

Rule-based extraction consists of identifying keywords and/or grammatical patterns to detect sentences asserting a relationship.
Keywords are typically crafted via expert knowledge or extensive use of ontologies, while grammatical patterns are mainly created via curating part of speech trees or dependency trees.
Most approaches use these methods to generate features for supervised and unsupervised machine learning algorithms and are discussed in later sections.
In this section we focus on using only rule based extraction to detect relationship asserting sentences.

One way to do rule based extraction is to use grammar rules to simplify sentences. 
One study used a set of context free grammars, a set of rules design to replace complex expression with a simpler vision, to reshape complex sentences with simpler versions.
These simplified versions were manually curated to determine the presence of a relationship.
This approach achieved high recall, but had a low precision score [@pmid:21346999].
Another approach used similar kind of simplification technique to make extraction easier [@doi:10.1093/database/baw156].
Despite the success, these kind of approaches heavily rely on expert knowledge to work.
Furthermore, these approaches do not scale well as the structure of english sentences are highly fluctuating.

Besides sentence simplifications, other studies relied on pattern matching to identify sentences.
These patterns are designed to match part of speech tags and keywords within a sentence [@doi:10.1093/nar/gkx462; @doi:10.1186/s12859-018-2103-8; @doi:10.1371/journal.pone.0152725; @doi:10.1093/bioinformatics/btg449; @doi:10.1371/journal.pone.0152725; @doi:10.1186/1471-2105-14-181].
Besides using part of speech trees, some approaches used dependency trees to construct patterns [@doi:10.1016/j.jbi.2015.08.008; @doi:10.1093/database/bay108].
Dependency tree are data structures that depict how words modify one another (example shown in Figure {@fig:dependency-parse-tree-example}).
Approaches that used these trees has similar detection performance as the other methods that used only part of speech trees.
Just like sentence simplification these methods require a significant amount of manual effort and expert knowledge to work well.
A future direction for these methods is to find a way to automate the construction of these hand crafted patterns.
By automating this process future effort can focus on fixing this issue of scalability.

![
A visualization of a dependency parse tree using the following sentence as in example: "BRCA1 is associated with breast cancer".
The arrows depict the dependency shared between two words.
For example, the dependency between BRCA1 and associated is nsubjpass.
Nsubjpass stands for passive nominal subject, which means that BRCA1 is the subject that is being referred to by the word associated.
](images/dependency_parse_example.png){#fig:dependency-parse-tree-example}

#### Unsupervised Machine Learning

1. Mention Clustering Analysis
2. Mention Co-Occurrence approaches

#### Supervised Machine Learning

1. Mention the availablility of publically available data
	1. PPI - 5 datasets 
	   1. 10.1016/j.artmed.2004.07.016 
	   2. 10.1186/1471-2105-8-50 
	   3. Learning language in logic - genic interaction extraction challenge
	   4. 10.1093/bioinformatics/btl616 
	   5. http://helix-web.stanford.edu/psb02/ding.pdf
	2. DaG - 3 datasets
	   1. 10.1016/j.jbi.2012.04.004 
	   2. 10.1186/s12859-015-0472-9
	   3. 10.1186/1471-2105-14-323 
	   4. 10.1186/1471-2105-13-161
	3. CiD 
	  1. 10.1093/database/baw068 
	4. CbG 
	  1. Biocreative VI track 5 - raw citation
	5. more if exists talk about deep learning methods
2. Mention the use of Support Vector Machines and other non deep learning classifiers
   1. Will have to mention that field has moved to deep learning.
   2. 10.1186/s13326-017-0168-3
   3. 10.1371/journal.pcbi.1004630
3. Mention deep learning methods
   1. 1901.06103v1
   2. 10.1016/j.knosys.2018.11.020
   3. 10.1177/0165551516673485
   4. 1706.01556v2
   5. ^^ A few papers here but a lot more will be put into place 
   6. Mention caveat which is the need for large annotated datasets
   7. Mention a direction the field is moving to which is weak supervision and more that info that will come in time.
