## Building Biomedical Knowledge Graphs

Constructing a knowledge graph involves the process of using databases as reference points to establish entities (nodes) and the relationships between them (edges).
These databases are constructed and populated by a simple workflow.
This workflow is described below:
(1) Gather relevant text such as journal articles, abstracts, or web-based text.
(2) Undergo named entity recognition, which is the process of identifing and normalizing keywords that represent entities of interest.
Typically, these keywords are identified using a dictionary look-up approach[@doi:10.1093/database/bas037] or machine learning systems [@doi:10.1093/bioinformatics/btw343; @doi:10.1142/9789812776136_0062; @doi:10.1186/1471-2105-12-S8-S5].
(3) Perform relationship extraction, which is the process of detect sentences that assert a relationship of interest.
This step involves the use of manual effort, automated approaches or a combination of both.
(4) Synthesize identified sentences as evidence for establishing a relationship between mentioned entites of interest. 

In this section we discuss examples of each type of approach mentioned in step three and synthesize the strengths and weaknesses of each.
We categorize automated approaches into the following groups: rule-based extraction, unsupervised machine learning, and supervised machine learning.

### Populating Databases via Manual Curation

1. Talk about papers that construct knowledge graphs without text mining approaches
2. Discuss the positives and negatives for these methods

### Text Mining for Relationship Extraction

#### Rule-Based Natural Language Processing

1. Mention papers on hand written rules and expressions

#### Unsupervised Machine Learning

1. Mention Clustering Analysis
2. Mention Co-Occurrence approaches

#### Supervised Machine Learning

1. Mention the availablility of publically available data
	1. PPI - 5 datasets 
	   1. 10.1016/j.artmed.2004.07.016 
	   2. 10.1186/1471-2105-8-50 
	   3. Learning language in logic - genic interaction extraction challenge
	   4. 10.1093/bioinformatics/btl616 
	   5. http://helix-web.stanford.edu/psb02/ding.pdf
	2. DaG - 3 datasets
	   1. 10.1016/j.jbi.2012.04.004 
	   2. 10.1186/s12859-015-0472-9
	   3. 10.1186/1471-2105-14-323 
	   4. 10.1186/1471-2105-13-161
	3. CiD 
	  1. 10.1093/database/baw068 
	4. CbG 
	  1. Biocreative VI track 5 - raw citation
	5. more if exists talk about deep learning methods
2. Mention the use of Support Vector Machines and other non deep learning classifiers
   1. Will have to mention that field has moved to deep learning.
   2. 10.1186/s13326-017-0168-3
   3. 10.1371/journal.pcbi.1004630
3. Mention deep learning methods
   1. 1901.06103v1
   2. 10.1016/j.knosys.2018.11.020
   3. 10.1177/0165551516673485
   4. 1706.01556v2
   5. ^^ A few papers here but a lot more will be put into place 
   6. Mention caveat which is the need for large annotated datasets
   7. Mention a direction the field is moving to which is weak supervision and more that info that will come in time.
