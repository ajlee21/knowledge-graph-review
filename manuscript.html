<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="David Nicholson" />
  <meta name="author" content="Casey S. Greene" />
  <meta name="dcterms.date" content="2020-02-28" />
  <meta name="keywords" content="knowledge-graphs, network-embeddings, text-mining, natural-language-processing, deep-learning, machine-learning, literature-review" />
  <title>Constructing Knowledge Graphs and Their Biomedical Applications</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Constructing Knowledge Graphs and Their Biomedical Applications</h1>
</header>
<p><small><em> This manuscript (<a href="https://greenelab.github.io/knowledge-graph-review/v/df161ec7ff36387655082fd45b81e9422e89f327/">permalink</a>) was automatically generated from <a href="https://github.com/greenelab/knowledge-graph-review/tree/df161ec7ff36387655082fd45b81e9422e89f327">greenelab/knowledge-graph-review@df161ec</a> on February 28, 2020. </em></small></p>
<h2 id="authors">Authors</h2>
<ul>
<li><p><strong>David Nicholson</strong><br> <img src="images/orcid.svg" alt="ORCID icon" class="inline_icon" /> <a href="https://orcid.org/0000-0003-0002-5761">0000-0003-0002-5761</a> · <img src="images/github.svg" alt="GitHub icon" class="inline_icon" /> <a href="https://github.com/danich1">danich1</a><br> <small> Department of Systems Pharmacology and Translational Therapeutics, University of Pennsylvania · Funded by GBMF4552 and T32 HG000046 </small></p></li>
<li><p><strong>Casey S. Greene</strong><br> <img src="images/orcid.svg" alt="ORCID icon" class="inline_icon" /> <a href="https://orcid.org/0000-0001-8713-9213">0000-0001-8713-9213</a> · <img src="images/github.svg" alt="GitHub icon" class="inline_icon" /> <a href="https://github.com/cgreene">cgreene</a> · <img src="images/twitter.svg" alt="Twitter icon" class="inline_icon" /> <a href="https://twitter.com/greenescientist">greenescientist</a><br> <small> Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania; Childhood Cancer Data Lab, Alex’s Lemonade Stand Foundation </small></p></li>
</ul>
<h2 id="abstract" class="page_break_before">Abstract</h2>
<p>Knowledge graphs can support many biomedical applications. These graphs represent biomedical concepts and relationships in the form of nodes and edges. In this review we discuss how these graphs are constructed and applied with a particular focus on the ways machine learning approaches are changing these processes. In many examples in the literature, biomedical knowledge graphs have been constructed from pre-existing databases that are populated by experts via manual curation, but we are now also seeing a more robust use of automatic systems. A number of techniques are used to represent knowledge graphs, but often machine learning methods are used to learn a low-dimensional representation that can support many different applications. This representation is designed to preserve a knowledge graph’s local and/or global structure. Additional machine learning methods can be applied to this representation to make predictions within genomic, pharmaceutical, and clinical domains. We frame our discussion first around knowledge graph construction then around unifying techniques and unifying applications separately. Advances in machine learning for biomedicine are creating new opportunities across many domains, and we note potential avenues for future work with knowledge graphs that appear particularly fruitful.</p>
<h2 id="introduction">Introduction</h2>
<p>Knowledge graphs are a practical resource for many real world applications. They have been used in social media mining to classify nodes <span class="citation" data-cites="DjhSdWbc">[<a href="#ref-DjhSdWbc" role="doc-biblioref">1</a>]</span> and create recommendation systems <span class="citation" data-cites="Eqbsazq5">[<a href="#ref-Eqbsazq5" role="doc-biblioref">2</a>]</span>. These graphs have also been used in natural language processing to interpret simple questions and use relational information to provide answers <span class="citation" data-cites="N0gUhlt9 s8ydThMc">[<a href="#ref-N0gUhlt9" role="doc-biblioref">3</a>,<a href="#ref-s8ydThMc" role="doc-biblioref">4</a>]</span>. In a biomedical setting these graphs have been used to prioritize genes relevant to disease <span class="citation" data-cites="GI2y7kMc Oi5yRd0v 15k4Xz0i3 1D9FTzRBg">[<a href="#ref-GI2y7kMc" role="doc-biblioref">5</a>,<a href="#ref-Oi5yRd0v" role="doc-biblioref">6</a>,<a href="#ref-15k4Xz0i3" role="doc-biblioref">7</a>,<a href="#ref-1D9FTzRBg" role="doc-biblioref">8</a>]</span>, perform drug repurposing <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">9</a>]</span> and identify drug-target interactions <span class="citation" data-cites="15GxqZyO8">[<a href="#ref-15GxqZyO8" role="doc-biblioref">10</a>]</span>.</p>
<p>Despite their utility, precisely defining a knowledge graph is a difficult task because there are multiple conflicting definitions <span class="citation" data-cites="V9M93in">[<a href="#ref-V9M93in" role="doc-biblioref">11</a>]</span>. For this review, we define a knowledge graph as the following: a resource that integrates single or multiple sources of information into the form of a graph. This graph allows for the capacity to make semantic interpretation, continuously incorporate new information and uncover novel hidden knowledge through computational techniques and algorithms. Based on this definition resources like Hetionet <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">9</a>]</span> would be considered a knowledge graph as Hetionet integrates multiple sources of information into the form of a graph (example shown in Figure <a href="#fig:hetionet_schema">1</a>). Hetionet was used to derive novel information concerning unique drug treatments <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">9</a>]</span>. We do not consider databases like DISEASES <span class="citation" data-cites="5gG8hwv7">[<a href="#ref-5gG8hwv7" role="doc-biblioref">12</a>]</span> and DrugBank <span class="citation" data-cites="1FI8iuYiQ">[<a href="#ref-1FI8iuYiQ" role="doc-biblioref">13</a>]</span> to be knowledge graphs. Although these resources contain essential information, they do not represent their data in the form of a graph.</p>
<p>Knowledge graphs are often constructed from manually curated databases <span class="citation" data-cites="O21tn8vf kBHNhSma tIGJl1ES BTEcMH0X">[<a href="#ref-O21tn8vf" role="doc-biblioref">9</a>,<a href="#ref-kBHNhSma" role="doc-biblioref">14</a>,<a href="#ref-tIGJl1ES" role="doc-biblioref">15</a>,<a href="#ref-BTEcMH0X" role="doc-biblioref">16</a>]</span>. These databases provide previously established information that can be incorporated into a graph. For example, a graph using DISEASES <span class="citation" data-cites="5gG8hwv7">[<a href="#ref-5gG8hwv7" role="doc-biblioref">12</a>]</span> as a resource would have genes and diseases as nodes, while edges added between nodes would represent an association between a gene and a disease. This example shows a single type of relationship; however, there are graphs that use databases with multiple relationships <span class="citation" data-cites="6Vifn4pu O21tn8vf">[<a href="#ref-6Vifn4pu" role="doc-biblioref">17</a>,<a href="#ref-O21tn8vf" role="doc-biblioref">9</a>]</span>. In addition to manual curation other approaches have used natural language processing techniques to construct knowledge graphs <span class="citation" data-cites="gddb9uXr rxaBUglG">[<a href="#ref-gddb9uXr" role="doc-biblioref">18</a>,<a href="#ref-rxaBUglG" role="doc-biblioref">19</a>]</span>. One example used a text mining system to extract sentences that illustrate a protein interacts with another protein <span class="citation" data-cites="ibJfUvEe">[<a href="#ref-ibJfUvEe" role="doc-biblioref">20</a>]</span>. Once identified, these sentences can be incorporated as evidence to establish an edge in a knowledge graph.</p>
<p>In this review we describe various approaches for constructing and applying knowledge graphs in a biomedical setting. We discuss the pros and cons of constructing a knowledge graph via manually curated databases and via text mining systems. We also compare assorted approaches for applying knowledge graphs to solve biomedical problems. Lastly, we conclude on the practicality of knowledge graphs and point out future applications that have yet to be explored.</p>
<figure>
<img src="https://raw.githubusercontent.com/dhimmel/rephetio/f02d44fde7eeef0ffdca0800e0b43c48d800c86d/figure/metagraph.png" alt="Figure 1: A metagraph (schema) of the heterogeneous network used in the Rephetio project [9]. This undirected network depicts pharmacological and biomedical information. The nodes (circles) represent entities and edges (lines) depict relational information between two entities." id="fig:hetionet_schema" /><figcaption><span>Figure 1:</span> A metagraph (schema) of the heterogeneous network used in the Rephetio project <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">9</a>]</span>. This undirected network depicts pharmacological and biomedical information. The nodes (circles) represent entities and edges (lines) depict relational information between two entities.</figcaption>
</figure>
<h2 id="building-biomedical-knowledge-graphs">Building Biomedical Knowledge Graphs</h2>
<p>Knowledge graphs can be constructed in many ways using resources such as pre-exisitng databases or text. Usually, knowledge graphs are constructed using pre-existing databases and these databases are constructed by domain experts using approaches ranging from manual curation to automated techniques, such as text mining. Manual curation is a time consuming process that requires domain experts to read papers and annotate sentences that assert a relationship. Automated approaches rely on machine learning or natural language processing techniques to rapidly detect sentences of interest. We categorize these automated approaches into the following groups: rule-based extraction, unsupervised machine learning, and supervised machine learning and discuss examples of each type of approach while synthesizing their strengths and weaknesses.</p>
<h3 id="constructing-databases-and-manual-curation">Constructing Databases and Manual Curation</h3>
<p>Database construction can date back all the way to 1956 where the first database contained a protein sequence of the insulin molecule <span class="citation" data-cites="GjM2NbnC">[<a href="#ref-GjM2NbnC" role="doc-biblioref">21</a>]</span>. This process involves gathering relevant text such as journal articles, abstracts, or web-based text and having curators read the gathered text to detect sentences that implicate a relationship (i.e. relationship extraction). Notable databases constructed by this process can be in found in Table <a href="#tbl:manual-curated-databases">1</a>. An example database, COSMIC <span class="citation" data-cites="pfquADl5">[<a href="#ref-pfquADl5" role="doc-biblioref">22</a>]</span> was constructed via a group of domain experts scanning the literature for key cancer related genes. This database contained approximately 35M entries in 2016 <span class="citation" data-cites="pfquADl5">[<a href="#ref-pfquADl5" role="doc-biblioref">22</a>]</span> and by 2019 had grown to 45M entries <span class="citation" data-cites="1E72FZcIm">[<a href="#ref-1E72FZcIm" role="doc-biblioref">23</a>]</span>. Studies have shown that databases constructed in this fashion contain relatively precise data, but in low quantifies <span class="citation" data-cites="5TLcy6Yl 1BnoByjXH OELNNm08 yjdNa04s d3rG3TXb 16P0HRKom UdzvLgBM">[<a href="#ref-5TLcy6Yl" role="doc-biblioref">24</a>,<a href="#ref-1BnoByjXH" role="doc-biblioref">25</a>,<a href="#ref-OELNNm08" role="doc-biblioref">26</a>,<a href="#ref-yjdNa04s" role="doc-biblioref">27</a>,<a href="#ref-d3rG3TXb" role="doc-biblioref">28</a>,<a href="#ref-16P0HRKom" role="doc-biblioref">29</a>,<a href="#ref-UdzvLgBM" role="doc-biblioref">30</a>]</span>. This happens because the publication rate is too high for curators to keep up <span class="citation" data-cites="vYYWSlK2">[<a href="#ref-vYYWSlK2" role="doc-biblioref">31</a>]</span>. This bottleneck highlights a critical need for future approaches to scale fast enough to compete with the increasing publication rate.</p>
<p>Semi-automatic methods are a way to accelerate the curation process <span class="citation" data-cites="17LLVYRDg iJxqfYog us6gXxVp kHKmKy23 17KVV4Pum d3rG3TXb SHPz84Z7">[<a href="#ref-d3rG3TXb" role="doc-biblioref">28</a>,<a href="#ref-17LLVYRDg" role="doc-biblioref">32</a>,<a href="#ref-iJxqfYog" role="doc-biblioref">33</a>,<a href="#ref-us6gXxVp" role="doc-biblioref">34</a>,<a href="#ref-kHKmKy23" role="doc-biblioref">35</a>,<a href="#ref-17KVV4Pum" role="doc-biblioref">36</a>,<a href="#ref-SHPz84Z7" role="doc-biblioref">37</a>]</span>. The first step of these methods is to use an automated system to initially extract sentences from text. This process removes irrelevant sentences, which dramatically decreases the amount of text that curators must sift through. Following the pre-filtering step, curators then approve or reject the remaining sentences. This approach saved curators an average of 2-2.8 hours compared to manual efforts <span class="citation" data-cites="17LLVYRDg KX7N360G">[<a href="#ref-17LLVYRDg" role="doc-biblioref">32</a>,<a href="#ref-KX7N360G" role="doc-biblioref">38</a>]</span>. Despite automated systems excelling in identifying sentences for commonly occurring relationships, they tend to miss lessor known relationships <span class="citation" data-cites="17LLVYRDg">[<a href="#ref-17LLVYRDg" role="doc-biblioref">32</a>]</span>. These systems also have a hard time parsing ambiguous sentences that naturally occur in text, which makes correcting them a challenging task <span class="citation" data-cites="17LLVYRDg">[<a href="#ref-17LLVYRDg" role="doc-biblioref">32</a>]</span>. Given these caveats, future approaches should look into using techniques that simplify sentences to solve the ambiguity issue <span class="citation" data-cites="umenx8Nh aJL1tPyy">[<a href="#ref-umenx8Nh" role="doc-biblioref">39</a>,<a href="#ref-aJL1tPyy" role="doc-biblioref">40</a>]</span>.</p>
<p>Despite the negatives of manual curation, it is still an essential process for extracting relationships from text. This process can be used to generate gold standard datasets that automated systems use for validation <span class="citation" data-cites="Y2DcwTrA YWh6tPj">[<a href="#ref-Y2DcwTrA" role="doc-biblioref">41</a>,<a href="#ref-YWh6tPj" role="doc-biblioref">42</a>]</span> and can be used during the training process of these systems (i.e. active learning) <span class="citation" data-cites="MTIt6gSA">[<a href="#ref-MTIt6gSA" role="doc-biblioref">43</a>]</span>. It is important to remember that manual curation alone is precise, but results in low recall rates <span class="citation" data-cites="UdzvLgBM">[<a href="#ref-UdzvLgBM" role="doc-biblioref">30</a>]</span>. Future databases should consider initially relying on automated methods to obtain sentences at an acceptable recall level, then incorporate manual curation as a way to fix or remove irrelevant results.</p>
<a name="tbl:manual-curated-databases"></a>
<table style="width:100%;">
<caption><span>Table 1:</span> A table of databases that used a form of manual curation to populate entries. Reported number of entities and relationships are relative to time of publication. </caption>
<colgroup>
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="header">
<th>Database [Reference]</th>
<th>Short Description</th>
<th>Number of Entries</th>
<th>Entity Types</th>
<th>Relationship Types</th>
<th>Method of Population</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Entrez-Gene <span class="citation" data-cites="u7vVtngU">[<a href="#ref-u7vVtngU" role="doc-biblioref">44</a>]</span></td>
<td>NCBI’s Gene annotation database that contains information pertaining to genes, gene’s organism source, phenotypes etc.</td>
<td>7,883,114</td>
<td>Genes, Species and Phenotypes</td>
<td>Gene-Phenotypes and Genes-Species mappings</td>
<td>Semi-automated curation</td>
</tr>
<tr class="even">
<td>UniProt <span class="citation" data-cites="1ZE22clL">[<a href="#ref-1ZE22clL" role="doc-biblioref">45</a>]</span></td>
<td>A protein protein interaction database that contains proteomic information.</td>
<td>560,823</td>
<td>Proteins, Protein sequences</td>
<td>Protein-Protein interactions</td>
<td>Manual and Automated Curation</td>
</tr>
<tr class="odd">
<td>PharmGKB <span class="citation" data-cites="qbo1ouMs">[<a href="#ref-qbo1ouMs" role="doc-biblioref">46</a>]</span></td>
<td>A database that contains genetic, phenotypic, and clinical information related to pharmacogenomic studies.</td>
<td>43,112</td>
<td>Drugs, Genes, Phenotypes, Variants, Pathways</td>
<td>Gene-Phenotypes, Pathway-Drugs, Gene-Variants, Gene-Pathways</td>
<td>Manual Curation and Automated Methods</td>
</tr>
<tr class="even">
<td>COSMIC <span class="citation" data-cites="pfquADl5">[<a href="#ref-pfquADl5" role="doc-biblioref">22</a>]</span></td>
<td>A database that contains high resolution human cancer genetic information.</td>
<td>35,946,704</td>
<td>Genes, Variants, Tumor Types</td>
<td>Gene-Variant Mappings</td>
<td>Manual Curation</td>
</tr>
<tr class="odd">
<td>BioGrid <span class="citation" data-cites="kFAyvOpe">[<a href="#ref-kFAyvOpe" role="doc-biblioref">47</a>]</span></td>
<td>A database for major model organisms. It contains genetic and proteomic information.</td>
<td>572,084</td>
<td>Genes, Proteins</td>
<td>Protein-Protein interactions</td>
<td>Semi-automatic methods</td>
</tr>
<tr class="even">
<td>Comparative Toxicogenomics Database <span class="citation" data-cites="axd6eJec">[<a href="#ref-axd6eJec" role="doc-biblioref">48</a>]</span></td>
<td>A database that contains manually curated chemical-gene-disease interactions and relationships.</td>
<td>2,429,689</td>
<td>Chemicals (Drugs), Genes, Diseases</td>
<td>Drug-Genes, Drug-Disease, Disease-Gene mappings</td>
<td>Manual curation and Automated systems</td>
</tr>
<tr class="odd">
<td>Comprehensive Antibiotic Resistance Database <span class="citation" data-cites="1ByMfX8Y1">[<a href="#ref-1ByMfX8Y1" role="doc-biblioref">49</a>]</span></td>
<td>Manually curated database that contains information about the molecular basis of antimicrobial resistance.</td>
<td>174,443</td>
<td>Drugs, Genes, Variants</td>
<td>Drug-Gene, Drug-Variant mappings</td>
<td>Manual curation</td>
</tr>
<tr class="even">
<td>OMIM <span class="citation" data-cites="1FZWpEoss">[<a href="#ref-1FZWpEoss" role="doc-biblioref">50</a>]</span></td>
<td>A database that contains phenotype and genotype information</td>
<td>25,153</td>
<td>Genes, Phenotypes</td>
<td>Gene-Phenotype mappings</td>
<td>Manual Curation</td>
</tr>
</tbody>
</table>
<h3 id="text-mining-for-relationship-extraction">Text Mining for Relationship Extraction</h3>
<h4 id="rule-based-relationship-extraction">Rule-Based Relationship Extraction</h4>
<p>Rule based-extraction consists of identifying essential keywords and grammatical patterns to detect relationships of interest. Keywords are established via expert knowledge or though the use of pre-existing ontologies, while grammatical patterns are constructed via experts curating parse trees. Parse trees are tree data structures that depict a sentence’s grammatical structure and come into two forms: a constituency parse tree (Figure <a href="#fig:constituency-parse-tree-example">2</a>) and a dependency parse tree (Figure <a href="#fig:dependency-parse-tree-example">3</a>). Both trees use part of speech tags, labels that dictate the grammatical role of a word such as noun, verb, adjective, etc, for construction, but represent the information in two different forms. Constituency parse trees breaks a sentence down into a subphrases (Figure <a href="#fig:constituency-parse-tree-example">2</a>) while dependency path trees analyzes the grammatical structure of a sentence (Figure <a href="#fig:dependency-parse-tree-example">3</a>). Many text mining approaches <span class="citation" data-cites="i7KpvzCo 3j1T67vB iiQkIqUX">[<a href="#ref-i7KpvzCo" role="doc-biblioref">51</a>,<a href="#ref-3j1T67vB" role="doc-biblioref">52</a>,<a href="#ref-iiQkIqUX" role="doc-biblioref">53</a>]</span> use such trees to generate features for machine learning algorithms and these approaches are discussed in later sections. In this section we focus on approaches that use rule based extraction as a primary strategy to detect sentences that allude to a relationship.</p>
<p>Grammatical patterns can simplify sentences for easy extraction <span class="citation" data-cites="aJL1tPyy 66vfJAIo">[<a href="#ref-aJL1tPyy" role="doc-biblioref">40</a>,<a href="#ref-66vfJAIo" role="doc-biblioref">54</a>]</span>. Jonnalagadda et al. used a set of grammar rules inspired by constituency trees to reshape complex sentences with simpler versions <span class="citation" data-cites="aJL1tPyy">[<a href="#ref-aJL1tPyy" role="doc-biblioref">40</a>]</span> and these simplified versions were manually curated to determine the presence of a relationship. By simplifying sentences this approach achieved high recall, but had low precision <span class="citation" data-cites="aJL1tPyy">[<a href="#ref-aJL1tPyy" role="doc-biblioref">40</a>]</span>. Other approach used simplification techniques to make extraction easier <span class="citation" data-cites="15I4QE3J 7PCrlbDi J0VF6x1n 1HnOwZ1Xq">[<a href="#ref-15I4QE3J" role="doc-biblioref">55</a>,<a href="#ref-7PCrlbDi" role="doc-biblioref">56</a>,<a href="#ref-J0VF6x1n" role="doc-biblioref">57</a>,<a href="#ref-1HnOwZ1Xq" role="doc-biblioref">58</a>]</span>. Tudor et al., simplified sentences to detect protein phosphorylation events <span class="citation" data-cites="J0VF6x1n">[<a href="#ref-J0VF6x1n" role="doc-biblioref">57</a>]</span>. Their sentence simplifier broke complex sentences that contain multiple protein events into smaller sentences that contain only one distinct event. By breaking these sentences down the authors were able to increase their recall; however, sentences that contained ambiguous directionality or multiple phosphorylation events were too complex for the simplifier. As a consequence the simplifier missed some relevant sentences <span class="citation" data-cites="J0VF6x1n">[<a href="#ref-J0VF6x1n" role="doc-biblioref">57</a>]</span>. These errors highlight a crucial need for future algorithms to be generalizable enough to handle various forms of complex sentences.</p>
<p>Pattern matching is a fundamental approach used to detect relationship asserting sentences. These patterns can consist of phrases from constituency trees, a set of keywords or some combination of both <span class="citation" data-cites="OnvaFHG9 d3rG3TXb dRQuIwpJ 23i6gRBE 1avvFjJ9 KEkjqdB0">[<a href="#ref-d3rG3TXb" role="doc-biblioref">28</a>,<a href="#ref-OnvaFHG9" role="doc-biblioref">59</a>,<a href="#ref-dRQuIwpJ" role="doc-biblioref">60</a>,<a href="#ref-23i6gRBE" role="doc-biblioref">61</a>,<a href="#ref-1avvFjJ9" role="doc-biblioref">62</a>,<a href="#ref-KEkjqdB0" role="doc-biblioref">63</a>]</span>. Xu et al., designed a pattern matcher system to detect sentences in PubMed abstracts that indicate drug-disease treatments <span class="citation" data-cites="1avvFjJ9">[<a href="#ref-1avvFjJ9" role="doc-biblioref">62</a>]</span>. This system matched drug-disease pairs from ClinicalTrials.gov to drug-disease pairs mentioned in abstracts. This matching process aided the authors in identifying sentences that can be used to create simple patterns, such as “Drug in the treatment of Disease” <span class="citation" data-cites="1avvFjJ9">[<a href="#ref-1avvFjJ9" role="doc-biblioref">62</a>]</span>, to match other sentences in a wide variety of abstracts. The authors hand curated two datasets for evaluation and achieved a high precision score of 0.904 and a low recall score of 0.131 <span class="citation" data-cites="1avvFjJ9">[<a href="#ref-1avvFjJ9" role="doc-biblioref">62</a>]</span>. This low recall score was based on constructed patterns being too specific to detect infrequent drug pairs. Besides constituency trees, some approaches used dependency trees to construct patterns <span class="citation" data-cites="jg0TGCov i7KpvzCo">[<a href="#ref-i7KpvzCo" role="doc-biblioref">51</a>,<a href="#ref-jg0TGCov" role="doc-biblioref">64</a>]</span>. Depending upon the nature of the algorithm and text, dependency trees could be more appropriate than constituency trees and vise versa. The performance difference between the two trees remains as an open question for future exploration.</p>
<p>Rules based methods provide a basis for many relationship extraction systems. Approaches in this category range from simplifying sentences for easy extraction to identifying sentences based on matched key phrases or grammatical patterns. Both require a significant amount of manual effort and expert knowledge to perform well. A future direction is to develop ways to automatically construct these hand-crafted patterns, which would accelerate the process of creating these rule-based systems.</p>
<figure>
<img src="images/figures/constituency_parse_tree_example.png" alt="Figure 2: A visualization of a constituency parse tree using the following sentence: “BRCA1 is associated with breast cancer” [65]. This type of tree has the root start at the beginning of the sentence. Each word is grouped into subphrases depending its correlating part of speech tag. For example, the word “associated” is a past participle verb (VBN) that belongs to the verb phrase (VP) subgroup." id="fig:constituency-parse-tree-example" /><figcaption><span>Figure 2:</span> A visualization of a constituency parse tree using the following sentence: “BRCA1 is associated with breast cancer” <span class="citation" data-cites="1EvoylLWK">[<a href="#ref-1EvoylLWK" role="doc-biblioref">65</a>]</span>. This type of tree has the root start at the beginning of the sentence. Each word is grouped into subphrases depending its correlating part of speech tag. For example, the word “associated” is a past participle verb (VBN) that belongs to the verb phrase (VP) subgroup.</figcaption>
</figure>
<figure>
<img src="images/figures/dependency_parse_example.png" alt="Figure 3: A visualization of a dependency parse tree using the following sentence: “BRCA1 is associated with breast cancer” [66]. For these type of trees the root begins with the main verb of the sentence. Each arrows represents the dependency shared between two words. For example, the dependency between BRCA1 and associated is nsubjpass, which stands for passive nominal subject. This means that “BRCA1” is the subject of the sentence and it is being referred to by the word “associated”." id="fig:dependency-parse-tree-example" /><figcaption><span>Figure 3:</span> A visualization of a dependency parse tree using the following sentence: “BRCA1 is associated with breast cancer” <span class="citation" data-cites="10i1qMFbL">[<a href="#ref-10i1qMFbL" role="doc-biblioref">66</a>]</span>. For these type of trees the root begins with the main verb of the sentence. Each arrows represents the dependency shared between two words. For example, the dependency between BRCA1 and associated is nsubjpass, which stands for passive nominal subject. This means that “BRCA1” is the subject of the sentence and it is being referred to by the word “associated”.</figcaption>
</figure>
<h4 id="extracting-relationships-without-labels">Extracting Relationships Without Labels</h4>
<p>Unsupervised methods of extraction involve drawing inferences from data without the use of labels. These methods involve some form of clustering or statistical calculations. In this section we discuss methods that use unsupervised learning to detect relationship asserting sentences from text.</p>
<p>An unsupervised method to extract relationships exploits the fact that two entities can appear together in text. This kind of event is called co-occurrence and studies that use this phenomenon can be found in table <a href="#tbl:unsupervised-methods-text-mining">2</a>. Two databases DISEASES <span class="citation" data-cites="5gG8hwv7">[<a href="#ref-5gG8hwv7" role="doc-biblioref">12</a>]</span> and STRING <span class="citation" data-cites="iihNCsNX">[<a href="#ref-iihNCsNX" role="doc-biblioref">67</a>]</span> were populated using a co-occurrence scoring method on PubMed abstracts. Both databases used the same scoring method that measured the frequency of co-mention pairs within individual sentences as well as the abstracts themselves. This method assumes independence between each individual occurrence. Under this assumption mention pairs that occur more than expected were presumed to indicate the presence of an association or interaction. This approach was able to identify 543,405 disease gene associations <span class="citation" data-cites="5gG8hwv7">[<a href="#ref-5gG8hwv7" role="doc-biblioref">12</a>]</span> and 792,730 high confidence protein protein interactions <span class="citation" data-cites="iihNCsNX">[<a href="#ref-iihNCsNX" role="doc-biblioref">67</a>]</span>, but is limited to only using PubMed abstracts.</p>
<p>Full text articles are able to drastically amplify text mining power to detect relationships <span class="citation" data-cites="DGlWGDEt pLAIFXqP">[<a href="#ref-DGlWGDEt" role="doc-biblioref">68</a>,<a href="#ref-pLAIFXqP" role="doc-biblioref">69</a>]</span>. Westergaard et al. used a co-occurrence approach, similar to DISEASES <span class="citation" data-cites="5gG8hwv7">[<a href="#ref-5gG8hwv7" role="doc-biblioref">12</a>]</span> and STRING <span class="citation" data-cites="iihNCsNX">[<a href="#ref-iihNCsNX" role="doc-biblioref">67</a>]</span>, to mine full articles for protein-protein interactions and other protein related information <span class="citation" data-cites="DGlWGDEt">[<a href="#ref-DGlWGDEt" role="doc-biblioref">68</a>]</span>. The authors discovered that full text provided better prediction power than using abstracts alone. This improvement suggests that future text mining approaches should consider using full text to increase detection power.</p>
<p>Unsupervised methods have been focused on treating multiple biomedical relationships as multiple isolated problems. These methods repeatedly use the same model for each biomedical relationship type. An alternative to this persepctive is to capture all different relationship types at once. Clustering is an approach that accomplish this concept of simultaneous extraction. Percha et al. used a biclustering algorithm on generated dependency parse trees to group PubMed abstract sentences <span class="citation" data-cites="CSiMoOrI">[<a href="#ref-CSiMoOrI" role="doc-biblioref">70</a>]</span>. Each cluster was manually curated to determine which relationship they represented. This approach captured 4,451,661 dependency paths for 36 different groups <span class="citation" data-cites="CSiMoOrI">[<a href="#ref-CSiMoOrI" role="doc-biblioref">70</a>]</span>. Despite the success, this approach suffered from technical issues such as dependency tree parsing errors. This type of error resulted in sentences not being grouped by the clustering algorithm <span class="citation" data-cites="CSiMoOrI">[<a href="#ref-CSiMoOrI" role="doc-biblioref">70</a>]</span>. Future clustering approaches should consider simplifying sentences to prevent this type of issue.</p>
<p>Overall unsupervised methods provide a means to rapidly find relationship asserting sentences without the need of annotated text. Approaches in this category range from using co-occurrence scores to clustering sentences. These methods provide a generalizable framework that can be used on large repositories of text. Future methods can improve detection power by considering the use of methods that simplify sentences and use datasets that include full text articles.</p>
<a name="tbl:unsupervised-methods-text-mining"></a>
<table>
<caption><span>Table 2:</span> Table of approaches that mainly use a form of co-occurrence. </caption>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>Study</th>
<th>Relationship of Interest</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>CoCoScore <span class="citation" data-cites="IGXdryzB">[<a href="#ref-IGXdryzB" role="doc-biblioref">71</a>]</span></td>
<td>Protein-Protein Interactions, Disease-Gene and Tissue-Gene Associations</td>
</tr>
<tr class="even">
<td>Rastegar-Mojarad et al. <span class="citation" data-cites="ETC6lm7S">[<a href="#ref-ETC6lm7S" role="doc-biblioref">72</a>]</span></td>
<td>Drug Disease Treatments</td>
</tr>
<tr class="odd">
<td>CoPub Discovery <span class="citation" data-cites="AdKPf5EO">[<a href="#ref-AdKPf5EO" role="doc-biblioref">73</a>]</span></td>
<td>Drug, Gene and Disease interactions</td>
</tr>
<tr class="even">
<td>Westergaard et al. <span class="citation" data-cites="DGlWGDEt">[<a href="#ref-DGlWGDEt" role="doc-biblioref">68</a>]</span></td>
<td>Protein-Protein Interactions</td>
</tr>
<tr class="odd">
<td>DISEASES <span class="citation" data-cites="5gG8hwv7">[<a href="#ref-5gG8hwv7" role="doc-biblioref">12</a>]</span></td>
<td>Disease-Gene associations</td>
</tr>
<tr class="even">
<td>STRING <span class="citation" data-cites="q9Fhy8eq">[<a href="#ref-q9Fhy8eq" role="doc-biblioref">74</a>]</span></td>
<td>Protein-Protein Interactions</td>
</tr>
<tr class="odd">
<td>Singhal et al. <span class="citation" data-cites="10tWTMIaV">[<a href="#ref-10tWTMIaV" role="doc-biblioref">75</a>]</span></td>
<td>Genotype-Phenotype Relationships</td>
</tr>
</tbody>
</table>
<h4 id="supervised-relationship-extraction">Supervised Relationship Extraction</h4>
<p>Supervised extraction uses labeled relationships to learn text patterns that correspond to positively labeled relationships instead of negative ones. Most of these approaches have flourished due to pre-labelled publicly available datasets (Table <a href="#tbl:supervised-text-datasets">3</a>). These datasets were constructed by curators for shared open tasks <span class="citation" data-cites="16As8893j 6wNuLZWb">[<a href="#ref-16As8893j" role="doc-biblioref">76</a>,<a href="#ref-6wNuLZWb" role="doc-biblioref">77</a>]</span> or as a means to provide the scientific community with a gold standard <span class="citation" data-cites="L9IIm3Zd 6wNuLZWb luGt8luc">[<a href="#ref-6wNuLZWb" role="doc-biblioref">77</a>,<a href="#ref-L9IIm3Zd" role="doc-biblioref">78</a>,<a href="#ref-luGt8luc" role="doc-biblioref">79</a>]</span>. Approaches that use these available datasets range from using support vector machines (SVMs) with custom kernels to deep learning with algorithms that can construct their own features. In the rest of this section we discuss approaches that use supervised methods to detect relationship-asserting sentences.</p>
<p>Extracting relationships in a supervised setting can involve mapping textual input onto a high dimensional space. Support vector machines are a type of classifier that can accomplish this task with a mapping function called a kernel <span class="citation" data-cites="iiQkIqUX 1B0lnkj35">[<a href="#ref-iiQkIqUX" role="doc-biblioref">53</a>,<a href="#ref-1B0lnkj35" role="doc-biblioref">80</a>]</span>. These kernels take information such as a sentence’s dependency tree <span class="citation" data-cites="i7KpvzCo 3j1T67vB">[<a href="#ref-i7KpvzCo" role="doc-biblioref">51</a>,<a href="#ref-3j1T67vB" role="doc-biblioref">52</a>]</span>, part of speech tags <span class="citation" data-cites="iiQkIqUX">[<a href="#ref-iiQkIqUX" role="doc-biblioref">53</a>]</span> or even word counts <span class="citation" data-cites="1B0lnkj35">[<a href="#ref-1B0lnkj35" role="doc-biblioref">80</a>]</span> and map them onto a dense feature space. Within this space, the methods learn a hyperplane that separates sentences in the positive class (mentions a relationship) from the negative class (does not mention a relationship). Kernels can be manually constructed or selected to cater to the relationship being extracted <span class="citation" data-cites="iiQkIqUX 3j1T67vB 1B0lnkj35 1B0lnkj35">[<a href="#ref-3j1T67vB" role="doc-biblioref">52</a>,<a href="#ref-iiQkIqUX" role="doc-biblioref">53</a>,<a href="#ref-1B0lnkj35" role="doc-biblioref">80</a>,<a href="#ref-1B0lnkj35" role="doc-biblioref">80</a>]</span>. Determining the correct kernel requires expert knowledge to be successful and is a nontrivial task depending on the relationship. In addition to single kernel methods, a recent study used an ensemble of SVMs to extract disease-gene associations <span class="citation" data-cites="GeCe9qfW">[<a href="#ref-GeCe9qfW" role="doc-biblioref">81</a>]</span>. The ensemble outperformed notable disease-gene association extractors <span class="citation" data-cites="jg0TGCov hbAqN08A">[<a href="#ref-jg0TGCov" role="doc-biblioref">64</a>,<a href="#ref-hbAqN08A" role="doc-biblioref">82</a>]</span> in terms of precision, recall and F1 score. Overall, SVMs have been shown to be beneficial in terms of relationship mining; however, major focus have shifted to utilizing deep learning techniques to extract relationships as these approaches can perform non-linear mappings of high dimensional data.</p>
<p>Deep learning is an increasingly popular class of techniques that can construct their own features within a high dimensional space <span class="citation" data-cites="vDFZcSf9 BeijBSRE">[<a href="#ref-vDFZcSf9" role="doc-biblioref">83</a>,<a href="#ref-BeijBSRE" role="doc-biblioref">84</a>]</span>. These methods use different forms of neural networks, such as recurrent or convolutional neural networks, to perform classification.</p>
<p>Recurrent neural networks (RNN) are designed for sequential analysis that consist of using a repeatedly updating hidden state to make predictions. An example of a recurrent neural network is a long short term memory (LSTM) network <span class="citation" data-cites="x4dbEYer">[<a href="#ref-x4dbEYer" role="doc-biblioref">85</a>]</span>. Cocos et al <span class="citation" data-cites="kCSge2o8">[<a href="#ref-kCSge2o8" role="doc-biblioref">86</a>]</span> used a LSTM to extract drug side effects from de-identified twitter posts, while Yadav et al. <span class="citation" data-cites="hEblZ1j5">[<a href="#ref-hEblZ1j5" role="doc-biblioref">87</a>]</span> used an LSTM to extract protein-protein interactions. Other works have used LSTMs to perform relationship extraction <span class="citation" data-cites="8lfvAUz7 8NrcroGt k4sSP5gN 1F5aZYjOB kCSge2o8">[<a href="#ref-kCSge2o8" role="doc-biblioref">86</a>,<a href="#ref-8lfvAUz7" role="doc-biblioref">88</a>,<a href="#ref-8NrcroGt" role="doc-biblioref">89</a>,<a href="#ref-k4sSP5gN" role="doc-biblioref">90</a>,<a href="#ref-1F5aZYjOB" role="doc-biblioref">91</a>]</span>. Despite the success of these networks, training can be difficult as these networks are highly susceptible to vanishing and exploding gradients <span class="citation" data-cites="YYBiIF26 6PiFh6Y2">[<a href="#ref-YYBiIF26" role="doc-biblioref">92</a>,<a href="#ref-6PiFh6Y2" role="doc-biblioref">93</a>]</span>. One solution to this problem is to clip the gradients while the neural network trains <span class="citation" data-cites="FoztezBR">[<a href="#ref-FoztezBR" role="doc-biblioref">94</a>]</span>. Besides the gradient problem, these approaches peak in performance when the dataset reaches at least a tens of thousand of data points <span class="citation" data-cites="anpoBunY">[<a href="#ref-anpoBunY" role="doc-biblioref">95</a>]</span>.</p>
<p>Convolutional neural networks (CNNs), which are widely applied for image analysis, use multiple kernel filters to capture small subsets of an overall image <span class="citation" data-cites="BeijBSRE">[<a href="#ref-BeijBSRE" role="doc-biblioref">84</a>]</span>. In the context of text mining an image is replaced with words within a sentence mapped to dense vectors (i.e., word embeddings) <span class="citation" data-cites="1GhHIDxuW u5iJzbp9">[<a href="#ref-1GhHIDxuW" role="doc-biblioref">96</a>,<a href="#ref-u5iJzbp9" role="doc-biblioref">97</a>]</span>. Peng et al. <span class="citation" data-cites="TNHJioqT">[<a href="#ref-TNHJioqT" role="doc-biblioref">98</a>]</span> used a CNN to extract sentences that mentioned protein-protein interactions and Zhou et al. <span class="citation" data-cites="HS4ARwmZ">[<a href="#ref-HS4ARwmZ" role="doc-biblioref">99</a>]</span> used a CNN to extract chemical-disease relations. Other approaches have used CNNs and variants of CNNs to extract relationship-asserting sentences <span class="citation" data-cites="1H4LpFrU0 5LOkzCNK 19fr9ZRrA">[<a href="#ref-1H4LpFrU0" role="doc-biblioref">100</a>,<a href="#ref-5LOkzCNK" role="doc-biblioref">101</a>,<a href="#ref-19fr9ZRrA" role="doc-biblioref">102</a>]</span>. Just like RNNs, these networks perform well when millions of labeled examples are present <span class="citation" data-cites="anpoBunY">[<a href="#ref-anpoBunY" role="doc-biblioref">95</a>]</span>. Future approaches that use CNNs or RNNs should consider solutions to obtaining these large quantities of data through means such as weak supervision <span class="citation" data-cites="EHeTvZht">[<a href="#ref-EHeTvZht" role="doc-biblioref">103</a>]</span>, semi-supervised learning <span class="citation" data-cites="xWET58su">[<a href="#ref-xWET58su" role="doc-biblioref">104</a>]</span> or using pre-trained networks via transfer learning <span class="citation" data-cites="12JtL2o6T YRDXK4f4">[<a href="#ref-12JtL2o6T" role="doc-biblioref">105</a>,<a href="#ref-YRDXK4f4" role="doc-biblioref">106</a>]</span>.</p>
<p>Semi-supervised learning <span class="citation" data-cites="xWET58su">[<a href="#ref-xWET58su" role="doc-biblioref">104</a>]</span> and weak supervision <span class="citation" data-cites="EHeTvZht">[<a href="#ref-EHeTvZht" role="doc-biblioref">103</a>]</span> are techniques that can construct large datasets for machine learning classifiers. Semi-supervised learning consists of combining labeled data with unlabeled data to extract relationships. For example, one study used a variational auto encoder with a LSTM network to extract protein-protein interactions from pubmed abstracts and full text <span class="citation" data-cites="hNMqMImK">[<a href="#ref-hNMqMImK" role="doc-biblioref">107</a>]</span>. This is an elegant solution to handle the small dataset problem, but requires labeled data to start. The dependency on labeled data makes finding under-studied relationships difficult as one would need to find or construct examples of the missing relationships in the beginning.</p>
<p>Weak or distant supervision takes a different approach that uses noisy or even erroneous labels to train classifiers <span class="citation" data-cites="EHeTvZht WYud0jQT vzoBuh4l 9Jo1af7Z">[<a href="#ref-EHeTvZht" role="doc-biblioref">103</a>,<a href="#ref-WYud0jQT" role="doc-biblioref">108</a>,<a href="#ref-vzoBuh4l" role="doc-biblioref">109</a>,<a href="#ref-9Jo1af7Z" role="doc-biblioref">110</a>]</span>. Under this paradigm sentences are labeled based on their mention pair being present (positive) or absent (negative) in a database. Once these labels are obtained a machine learning classifier can now be trained to predict sentences <span class="citation" data-cites="EHeTvZht">[<a href="#ref-EHeTvZht" role="doc-biblioref">103</a>]</span>. For example, Thomas et al. <span class="citation" data-cites="kvlZD1mv">[<a href="#ref-kvlZD1mv" role="doc-biblioref">111</a>]</span> used distant supervision to train a support vector machine to extract sentences mentioning protein-protein interactions (ppi). Their SVM model achieved comparable performance against a baseline model; however, the noise generated via distant supervision was difficult to eradicate <span class="citation" data-cites="kvlZD1mv">[<a href="#ref-kvlZD1mv" role="doc-biblioref">111</a>]</span>. A number of efforts have focused on combining distant supervision with other types of labeling strategies to reduce the negative impacts of noisy knowledge bases <span class="citation" data-cites="Kry87kzn M5UWoN93 xy08BzDf">[<a href="#ref-Kry87kzn" role="doc-biblioref">112</a>,<a href="#ref-M5UWoN93" role="doc-biblioref">113</a>,<a href="#ref-xy08BzDf" role="doc-biblioref">114</a>]</span>. Nicholson et al. <span class="citation" data-cites="19fr9ZRrA">[<a href="#ref-19fr9ZRrA" role="doc-biblioref">102</a>]</span> found that, in some circumstances, these strategies and rules can be reused across different types of biomedical edges to learn a heterogeneous knowledge graph if those edges describe similar physical concepts. This remains an active area of investigation with numerous associated challenges and opportunities. Overall, semi-supervised learning and weak supervision provide promising results in terms of relation extraction and future approaches should consider using those paradigms to train machine learning classifiers.</p>
<a name="tbl:supervised-text-datasets"></a>
<table>
<caption><span>Table 3:</span> A set of publicly available datasets for supervised text mining. </caption>
<thead>
<tr class="header">
<th>Dataset</th>
<th>Type of Sentences</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AIMed <span class="citation" data-cites="YWh6tPj">[<a href="#ref-YWh6tPj" role="doc-biblioref">42</a>]</span></td>
<td>PPI</td>
</tr>
<tr class="even">
<td>BioInfer <span class="citation" data-cites="DWpAeBxB">[<a href="#ref-DWpAeBxB" role="doc-biblioref">115</a>]</span></td>
<td>PPI</td>
</tr>
<tr class="odd">
<td>LLL <span class="citation" data-cites="szMMEMdC">[<a href="#ref-szMMEMdC" role="doc-biblioref">116</a>]</span></td>
<td>PPI</td>
</tr>
<tr class="even">
<td>IEPA <span class="citation" data-cites="115pgEuOr">[<a href="#ref-115pgEuOr" role="doc-biblioref">117</a>]</span></td>
<td>PPI</td>
</tr>
<tr class="odd">
<td>HPRD5 <span class="citation" data-cites="L9IIm3Zd">[<a href="#ref-L9IIm3Zd" role="doc-biblioref">78</a>]</span></td>
<td>PPI</td>
</tr>
<tr class="even">
<td>EU-ADR <span class="citation" data-cites="Y2DcwTrA">[<a href="#ref-Y2DcwTrA" role="doc-biblioref">41</a>]</span></td>
<td>DaG</td>
</tr>
<tr class="odd">
<td>BeFree <span class="citation" data-cites="hbAqN08A">[<a href="#ref-hbAqN08A" role="doc-biblioref">82</a>]</span></td>
<td>DaG</td>
</tr>
<tr class="even">
<td>CoMAGC <span class="citation" data-cites="luGt8luc">[<a href="#ref-luGt8luc" role="doc-biblioref">79</a>]</span></td>
<td>DaG</td>
</tr>
<tr class="odd">
<td>CRAFT <span class="citation" data-cites="1Du6MinB8">[<a href="#ref-1Du6MinB8" role="doc-biblioref">118</a>]</span></td>
<td>DaG</td>
</tr>
<tr class="even">
<td>Biocreative V CDR <span class="citation" data-cites="6wNuLZWb">[<a href="#ref-6wNuLZWb" role="doc-biblioref">77</a>]</span></td>
<td>Compound induces Disease</td>
</tr>
<tr class="odd">
<td>Biocreative IV ChemProt <span class="citation" data-cites="16As8893j">[<a href="#ref-16As8893j" role="doc-biblioref">76</a>]</span></td>
<td>CbG</td>
</tr>
</tbody>
</table>
<h2 id="applying-knowledge-graphs-to-biomedical-challenges">Applying Knowledge Graphs to Biomedical Challenges</h2>
<p>Knowledge graphs can help researchers tackle many biomedical tasks such as finding new treatments for existing drugs <span class="citation" data-cites="O21tn8vf">[<a href="#ref-O21tn8vf" role="doc-biblioref">9</a>]</span>, aiding efforts to diagnose patients <span class="citation" data-cites="10nDTiETi">[<a href="#ref-10nDTiETi" role="doc-biblioref">119</a>]</span> and predicting associations between diseases and biomolecules <span class="citation" data-cites="YyPaovQ0">[<a href="#ref-YyPaovQ0" role="doc-biblioref">120</a>]</span>. In many cases, solutions rely on representing knowledges graphs in a low dimensional space, which is a process called representation learning. This space preserves a knowledge graph’s local and/or global structure and can support efforts to apply machine learning methods to make predictions. We discuss the unifying techniques to construct this low dimensional space and unifying applications that use this space to solve biomedical problems.</p>
<h3 id="unifying-techniques">Unifying Techniques</h3>
<p>Mapping high dimensional data into a low dimensional space has greatly improved modeling performance in fields such as natural language processing <span class="citation" data-cites="1GhHIDxuW u5iJzbp9">[<a href="#ref-1GhHIDxuW" role="doc-biblioref">96</a>,<a href="#ref-u5iJzbp9" role="doc-biblioref">97</a>]</span> and image analysis <span class="citation" data-cites="j7KrVyi8">[<a href="#ref-j7KrVyi8" role="doc-biblioref">121</a>]</span>. The success of these approaches provides rationale for projecting knowledge graphs into a low dimensional space as well <span class="citation" data-cites="DSiHGDz9">[<a href="#ref-DSiHGDz9" role="doc-biblioref">122</a>]</span>. Techniques that perform this projection often require information on how nodes are connected with one another <span class="citation" data-cites="18ZTxo1gJ u6NlpEUq dylXYFm6 9F3iyg8e">[<a href="#ref-18ZTxo1gJ" role="doc-biblioref">123</a>,<a href="#ref-u6NlpEUq" role="doc-biblioref">124</a>,<a href="#ref-dylXYFm6" role="doc-biblioref">125</a>,<a href="#ref-9F3iyg8e" role="doc-biblioref">126</a>]</span>, while other approaches can work directly with the edges themselves <span class="citation" data-cites="E5xHFo4P">[<a href="#ref-E5xHFo4P" role="doc-biblioref">127</a>]</span>. We group methods for producing low-dimensional representations of knowledge graphs into the following three categories: matrix factorization, translational methods, and deep learning (Figure <a href="#fig:unifying_techniques_overview">4</a>).</p>
<figure>
<img src="images/figures/unifying_techniques_overview.png" alt="Figure 4: Pipeline for embedding knowledge graphs into a low dimensional space. Starting with a knowledge graph, embeddings can be generated using one of the following options: Matrix Factorization (a), Translational Models (b) or Deep Learning (c). The output of this pipeline is an embedding space that clusters similar node types together." id="fig:unifying_techniques_overview" /><figcaption><span>Figure 4:</span> Pipeline for embedding knowledge graphs into a low dimensional space. Starting with a knowledge graph, embeddings can be generated using one of the following options: Matrix Factorization (a), Translational Models (b) or Deep Learning (c). The output of this pipeline is an embedding space that clusters similar node types together.</figcaption>
</figure>
<h4 id="matrix-factorization">Matrix Factorization</h4>
<p>Matrix factorization is a technique that uses linear algebra to map high dimensional data into a low dimensional space. This projection is accomplished by decomposing a matrix into a set of small rectangular matrices (Figure <a href="#fig:unifying_techniques_overview">4</a> (a)). Notable methods for matrix decomposition include Isomap <span class="citation" data-cites="13cvwdrYY">[<a href="#ref-13cvwdrYY" role="doc-biblioref">128</a>]</span>, Laplacian eigenmaps <span class="citation" data-cites="MxPEnWF1">[<a href="#ref-MxPEnWF1" role="doc-biblioref">129</a>]</span> and Principal Component Analysis (PCA) <span class="citation" data-cites="sSbTaHau">[<a href="#ref-sSbTaHau" role="doc-biblioref">130</a>]</span>/Singular Vector Decomposition (SVD) <span class="citation" data-cites="H0ez30Pz">[<a href="#ref-H0ez30Pz" role="doc-biblioref">131</a>]</span>. These methods were designed to be used on many different types of data; however, we discuss their use in the context of projecting knowledge graphs into a low dimensional space.</p>
<p>SVD <span class="citation" data-cites="H0ez30Pz">[<a href="#ref-H0ez30Pz" role="doc-biblioref">131</a>]</span> is an algorithm that uses matrix factorization to represent knowledge graphs in a low dimensional space. The input for this algorithm is an adjacency matrix (<span class="math inline">\(A\)</span>), which is a square matrix where rows and columns represent nodes and each entry represents the presence of an edge between two nodes. This adjacency matrix (<span class="math inline">\(A\)</span>) gets decomposed into three parts: a square matrix <span class="math inline">\(Σ\)</span> and a set of two small rectangular matrices <span class="math inline">\(U\)</span> and <span class="math inline">\(V^{T}\)</span>. This values within <span class="math inline">\(Σ\)</span> are called singular values, which akin to eigenvalues <span class="citation" data-cites="H0ez30Pz">[<a href="#ref-H0ez30Pz" role="doc-biblioref">131</a>]</span>. Each row in <span class="math inline">\(U\)</span> and each column in <span class="math inline">\(V^{T}\)</span> represents nodes projected onto a low dimensional space <span class="citation" data-cites="H0ez30Pz sSbTaHau">[<a href="#ref-sSbTaHau" role="doc-biblioref">130</a>,<a href="#ref-H0ez30Pz" role="doc-biblioref">131</a>]</span>. In practice <span class="math inline">\(U\)</span> is usually used to represent nodes in a knowledge graph, but <span class="math inline">\(V^{T}\)</span> can also be used <span class="citation" data-cites="H0ez30Pz TFsQrgwM">[<a href="#ref-H0ez30Pz" role="doc-biblioref">131</a>,<a href="#ref-TFsQrgwM" role="doc-biblioref">132</a>]</span>. Typically, SVD appears in recommendation systems via collaborative filtering <span class="citation" data-cites="Z5VAJJmP">[<a href="#ref-Z5VAJJmP" role="doc-biblioref">133</a>]</span>; however, this technique can also be used as a standalone baseline to compare to other approaches <span class="citation" data-cites="OJXYxm8W">[<a href="#ref-OJXYxm8W" role="doc-biblioref">134</a>]</span>.</p>
<p>Laplacian eigenmaps assume there is low dimensional structure in a high dimensional space <span class="citation" data-cites="MxPEnWF1">[<a href="#ref-MxPEnWF1" role="doc-biblioref">129</a>]</span>. This algorithm preserves this structure while projecting data into a low dimensional space. Typically, the first step of this algorithm is to construct a figurative knowledge graph where nodes represent datapoints and edges are constructed based on similarity of two datapoints; however, in this context, the knowledge graph has already been constructed. The next step in this algorithm is to obtain both an adjacency matrix (<span class="math inline">\(A\)</span>) and a degree matrix (<span class="math inline">\(D\)</span>) from the knowledge graph. A degree matrix is a diagonal matrix where each entry represents the number of edges connected to a node. The adjacency and degree matrices are converted into a laplacian matrix (<span class="math inline">\(L\)</span>), which is a matrix that shares the same properties as the adjacency matrix. The laplacian matrix is generated by subtracting the adjacency matrix from the degree matrix (<span class="math inline">\(L=D-A\)</span>) and, once constructed, the algorithm uses linear algebra to calculate eigenvalues and eigenvectors from the matrix (<span class="math inline">\(Lx = \lambda Dx\)</span>). The generated eigenvectors represent the knowledge graph’s nodes projected onto a low dimensional space <span class="citation" data-cites="MxPEnWF1">[<a href="#ref-MxPEnWF1" role="doc-biblioref">129</a>]</span>. A number of approaches have used variants of this algorithm to perform their own node projection <span class="citation" data-cites="18ZTxo1gJ u6NlpEUq KzDGRrSP">[<a href="#ref-18ZTxo1gJ" role="doc-biblioref">123</a>,<a href="#ref-u6NlpEUq" role="doc-biblioref">124</a>,<a href="#ref-KzDGRrSP" role="doc-biblioref">135</a>]</span>. Typically, eigenmaps work well when knowledge graphs have a sparse number of edges between nodes but struggle when presented with denser networks <span class="citation" data-cites="OJXYxm8W FE8pyO0l KzDGRrSP">[<a href="#ref-OJXYxm8W" role="doc-biblioref">134</a>,<a href="#ref-KzDGRrSP" role="doc-biblioref">135</a>,<a href="#ref-FE8pyO0l" role="doc-biblioref">136</a>]</span>. A future direction is to adapt these methods to scale to knowledge graphs that have a large number of edges.</p>
<p>Matrix factorization is a powerful technique that uses a matrices such as an adjacency matrix as input. Common approaches involve using SVD, Laplacian eigenmaps or variants of the two to perform embeddings. Despite reported success, the dependence on matrices like an adjacency matrix creates an issue of scalability as matrices of large networks would take too much memory for a regular computer to handle. Furthermore, these methods treat all edge types the same, but a possible extension for future approaches that use matrix factorization would be to incorporate node and edge types as sources of input.</p>
<h4 id="translational-distance-models">Translational Distance Models</h4>
<p>Translational distance models treat edges in a knowledge graph as linear transformations. As an example, one such algorithm, TransE <span class="citation" data-cites="mGBbZq62">[<a href="#ref-mGBbZq62" role="doc-biblioref">137</a>]</span>, treats every node-edge pair as a triplet with head nodes represented as <span class="math inline">\(\textbf{h}\)</span>, edges represented as <span class="math inline">\(\textbf{r}\)</span>, and tail nodes represented as <span class="math inline">\(\textbf{t}\)</span>. These representations are combined into an equation that mimics the iconic word vectors translations (<span class="math inline">\(\textbf{king} - \textbf{man} + \textbf{woman} \approx \textbf{queen}\)</span>) from the Word2vec model <span class="citation" data-cites="u5iJzbp9">[<a href="#ref-u5iJzbp9" role="doc-biblioref">97</a>]</span>. The equation is shown as follows: <span class="math inline">\(\textbf{h} + \textbf{r} \approx \textbf{t}\)</span>. Starting at the head node (<span class="math inline">\(\textbf{h}\)</span>), add the edge vector (<span class="math inline">\(\textbf{r}\)</span>) and the result should be the tail node (<span class="math inline">\(\textbf{t}\)</span>). TransE optimizes embeddings for <span class="math inline">\(\textbf{h}\)</span>, <span class="math inline">\(\textbf{r}\)</span>, <span class="math inline">\(\textbf{t}\)</span>, while guaranteeing the global equation (<span class="math inline">\(\textbf{h} + \textbf{r} \approx \textbf{t}\)</span>) is satisfied <span class="citation" data-cites="mGBbZq62">[<a href="#ref-mGBbZq62" role="doc-biblioref">137</a>]</span>. A caveat to the TransE approach is that it the training steps force relationships to have a one to one mapping, which may not be appropriate for all types of relationships.</p>
<p>Wang et al. <span class="citation" data-cites="nprR5cVj">[<a href="#ref-nprR5cVj" role="doc-biblioref">138</a>]</span> attempted to resolve the one to one mapping issue by developing the TransH model. TransH treats relations as hyperplanes rather than a regular vector and projects the head (<span class="math inline">\(\textbf{h}\)</span>) and tail (<span class="math inline">\(\textbf{t}\)</span>) nodes onto the hyperplane. Following this projection, a distance vector (<span class="math inline">\(\textbf{d}_{r}\)</span>) is calculated between the projected head and tail nodes. Finally, each vector is optimized while preserving the global equation (<span class="math inline">\(\textbf{h} + \textbf{d}_{r} \approx \textbf{t}\)</span>) <span class="citation" data-cites="nprR5cVj">[<a href="#ref-nprR5cVj" role="doc-biblioref">138</a>]</span>. Other approaches <span class="citation" data-cites="R8kotaKY BRGxlTb9">[<a href="#ref-R8kotaKY" role="doc-biblioref">139</a>,<a href="#ref-BRGxlTb9" role="doc-biblioref">140</a>]</span> have built off of the TransE and TransH models. In the future, it may be beneficial for these models is to incorporate other types of information such as edge confidence scores, textual information, or edge type information when optimizing these embeddings.</p>
<h4 id="deep-learning">Deep Learning</h4>
<p>Deep learning is a paradigm that uses multiple non-linear transformations to map high dimensional data into a low dimensional space. Many techniques that use deep learning for knowledge graphs are based on word2vec <span class="citation" data-cites="u5iJzbp9 1GhHIDxuW">[<a href="#ref-1GhHIDxuW" role="doc-biblioref">96</a>,<a href="#ref-u5iJzbp9" role="doc-biblioref">97</a>]</span>, a set of approaches that are widely used for natural language processing. The goal of word2vec is to project words into a low dimensional space that preserves their semantic meaning. Strategies for training word2vec models use one of two neural network architectures: skip-gram and continuous bag of words (CBOW). Both models are feed-forward neural networks, but CBOW models are trained to predict a word given it’s context while skip-gram models are trained to predict the context given a word <span class="citation" data-cites="u5iJzbp9 1GhHIDxuW">[<a href="#ref-1GhHIDxuW" role="doc-biblioref">96</a>,<a href="#ref-u5iJzbp9" role="doc-biblioref">97</a>]</span>. Once training has finished, words are now associated with dense vectors that downstream models, such as feed forward networks or recurrent networks, can use for input.</p>
<p>Deepwalk <span class="citation" data-cites="7BUncUx3">[<a href="#ref-7BUncUx3" role="doc-biblioref">141</a>]</span> is an early method designed to project a knowledge graph into a low dimensional space. The first step of this method is to perform a random walk along a knowledge graph. During the random walk, every generated sequence of nodes is recorded and treated like a sentence in word2vec <span class="citation" data-cites="u5iJzbp9 1GhHIDxuW">[<a href="#ref-1GhHIDxuW" role="doc-biblioref">96</a>,<a href="#ref-u5iJzbp9" role="doc-biblioref">97</a>]</span>. After every node has been processed, a skip-gram model is trained to predict the context of each node thereby projecting a knowledge graph into a low dimensional space <span class="citation" data-cites="7BUncUx3">[<a href="#ref-7BUncUx3" role="doc-biblioref">141</a>]</span>. A limitation of this method is that the random walk cannot be controlled, so every node has an equal chance to be reached. Grover and Leskovec <span class="citation" data-cites="PD4udqRe">[<a href="#ref-PD4udqRe" role="doc-biblioref">142</a>]</span> demonstrated that this limitation can hurt performance when classifying edges between nodes and developed node2vec as a result. Node2vec <span class="citation" data-cites="PD4udqRe">[<a href="#ref-PD4udqRe" role="doc-biblioref">142</a>]</span> operates the in the same fashion as deepwalk; however, this algorithm specifies a parameter that lets the random walk be biased when traversing nodes. A caveat to both deepwalk and node2vec is that both algorithms ignore information such as edge type and node type. Various approaches have evolved to fix this limitation by incorporating node, edge and even path types when projecting nodes into a low dimensional space <span class="citation" data-cites="BatC4UOA 1AeZs6xaT 1G1nukcFt eSGflyQ5">[<a href="#ref-BatC4UOA" role="doc-biblioref">143</a>,<a href="#ref-1AeZs6xaT" role="doc-biblioref">144</a>,<a href="#ref-1G1nukcFt" role="doc-biblioref">145</a>,<a href="#ref-eSGflyQ5" role="doc-biblioref">146</a>]</span>. These approaches primarily capture a network’s local structure. An emerging area of work is to develop approaches that capture both the local and global structure of a network when projecting knowledge graphs into a low dimensional space.</p>
<p>Some deep learning approaches use an adjacency matrix as input <span class="citation" data-cites="u5iJzbp9 1GhHIDxuW">[<a href="#ref-1GhHIDxuW" role="doc-biblioref">96</a>,<a href="#ref-u5iJzbp9" role="doc-biblioref">97</a>]</span> instead of using the word2vec framing. Algorithms such as auto-encoders can also generate network embeddings <span class="citation" data-cites="bt1KIf4U hjIIetVM 1A6Dhbwkr">[<a href="#ref-bt1KIf4U" role="doc-biblioref">147</a>,<a href="#ref-hjIIetVM" role="doc-biblioref">148</a>,<a href="#ref-1A6Dhbwkr" role="doc-biblioref">149</a>]</span>. Autoencoders <span class="citation" data-cites="DZT65ZRY 1ErNQZjBt">[<a href="#ref-DZT65ZRY" role="doc-biblioref">150</a>,<a href="#ref-1ErNQZjBt" role="doc-biblioref">151</a>]</span> are neural networks that map input such as an adjacency matrices into a low dimensional space and then learns how to construct this space by reconstructing the same input. The generated low dimensional space captures the node connectivity structure of the knowledge graph and every node is mapped onto this space <span class="citation" data-cites="bt1KIf4U hjIIetVM 1A6Dhbwkr">[<a href="#ref-bt1KIf4U" role="doc-biblioref">147</a>,<a href="#ref-hjIIetVM" role="doc-biblioref">148</a>,<a href="#ref-1A6Dhbwkr" role="doc-biblioref">149</a>]</span>. Despite the high potential of this approach, this method relies on an adjacency matrix for input. If a knowledge graph asymptotically increases in size, these approaches could run into scalability issues as discovered by Khosla et al. <span class="citation" data-cites="YVOAlp8C">[<a href="#ref-YVOAlp8C" role="doc-biblioref">152</a>]</span>. Plus, Khosla et al.<span class="citation" data-cites="YVOAlp8C">[<a href="#ref-YVOAlp8C" role="doc-biblioref">152</a>]</span> discovered that approaches akin to node2vec outperformed algorithms using autoencoders when undergoing link prediction and node classification. Overall, the performance of these models largely depends upon the structure of nodes and edges within a knowledge graph <span class="citation" data-cites="YVOAlp8C">[<a href="#ref-YVOAlp8C" role="doc-biblioref">152</a>]</span>. Future approaches should consider creating hybrid models that use both node2vec and autoencoders to construct complementary low dimensional representations of knowledge graphs.</p>
<h3 id="unifying-applications">Unifying Applications</h3>
<p>Knowledge graphs have been used in many biomedical applications ranging from identifying protein functions <span class="citation" data-cites="1EP2NrAhl">[<a href="#ref-1EP2NrAhl" role="doc-biblioref">153</a>]</span> to prioritizing cancer genes <span class="citation" data-cites="17R6q0KTd">[<a href="#ref-17R6q0KTd" role="doc-biblioref">154</a>]</span> to recommending safer drugs to patients <span class="citation" data-cites="aLsdEzlV 8vj5v8un">[<a href="#ref-aLsdEzlV" role="doc-biblioref">155</a>,<a href="#ref-8vj5v8un" role="doc-biblioref">156</a>]</span> (Figure <a href="#fig:unifying_applications">5</a>). In this section we discuss how knowledge graphs are being applied in biomedical settings and put particular emphasis on an emerging set of techniques: those that project knowledge graphs into a low dimensional space.</p>
<figure>
<img src="images/figures/unifying_applications_overview.png" alt="Figure 5: Overview of biomedical applications that make use of knowledge graphs. Categories consist of: (a) Multi-Omic applications, (b) Pharmaceutical Applications and (c) Clinical Applications." id="fig:unifying_applications" /><figcaption><span>Figure 5:</span> Overview of biomedical applications that make use of knowledge graphs. Categories consist of: (a) Multi-Omic applications, (b) Pharmaceutical Applications and (c) Clinical Applications.</figcaption>
</figure>
<h4 id="multi-omic-applications">Multi-Omic Applications</h4>
<p>Multi-omic applications for knowledge graphs include efforts to study the genome, how genes are expressed in the transcriptome, and how the products of those transcripts interact in the proteome. Approaches in this category use knowledge graphs to establish connections between -omic entities as well as diseases. Such tasks include gene-symptom prioritization <span class="citation" data-cites="otY29wFV">[<a href="#ref-otY29wFV" role="doc-biblioref">157</a>]</span>, protein-protein interaction prediction <span class="citation" data-cites="6O3BO6WO Y2RTnbCe">[<a href="#ref-6O3BO6WO" role="doc-biblioref">158</a>,<a href="#ref-Y2RTnbCe" role="doc-biblioref">159</a>]</span>, and detecting miRNA-disease associations <span class="citation" data-cites="YyPaovQ0">[<a href="#ref-YyPaovQ0" role="doc-biblioref">120</a>]</span>. We focus specifically on multi-omic applications of algorithms that project knowledge graphs into a low dimensional space to make connections.</p>
<p>Knowledge graphs have been used as recommendation systems to establish links between RNA with disease and proteins with other proteins. Shen et al. <span class="citation" data-cites="YyPaovQ0">[<a href="#ref-YyPaovQ0" role="doc-biblioref">120</a>]</span> used an algorithm called collaborative filtering to establish an association between miRNA and diseases. The authors constructed an miRNA-Disease network using the HMDDD database <span class="citation" data-cites="1F18ycwfS">[<a href="#ref-1F18ycwfS" role="doc-biblioref">160</a>]</span> and generated an adjacency matrix with the rows representing miRNA and the columns representing diseases. This adjacency matrix was decomposed into small rectangular matrices using SVD, then these matricies were used to calculate similarity scores between the miRNA and diseases. High scores implied a high likelihood that a given miRNA had an association with a given disease <span class="citation" data-cites="YyPaovQ0">[<a href="#ref-YyPaovQ0" role="doc-biblioref">120</a>]</span>. Other approaches have built off of Shen et al.’s <span class="citation" data-cites="YyPaovQ0">[<a href="#ref-YyPaovQ0" role="doc-biblioref">120</a>]</span> work by incorpoating novel ways to perform matrix factorization <span class="citation" data-cites="1DjgsuPV2 hZ2R5BRj 4xcJzyPc">[<a href="#ref-1DjgsuPV2" role="doc-biblioref">161</a>,<a href="#ref-hZ2R5BRj" role="doc-biblioref">162</a>,<a href="#ref-4xcJzyPc" role="doc-biblioref">163</a>]</span> or by integrating machine learning models in conjunction with matrix factorization <span class="citation" data-cites="icSe8Yyw">[<a href="#ref-icSe8Yyw" role="doc-biblioref">164</a>]</span>. These methods provided high AUROCs, but new discoveries have been hard to validate as experiments in this space are costly and time consuming at best <span class="citation" data-cites="YyPaovQ0">[<a href="#ref-YyPaovQ0" role="doc-biblioref">120</a>]</span>. Apart from miRNA, collaborative filtering has been used to predict protein-protein interactions <span class="citation" data-cites="6FrpIkNZ 6O3BO6WO Y2RTnbCe">[<a href="#ref-6O3BO6WO" role="doc-biblioref">158</a>,<a href="#ref-Y2RTnbCe" role="doc-biblioref">159</a>,<a href="#ref-6FrpIkNZ" role="doc-biblioref">165</a>]</span>. Though extensive validation of newly generated candidates may be impractical, it would be helpful to see future efforts in this space include a blinded literature search for prioritized and randomly selected candidates as part of the standard evaluation of such approaches.</p>
<p>Approaches that use deep learning have mainly used the node2vec model <span class="citation" data-cites="PD4udqRe">[<a href="#ref-PD4udqRe" role="doc-biblioref">142</a>]</span> or variants of that model. Yang et al. <span class="citation" data-cites="otY29wFV">[<a href="#ref-otY29wFV" role="doc-biblioref">157</a>]</span> used node2vec to create a recommendation system to infer associations between genes and disease symptoms. The authors constructed a gene-disease symptom knowledge graph by combining two bipartite graphs: genes-diseases and diseases-disease symptoms. The generated knowledge graph was embedded via node2vec and similarity scores were calculated for every gene-symptom pair in the graph. High scores implicated high chance for an association <span class="citation" data-cites="otY29wFV">[<a href="#ref-otY29wFV" role="doc-biblioref">157</a>]</span>. This approach outperformed methods that didn’t use a knowledge graph; however, validation was difficult as it involved manual curation of the literature <span class="citation" data-cites="otY29wFV"><a href="#ref-otY29wFV" role="doc-biblioref">157</a></span>]. Similar approaches used variants of the node2vec algorithm to predict gene-disease associations <span class="citation" data-cites="1D9FTzRBg 6PISrkV5 taI1UUAE">[<a href="#ref-1D9FTzRBg" role="doc-biblioref">8</a>,<a href="#ref-6PISrkV5" role="doc-biblioref">166</a>,<a href="#ref-taI1UUAE" role="doc-biblioref">167</a>]</span> analyze RNA-seq data <span class="citation" data-cites="qbHGtxhA">[<a href="#ref-qbHGtxhA" role="doc-biblioref">168</a>]</span> and infer novel protein information <span class="citation" data-cites="QQtRw08H 8qB2oCgy RYW74Wvh 1EP2NrAhl">[<a href="#ref-1EP2NrAhl" role="doc-biblioref">153</a>,<a href="#ref-QQtRw08H" role="doc-biblioref">169</a>,<a href="#ref-8qB2oCgy" role="doc-biblioref">170</a>,<a href="#ref-RYW74Wvh" role="doc-biblioref">171</a>]</span>. Future extensions of these applications should consider incorporating more sources of data such as compounds, anatomic locations or even gene pathways to improve prediciton performance.</p>
<p>Knowledge graphs have aided the multi-omics field by generating novel discoveries. Most approaches to date use matrix factorization and node2vec to project knowledge graph into a low dimensional space, and translational models may be an untapped resource that could aid future efforts. Another area of exploration could be the incorporation of multiple sources of information such as anatomic locations or genetic pathways to improve the specificity of findings (i.e., to predict that a protein-protein interaction happens in a specific cell type or tissue).</p>
<h4 id="pharmaceutical-applications">Pharmaceutical Applications</h4>
<p>There are many examples of how knowledge graphs are applied to identify new properties of drugs. Tasks in this context involve prediction drugs interacting with other drugs <span class="citation" data-cites="NnOS86ev">[<a href="#ref-NnOS86ev" role="doc-biblioref">172</a>]</span>, identifying molecular targets a drug might interact with <span class="citation" data-cites="11ua4nEkY">[<a href="#ref-11ua4nEkY" role="doc-biblioref">173</a>]</span> and identifying new disease treatments for previously established drugs <span class="citation" data-cites="sj2fr8fp">[<a href="#ref-sj2fr8fp" role="doc-biblioref">174</a>]</span>. As with other applications, we focus on those that use low-dimensional representations.</p>
<p>Similar to multi-omic applications knowledge graphs have been used in recommendation systems to infer novel links between drugs and diseases. Dai et al. <span class="citation" data-cites="11ua4nEkY">[<a href="#ref-11ua4nEkY" role="doc-biblioref">173</a>]</span> used collaborative filtering to infer drug-disease associations. The authors constructed a drug-disease network by integrating two bipartite networks: a drug-gene interaction network and a disease-gene interaction network. They integrated both networks under the assumption that drugs associated with a disease interact with the same gene of interest. Then the authors generated an adjacency matrix where rows represent drugs and columns represent diseases and decomposed this matrix into two small rectangular matrices. These matrices were used to calculate similarity scores between all drugs and all diseases where high values implicate an association <span class="citation" data-cites="11ua4nEkY">[<a href="#ref-11ua4nEkY" role="doc-biblioref">173</a>]</span>. Related approaches have been used to infer drug-target interactions <span class="citation" data-cites="S0MrOfj0 HOrwJFzW Z391qdG0">[<a href="#ref-S0MrOfj0" role="doc-biblioref">175</a>,<a href="#ref-HOrwJFzW" role="doc-biblioref">176</a>,<a href="#ref-Z391qdG0" role="doc-biblioref">177</a>]</span> and drug-disease treatments <span class="citation" data-cites="dbgPwLaZ 94kKAy9w oKdMo9U9 16FEYidu2 18YRZaX7n">[<a href="#ref-dbgPwLaZ" role="doc-biblioref">178</a>,<a href="#ref-94kKAy9w" role="doc-biblioref">179</a>,<a href="#ref-oKdMo9U9" role="doc-biblioref">180</a>,<a href="#ref-16FEYidu2" role="doc-biblioref">181</a>,<a href="#ref-18YRZaX7n" role="doc-biblioref">182</a>]</span> In spite of reported success, these approaches are limited to the drugs and diseases contained in the network. Combining these approaches with representations of chemical structures might make it possible to one day make predictions about novel compounds.</p>
<p>Deep learning applications have used node2vec <span class="citation" data-cites="19E33rJiu dR3gjJXP">[<a href="#ref-19E33rJiu" role="doc-biblioref">183</a>,<a href="#ref-dR3gjJXP" role="doc-biblioref">184</a>]</span> and auto-encoder <span class="citation" data-cites="za8DCIPS 1BT2OTuxL">[<a href="#ref-za8DCIPS" role="doc-biblioref">185</a>,<a href="#ref-1BT2OTuxL" role="doc-biblioref">186</a>]</span> approaches to project knowledge graphs into a low dimensional space. Zong et al. <span class="citation" data-cites="19E33rJiu">[<a href="#ref-19E33rJiu" role="doc-biblioref">183</a>]</span> used a node2vec-like model to predict drug-target associations. The authors constructed a disease-target-disease network using drug centered databases: Drugbank <span class="citation" data-cites="111FgvD8J">[<a href="#ref-111FgvD8J" role="doc-biblioref">187</a>]</span> and Diseasome <span class="citation" data-cites="14fs7pzn0">[<a href="#ref-14fs7pzn0" role="doc-biblioref">188</a>]</span>. Next, the authors applied a random walk to the network and trained a skip-gram model to generate node embeddings. Lastly, the authors constructed a similarity metric to rank how similar drugs are to their targets <span class="citation" data-cites="19E33rJiu">[<a href="#ref-19E33rJiu" role="doc-biblioref">183</a>]</span>. A limitation to this method is that their network is missing information such as pharmacological class or drug chemical structure that may help in prediction performance. Overall, deep learning provides a robust set of techniques that has been shown to outperform most linear approaches in this context <span class="citation" data-cites="245Px4P3 WMEox1CM">[<a href="#ref-245Px4P3" role="doc-biblioref">189</a>,<a href="#ref-WMEox1CM" role="doc-biblioref">190</a>]</span>.</p>
<p>Knowledge graphs can support drug discovery efforts by predicting drug information such as drug side effects and new disease treatments. Most methods to date use matrix factorization and deep learning techniques to produce a low-dimensional representation. Due to the success of deep learning <span class="citation" data-cites="245Px4P3 WMEox1CM">[<a href="#ref-245Px4P3" role="doc-biblioref">189</a>,<a href="#ref-WMEox1CM" role="doc-biblioref">190</a>]</span> the focus of the field has shifted to these techniques; however, a possible extension is to use an ensemble of deep learning techniques and linear methods to improve performance. Plus, another area of exploration is to incorporate information such as phamaceutical classes for drugs or chemical structure to improve knowledge graph detection power.</p>
<h4 id="clinical-applications">Clinical applications</h4>
<p>Using knowledge graphs for clinical applications is in early stages of development, but the long-term goal is to use analyses of knowledge graphs to aid patient care. Typically, graphs for these applications are constructed from electronic health records (EHR) and nodes represent patients, drugs and diseases and edges represent relationships such as a patient being prescribed a treatment or a patient being diagnosed with a disease <span class="citation" data-cites="xNv4Rkif mrfQbq3g xU6Ims3W gddb9uXr">[<a href="#ref-gddb9uXr" role="doc-biblioref">18</a>,<a href="#ref-xNv4Rkif" role="doc-biblioref">191</a>,<a href="#ref-mrfQbq3g" role="doc-biblioref">192</a>,<a href="#ref-xU6Ims3W" role="doc-biblioref">193</a>]</span>. Tasks range from improving patient diagnoses <span class="citation" data-cites="UuF5A9Pu OCnhKscH">[<a href="#ref-UuF5A9Pu" role="doc-biblioref">194</a>,<a href="#ref-OCnhKscH" role="doc-biblioref">195</a>]</span> to recommending safer drugs for patients <span class="citation" data-cites="aLsdEzlV OCnhKscH">[<a href="#ref-aLsdEzlV" role="doc-biblioref">155</a>,<a href="#ref-OCnhKscH" role="doc-biblioref">195</a>]</span>.</p>
<p>Early work in this field applied translational models (Figure <a href="#fig:unifying_techniques_overview">4</a> (b)) to knowledge graphs to recommend safe drugs. Wang et al. <span class="citation" data-cites="aLsdEzlV">[<a href="#ref-aLsdEzlV" role="doc-biblioref">155</a>]</span> used a variant of the TransH <span class="citation" data-cites="nprR5cVj">[<a href="#ref-nprR5cVj" role="doc-biblioref">138</a>]</span> model to create such a system for patients. They constructed a disease-patient-drug network by integrating a patient-disease bipartite network with a patient-drug bipartite network. Every node in the graph was embedded while satisfying the following equation: <span class="math inline">\(\textbf{h} - r \approx \textbf{t}\)</span>. Following the embedding step, the authors formulated their own similarity metric that selected drug combinations with a low number of interactions <span class="citation" data-cites="aLsdEzlV">[<a href="#ref-aLsdEzlV" role="doc-biblioref">155</a>]</span>. Researchers in <span class="citation" data-cites="BRGxlTb9">[<a href="#ref-BRGxlTb9" role="doc-biblioref">140</a>]</span> applied a similar variant of the TransH model to a medical knowledge graph and evaluated their model for link prediction rather than patient recommendation.</p>
<p>In contrast with other applications where node2vec and auto-encoder models have become established, deep learning methods in this area often use graph attention models <span class="citation" data-cites="Exfv0f4l">[<a href="#ref-Exfv0f4l" role="doc-biblioref">196</a>]</span>. These models mimic machine translation models <span class="citation" data-cites="haHzVaaz">[<a href="#ref-haHzVaaz" role="doc-biblioref">197</a>]</span> and aim to simultaneously embed knowledge graphs into a low dimensional space and perform the task at hand. Choi et al. <span class="citation" data-cites="10nDTiETi">[<a href="#ref-10nDTiETi" role="doc-biblioref">119</a>]</span> used a graph attention model to predict patient diagnoses. The authors constructed a directed graph using medical concepts from patient EHR data. This directed graph was fed into a graph attention network and then used to predict a patient’s likelihood of heart failure <span class="citation" data-cites="10nDTiETi">[<a href="#ref-10nDTiETi" role="doc-biblioref">119</a>]</span>. Other approaches have used graph attention models to perform clinical tasks such as drug safety recommendations <span class="citation" data-cites="8vj5v8un">[<a href="#ref-8vj5v8un" role="doc-biblioref">156</a>]</span> and patient diagnoses <span class="citation" data-cites="QNJ3b5bY">[<a href="#ref-QNJ3b5bY" role="doc-biblioref">198</a>]</span>.</p>
<p>Knowledge graphs have shown promising results when used for clinical applications; however, there is still room for improvement. Most approaches have run into the common problem with missing data from EHR <span class="citation" data-cites="10nDTiETi aLsdEzlV 8vj5v8un">[<a href="#ref-10nDTiETi" role="doc-biblioref">119</a>,<a href="#ref-aLsdEzlV" role="doc-biblioref">155</a>,<a href="#ref-8vj5v8un" role="doc-biblioref">156</a>]</span>. Future directions consist of designing algorithms that can fill in this missing data gap or construct models that can take missing data into account.</p>
<h2 id="conclusion">Conclusion</h2>
<ol type="1">
<li>Summarize discussed positives and pitfalls</li>
<li>Leave some open ended questions yet to be explored</li>
<li>Will come into play as I write this review paper</li>
</ol>
<h2 id="references" class="page_break_before">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" role="doc-bibliography">
<div id="ref-DjhSdWbc">
<p>1. <strong>Node Classification in Social Networks</strong><br />
Smriti Bhagat, Graham Cormode, S. Muthukrishnan<br />
<em>Social Network Data Analytics</em> (2011) <a href="https://doi.org/fjj48w">https://doi.org/fjj48w</a><br />
DOI: <a href="https://doi.org/10.1007/978-1-4419-8462-3_5">10.1007/978-1-4419-8462-3_5</a></p>
</div>
<div id="ref-Eqbsazq5">
<p>2. <strong>Network Embedding Based Recommendation Method in Social Networks</strong><br />
Yufei Wen, Lei Guo, Zhumin Chen, Jun Ma<br />
<em>Companion of the The Web Conference 2018 on The Web Conference 2018 - WWW ’18</em> (2018) <a href="https://doi.org/gf6rtt">https://doi.org/gf6rtt</a><br />
DOI: <a href="https://doi.org/10.1145/3184558.3186904">10.1145/3184558.3186904</a></p>
</div>
<div id="ref-N0gUhlt9">
<p>3. <strong>Open Question Answering with Weakly Supervised Embedding Models</strong><br />
Antoine Bordes, Jason Weston, Nicolas Usunier<br />
<em>arXiv</em> (2014-04-16) <a href="https://arxiv.org/abs/1404.4326v1">https://arxiv.org/abs/1404.4326v1</a></p>
</div>
<div id="ref-s8ydThMc">
<p>4. <strong>Neural Network-based Question Answering over Knowledge Graphs on Word and Character Level</strong><br />
Denis Lukovnikov, Asja Fischer, Jens Lehmann, Sören Auer<br />
<em>Proceedings of the 26th International Conference on World Wide Web - WWW ’17</em> (2017) <a href="https://doi.org/gfv8hp">https://doi.org/gfv8hp</a><br />
DOI: <a href="https://doi.org/10.1145/3038912.3052675">10.1145/3038912.3052675</a></p>
</div>
<div id="ref-GI2y7kMc">
<p>5. <strong>Towards integrative gene prioritization in Alzheimer’s disease.</strong><br />
Jang H Lee, Graciela H Gonzalez<br />
<em>Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing</em> (2011) <a href="https://www.ncbi.nlm.nih.gov/pubmed/21121028">https://www.ncbi.nlm.nih.gov/pubmed/21121028</a><br />
DOI: <a href="https://doi.org/10.1142/9789814335058_0002">10.1142/9789814335058_0002</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21121028">21121028</a></p>
</div>
<div id="ref-Oi5yRd0v">
<p>6. <strong>PhenoGeneRanker: A Tool for Gene Prioritization Using Complete Multiplex Heterogeneous Networks</strong><br />
Cagatay Dursun, Naoki Shimoyama, Mary Shimoyama, Michael Schläppi, Serdar Bozdag<br />
<em>Cold Spring Harbor Laboratory</em> (2019-05-27) <a href="https://doi.org/gf6rtr">https://doi.org/gf6rtr</a><br />
DOI: <a href="https://doi.org/10.1101/651000">10.1101/651000</a></p>
</div>
<div id="ref-15k4Xz0i3">
<p>7. <strong>Biological Random Walks: Integrating heterogeneous data in disease gene prioritization</strong><br />
Michele Gentili, Leonardo Martini, Manuela Petti, Lorenzo Farina, Luca Becchetti<br />
<em>2019 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)</em> (2019-07) <a href="https://doi.org/gf6rts">https://doi.org/gf6rts</a><br />
DOI: <a href="https://doi.org/10.1109/cibcb.2019.8791472">10.1109/cibcb.2019.8791472</a></p>
</div>
<div id="ref-1D9FTzRBg">
<p>8. <strong>Semantic Disease Gene Embeddings (SmuDGE): phenotype-based disease gene prioritization without phenotypes</strong><br />
Mona Alshahrani, Robert Hoehndorf<br />
<em>Bioinformatics</em> (2018-09-01) <a href="https://doi.org/gd9k8n">https://doi.org/gd9k8n</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bty559">10.1093/bioinformatics/bty559</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30423077">30423077</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129260">PMC6129260</a></p>
</div>
<div id="ref-O21tn8vf">
<p>9. <strong>Systematic integration of biomedical knowledge prioritizes drugs for repurposing</strong><br />
Daniel Scott Himmelstein, Antoine Lizee, Christine Hessler, Leo Brueggeman, Sabrina L Chen, Dexter Hadley, Ari Green, Pouya Khankhanian, Sergio E Baranzini<br />
<em>eLife</em> (2017-09-22) <a href="https://doi.org/cdfk">https://doi.org/cdfk</a><br />
DOI: <a href="https://doi.org/10.7554/elife.26726">10.7554/elife.26726</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28936969">28936969</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5640425">PMC5640425</a></p>
</div>
<div id="ref-15GxqZyO8">
<p>10. <strong>Assessing Drug Target Association Using Semantic Linked Data</strong><br />
Bin Chen, Ying Ding, David J. Wild<br />
<em>PLoS Computational Biology</em> (2012-07-05) <a href="https://doi.org/rn6">https://doi.org/rn6</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1002574">10.1371/journal.pcbi.1002574</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22859915">22859915</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3390390">PMC3390390</a></p>
</div>
<div id="ref-V9M93in">
<p>11. <strong>Towards a definition of knowledge graphs</strong><br />
Lisa Ehrlinger, Wolfram Wöß<br />
<em>SEMANTiCS</em> (2016)</p>
</div>
<div id="ref-5gG8hwv7">
<p>12. <strong>DISEASES: Text mining and data integration of disease–gene associations</strong><br />
Sune Pletscher-Frankild, Albert Pallejà, Kalliopi Tsafou, Janos X. Binder, Lars Juhl Jensen<br />
<em>Methods</em> (2015-03) <a href="https://doi.org/f3mn6s">https://doi.org/f3mn6s</a><br />
DOI: <a href="https://doi.org/10.1016/j.ymeth.2014.11.020">10.1016/j.ymeth.2014.11.020</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25484339">25484339</a></p>
</div>
<div id="ref-1FI8iuYiQ">
<p>13. <strong>DrugBank 5.0: a major update to the DrugBank database for 2018</strong><br />
David S Wishart, Yannick D Feunang, An C Guo, Elvis J Lo, Ana Marcu, Jason R Grant, Tanvir Sajed, Daniel Johnson, Carin Li, Zinat Sayeeda, … Michael Wilson<br />
<em>Nucleic Acids Research</em> (2017-11-08) <a href="https://doi.org/gcwtzk">https://doi.org/gcwtzk</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gkx1037">10.1093/nar/gkx1037</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29126136">29126136</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5753335">PMC5753335</a></p>
</div>
<div id="ref-kBHNhSma">
<p>14. <strong>A network integration approach for drug-target interaction prediction and computational drug repositioning from heterogeneous information</strong><br />
Yunan Luo, Xinbin Zhao, Jingtian Zhou, Jinglin Yang, Yanqing Zhang, Wenhua Kuang, Jian Peng, Ligong Chen, Jianyang Zeng<br />
<em>Nature Communications</em> (2017-09-18) <a href="https://doi.org/gbxwrc">https://doi.org/gbxwrc</a><br />
DOI: <a href="https://doi.org/10.1038/s41467-017-00680-8">10.1038/s41467-017-00680-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28924171">28924171</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5603535">PMC5603535</a></p>
</div>
<div id="ref-tIGJl1ES">
<p>15. <strong>Inferring new indications for approved drugs via random walk on drug-disease heterogenous networks</strong><br />
Hui Liu, Yinglong Song, Jihong Guan, Libo Luo, Ziheng Zhuang<br />
<em>BMC Bioinformatics</em> (2016-12) <a href="https://doi.org/gf6v27">https://doi.org/gf6v27</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-016-1336-7">10.1186/s12859-016-1336-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28155639">28155639</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5259862">PMC5259862</a></p>
</div>
<div id="ref-BTEcMH0X">
<p>16. <strong>Finding disease similarity based on implicit semantic similarity</strong><br />
Sachin Mathur, Deendayal Dinakarpandian<br />
<em>Journal of Biomedical Informatics</em> (2012-04) <a href="https://doi.org/b7b3tw">https://doi.org/b7b3tw</a><br />
DOI: <a href="https://doi.org/10.1016/j.jbi.2011.11.017">10.1016/j.jbi.2011.11.017</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22166490">22166490</a></p>
</div>
<div id="ref-6Vifn4pu">
<p>17. <strong>Bio2RDF: Towards a mashup to build bioinformatics knowledge systems</strong><br />
François Belleau, Marc-Alexandre Nolin, Nicole Tourigny, Philippe Rigault, Jean Morissette<br />
<em>Journal of Biomedical Informatics</em> (2008-10) <a href="https://doi.org/frqkq5">https://doi.org/frqkq5</a><br />
DOI: <a href="https://doi.org/10.1016/j.jbi.2008.03.004">10.1016/j.jbi.2008.03.004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18472304">18472304</a></p>
</div>
<div id="ref-gddb9uXr">
<p>18. <strong>KnowLife: a versatile approach for constructing a large knowledge graph for biomedical sciences</strong><br />
Patrick Ernst, Amy Siu, Gerhard Weikum<br />
<em>BMC Bioinformatics</em> (2015-05-14) <a href="https://doi.org/gb8w8d">https://doi.org/gb8w8d</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-015-0549-5">10.1186/s12859-015-0549-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25971816">25971816</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4448285">PMC4448285</a></p>
</div>
<div id="ref-rxaBUglG">
<p>19. <strong>Constructing biomedical domain-specific knowledge graph with minimum supervision</strong><br />
Jianbo Yuan, Zhiwei Jin, Han Guo, Hongxia Jin, Xianchao Zhang, Tristram Smith, Jiebo Luo<br />
<em>Knowledge and Information Systems</em> (2019-03-23) <a href="https://doi.org/gf6v26">https://doi.org/gf6v26</a><br />
DOI: <a href="https://doi.org/10.1007/s10115-019-01351-4">10.1007/s10115-019-01351-4</a></p>
</div>
<div id="ref-ibJfUvEe">
<p>20. <strong>Feature assisted stacked attentive shortest dependency path based Bi-LSTM model for protein–protein interaction</strong><br />
Shweta Yadav, Asif Ekbal, Sriparna Saha, Ankit Kumar, Pushpak Bhattacharyya<br />
<em>Knowledge-Based Systems</em> (2019-02) <a href="https://doi.org/gf4788">https://doi.org/gf4788</a><br />
DOI: <a href="https://doi.org/10.1016/j.knosys.2018.11.020">10.1016/j.knosys.2018.11.020</a></p>
</div>
<div id="ref-GjM2NbnC">
<p>21. <strong>Biological Databases- Integration of Life Science Data</strong><br />
Nishant Toomula, Arun Kumar, Sathish Kumar D, Vijaya Shanti Bheemidi<br />
<em>Journal of Computer Science &amp; Systems Biology</em> (2012) <a href="https://doi.org/gf8qcb">https://doi.org/gf8qcb</a><br />
DOI: <a href="https://doi.org/10.4172/jcsb.1000081">10.4172/jcsb.1000081</a></p>
</div>
<div id="ref-pfquADl5">
<p>22. <strong>COSMIC: somatic cancer genetics at high-resolution</strong><br />
Simon A. Forbes, David Beare, Harry Boutselakis, Sally Bamford, Nidhi Bindal, John Tate, Charlotte G. Cole, Sari Ward, Elisabeth Dawson, Laura Ponting, … Peter J. Campbell<br />
<em>Nucleic Acids Research</em> (2016-11-28) <a href="https://doi.org/f9v865">https://doi.org/f9v865</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gkw1121">10.1093/nar/gkw1121</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27899578">27899578</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5210583">PMC5210583</a></p>
</div>
<div id="ref-1E72FZcIm">
<p>23. <strong>COSMIC: the Catalogue Of Somatic Mutations In Cancer</strong><br />
John G Tate, Sally Bamford, Harry C Jubb, Zbyslaw Sondka, David M Beare, Nidhi Bindal, Harry Boutselakis, Charlotte G Cole, Celestino Creatore, Elisabeth Dawson, … Simon A Forbes<br />
<em>Nucleic Acids Research</em> (2018-10-29) <a href="https://doi.org/gf9hxg">https://doi.org/gf9hxg</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gky1015">10.1093/nar/gky1015</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30371878">30371878</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323903">PMC6323903</a></p>
</div>
<div id="ref-5TLcy6Yl">
<p>24. <strong>Recurated protein interaction datasets</strong><br />
Lukasz Salwinski, Luana Licata, Andrew Winter, David Thorneycroft, Jyoti Khadake, Arnaud Ceol, Andrew Chatr Aryamontri, Rose Oughtred, Michael Livstone, Lorrie Boucher, … Henning Hermjakob<br />
<em>Nature Methods</em> (2009-12) <a href="https://doi.org/fgvkmf">https://doi.org/fgvkmf</a><br />
DOI: <a href="https://doi.org/10.1038/nmeth1209-860">10.1038/nmeth1209-860</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19935838">19935838</a></p>
</div>
<div id="ref-1BnoByjXH">
<p>25. <strong>Literature-curated protein interaction datasets</strong><br />
Michael E Cusick, Haiyuan Yu, Alex Smolyar, Kavitha Venkatesan, Anne-Ruxandra Carvunis, Nicolas Simonis, Jean-François Rual, Heather Borick, Pascal Braun, Matija Dreze, … Marc Vidal<br />
<em>Nature Methods</em> (2008-12-30) <a href="https://doi.org/d4j62p">https://doi.org/d4j62p</a><br />
DOI: <a href="https://doi.org/10.1038/nmeth.1284">10.1038/nmeth.1284</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19116613">19116613</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2683745">PMC2683745</a></p>
</div>
<div id="ref-OELNNm08">
<p>26. <strong>Curation accuracy of model organism databases</strong><br />
I. M. Keseler, M. Skrzypek, D. Weerasinghe, A. Y. Chen, C. Fulcher, G.-W. Li, K. C. Lemmer, K. M. Mladinich, E. D. Chow, G. Sherlock, P. D. Karp<br />
<em>Database</em> (2014-06-12) <a href="https://doi.org/gf63jz">https://doi.org/gf63jz</a><br />
DOI: <a href="https://doi.org/10.1093/database/bau058">10.1093/database/bau058</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24923819">24923819</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4207230">PMC4207230</a></p>
</div>
<div id="ref-yjdNa04s">
<p>27. <strong>OMIM.org: Online Mendelian Inheritance in Man (OMIM®), an online catalog of human genes and genetic disorders</strong><br />
Joanna S. Amberger, Carol A. Bocchini, François Schiettecatte, Alan F. Scott, Ada Hamosh<br />
<em>Nucleic Acids Research</em> (2014-11-26) <a href="https://doi.org/gf8qb6">https://doi.org/gf8qb6</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gku1205">10.1093/nar/gku1205</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25428349">25428349</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4383985">PMC4383985</a></p>
</div>
<div id="ref-d3rG3TXb">
<p>28. <strong>Textpresso Central: a customizable platform for searching, text mining, viewing, and curating biomedical literature</strong><br />
H.-M. Müller, K. M. Van Auken, Y. Li, P. W. Sternberg<br />
<em>BMC Bioinformatics</em> (2018-03-09) <a href="https://doi.org/gf7rbz">https://doi.org/gf7rbz</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-018-2103-8">10.1186/s12859-018-2103-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29523070">29523070</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5845379">PMC5845379</a></p>
</div>
<div id="ref-16P0HRKom">
<p>29. <strong>Text mining and expert curation to develop a database on psychiatric diseases and their genes</strong><br />
Alba Gutiérrez-Sacristán, Àlex Bravo, Marta Portero-Tresserra, Olga Valverde, Antonio Armario, M. C. Blanco-Gandía, Adriana Farré, Lierni Fernández-Ibarrondo, Francina Fonseca, Jesús Giraldo, … Laura I. Furlong<br />
<em>Database</em> (2017-01-01) <a href="https://doi.org/gf8qb5">https://doi.org/gf8qb5</a><br />
DOI: <a href="https://doi.org/10.1093/database/bax043">10.1093/database/bax043</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29220439">29220439</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5502359">PMC5502359</a></p>
</div>
<div id="ref-UdzvLgBM">
<p>30. <strong>Manual curation is not sufficient for annotation of genomic databases</strong><br />
William A. Baumgartner Jr, K. Bretonnel Cohen, Lynne M. Fox, George Acquaah-Mensah, Lawrence Hunter<br />
<em>Bioinformatics</em> (2007-07-01) <a href="https://doi.org/dtck86">https://doi.org/dtck86</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btm229">10.1093/bioinformatics/btm229</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/17646325">17646325</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2516305">PMC2516305</a></p>
</div>
<div id="ref-vYYWSlK2">
<p>31. <strong>The rate of growth in scientific publication and the decline in coverage provided by Science Citation Index</strong><br />
Peder Olesen Larsen, Markus von Ins<br />
<em>Scientometrics</em> (2010-03-10) <a href="https://doi.org/c4hb8r">https://doi.org/c4hb8r</a><br />
DOI: <a href="https://doi.org/10.1007/s11192-010-0202-z">10.1007/s11192-010-0202-z</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20700371">20700371</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2909426">PMC2909426</a></p>
</div>
<div id="ref-17LLVYRDg">
<p>32. <strong>Semi-automatic semantic annotation of PubMed queries: A study on quality, efficiency, satisfaction</strong><br />
Aurélie Névéol, Rezarta Islamaj Doğan, Zhiyong Lu<br />
<em>Journal of Biomedical Informatics</em> (2011-04) <a href="https://doi.org/bq34sj">https://doi.org/bq34sj</a><br />
DOI: <a href="https://doi.org/10.1016/j.jbi.2010.11.001">10.1016/j.jbi.2010.11.001</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21094696">21094696</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3063330">PMC3063330</a></p>
</div>
<div id="ref-iJxqfYog">
<p>33. <strong>Assisting manual literature curation for protein-protein interactions using BioQRator</strong><br />
D. Kwon, S. Kim, S.-Y. Shin, A. Chatr-aryamontri, W. J. Wilbur<br />
<em>Database</em> (2014-07-22) <a href="https://doi.org/gf7hm3">https://doi.org/gf7hm3</a><br />
DOI: <a href="https://doi.org/10.1093/database/bau067">10.1093/database/bau067</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25052701">25052701</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4105708">PMC4105708</a></p>
</div>
<div id="ref-us6gXxVp">
<p>34. <strong>Argo: an integrative, interactive, text mining-based workbench supporting curation</strong><br />
R. Rak, A. Rowley, W. Black, S. Ananiadou<br />
<em>Database</em> (2012-03-20) <a href="https://doi.org/h5d">https://doi.org/h5d</a><br />
DOI: <a href="https://doi.org/10.1093/database/bas010">10.1093/database/bas010</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22434844">22434844</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3308166">PMC3308166</a></p>
</div>
<div id="ref-kHKmKy23">
<p>35. <strong>CurEx</strong><br />
Michael Loster, Felix Naumann, Jan Ehmueller, Benjamin Feldmann<br />
<em>Proceedings of the 27th ACM International Conference on Information and Knowledge Management - CIKM ’18</em> (2018) <a href="https://doi.org/gf8qb8">https://doi.org/gf8qb8</a><br />
DOI: <a href="https://doi.org/10.1145/3269206.3269229">10.1145/3269206.3269229</a></p>
</div>
<div id="ref-17KVV4Pum">
<p>36. <strong>Re-curation and rational enrichment of knowledge graphs in Biological Expression Language</strong><br />
Charles Tapley Hoyt, Daniel Domingo-Fernández, Rana Aldisi, Lingling Xu, Kristian Kolpeja, Sandra Spalek, Esther Wollert, John Bachman, Benjamin M Gyori, Patrick Greene, Martin Hofmann-Apitius<br />
<em>Database</em> (2019-01-01) <a href="https://doi.org/gf7hm4">https://doi.org/gf7hm4</a><br />
DOI: <a href="https://doi.org/10.1093/database/baz068">10.1093/database/baz068</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31225582">31225582</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6587072">PMC6587072</a></p>
</div>
<div id="ref-SHPz84Z7">
<p>37. <strong>LocText: relation extraction of protein localizations to assist database curation</strong><br />
Juan Miguel Cejuela, Shrikant Vinchurkar, Tatyana Goldberg, Madhukar Sollepura Prabhu Shankar, Ashish Baghudana, Aleksandar Bojchevski, Carsten Uhlig, André Ofner, Pandu Raharja-Liu, Lars Juhl Jensen, Burkhard Rost<br />
<em>BMC Bioinformatics</em> (2018-01-17) <a href="https://doi.org/gf8qb9">https://doi.org/gf8qb9</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-018-2021-9">10.1186/s12859-018-2021-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29343218">29343218</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5773052">PMC5773052</a></p>
</div>
<div id="ref-KX7N360G">
<p>38. <strong>Evaluating the impact of pre-annotation on annotation speed and potential bias: natural language processing gold standard development for clinical named entity recognition in clinical trial announcements</strong><br />
Todd Lingren, Louise Deleger, Katalin Molnar, Haijun Zhai, Jareen Meinzen-Derr, Megan Kaiser, Laura Stoutenborough, Qi Li, Imre Solti<br />
<em>Journal of the American Medical Informatics Association</em> (2014-05) <a href="https://doi.org/f5zggh">https://doi.org/f5zggh</a><br />
DOI: <a href="https://doi.org/10.1136/amiajnl-2013-001837">10.1136/amiajnl-2013-001837</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24001514">24001514</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3994857">PMC3994857</a></p>
</div>
<div id="ref-umenx8Nh">
<p>39. <strong>iSimp in BioC standard format: enhancing the interoperability of a sentence simplification system</strong><br />
Y. Peng, C. O. Tudor, M. Torii, C. H. Wu, K. Vijay-Shanker<br />
<em>Database</em> (2014-05-21) <a href="https://doi.org/gf9hxf">https://doi.org/gf9hxf</a><br />
DOI: <a href="https://doi.org/10.1093/database/bau038">10.1093/database/bau038</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24850848">24850848</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4028706">PMC4028706</a></p>
</div>
<div id="ref-aJL1tPyy">
<p>40. <strong>BioSimplify: an open source sentence simplification engine to improve recall in automatic biomedical information extraction.</strong><br />
Siddhartha Jonnalagadda, Graciela Gonzalez<br />
<em>AMIA … Annual Symposium proceedings. AMIA Symposium</em> (2010-11-13) <a href="https://www.ncbi.nlm.nih.gov/pubmed/21346999">https://www.ncbi.nlm.nih.gov/pubmed/21346999</a><br />
PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21346999">21346999</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041388">PMC3041388</a></p>
</div>
<div id="ref-Y2DcwTrA">
<p>41. <strong>The EU-ADR corpus: Annotated drugs, diseases, targets, and their relationships</strong><br />
Erik M. van Mulligen, Annie Fourrier-Reglat, David Gurwitz, Mariam Molokhia, Ainhoa Nieto, Gianluca Trifiro, Jan A. Kors, Laura I. Furlong<br />
<em>Journal of Biomedical Informatics</em> (2012-10) <a href="https://doi.org/f36vn6">https://doi.org/f36vn6</a><br />
DOI: <a href="https://doi.org/10.1016/j.jbi.2012.04.004">10.1016/j.jbi.2012.04.004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22554700">22554700</a></p>
</div>
<div id="ref-YWh6tPj">
<p>42. <strong>Comparative experiments on learning information extractors for proteins and their interactions</strong><br />
Razvan Bunescu, Ruifang Ge, Rohit J. Kate, Edward M. Marcotte, Raymond J. Mooney, Arun K. Ramani, Yuk Wah Wong<br />
<em>Artificial Intelligence in Medicine</em> (2005-02) <a href="https://doi.org/dhztpn">https://doi.org/dhztpn</a><br />
DOI: <a href="https://doi.org/10.1016/j.artmed.2004.07.016">10.1016/j.artmed.2004.07.016</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/15811782">15811782</a></p>
</div>
<div id="ref-MTIt6gSA">
<p>43. <strong>A Unified Active Learning Framework for Biomedical Relation Extraction</strong><br />
Hong-Tao Zhang, Min-Lie Huang, Xiao-Yan Zhu<br />
<em>Journal of Computer Science and Technology</em> (2012-11) <a href="https://doi.org/gf8qb4">https://doi.org/gf8qb4</a><br />
DOI: <a href="https://doi.org/10.1007/s11390-012-1306-0">10.1007/s11390-012-1306-0</a></p>
</div>
<div id="ref-u7vVtngU">
<p>44. <strong>Entrez Gene: gene-centered information at NCBI</strong><br />
D. Maglott, J. Ostell, K. D. Pruitt, T. Tatusova<br />
<em>Nucleic Acids Research</em> (2010-11-28) <a href="https://doi.org/fsjcqz">https://doi.org/fsjcqz</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gkq1237">10.1093/nar/gkq1237</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21115458">21115458</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013746">PMC3013746</a></p>
</div>
<div id="ref-1ZE22clL">
<p>45. <strong>UniProt: a worldwide hub of protein knowledge</strong><em>Nucleic Acids Research</em> (2018-11-05) <a href="https://doi.org/gfwqck">https://doi.org/gfwqck</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gky1049">10.1093/nar/gky1049</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30395287">30395287</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323992">PMC6323992</a></p>
</div>
<div id="ref-qbo1ouMs">
<p>46. <strong>Pharmacogenomics Knowledge for Personalized Medicine</strong><br />
M Whirl-Carrillo, EM McDonagh, JM Hebert, L Gong, K Sangkuhl, CF Thorn, RB Altman, TE Klein<br />
<em>Clinical Pharmacology &amp; Therapeutics</em> (2012-10) <a href="https://doi.org/gdnfzr">https://doi.org/gdnfzr</a><br />
DOI: <a href="https://doi.org/10.1038/clpt.2012.96">10.1038/clpt.2012.96</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22992668">22992668</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3660037">PMC3660037</a></p>
</div>
<div id="ref-kFAyvOpe">
<p>47. <strong>The BioGRID interaction database: 2013 update</strong><br />
Andrew Chatr-aryamontri, Bobby-Joe Breitkreutz, Sven Heinicke, Lorrie Boucher, Andrew Winter, Chris Stark, Julie Nixon, Lindsay Ramage, Nadine Kolas, Lara O’Donnell, … Mike Tyers<br />
<em>Nucleic Acids Research</em> (2012-11-30) <a href="https://doi.org/f4jmz4">https://doi.org/f4jmz4</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gks1158">10.1093/nar/gks1158</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23203989">23203989</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3531226">PMC3531226</a></p>
</div>
<div id="ref-axd6eJec">
<p>48. <strong>The Comparative Toxicogenomics Database: update 2019</strong><br />
Allan Peter Davis, Cynthia J Grondin, Robin J Johnson, Daniela Sciaky, Roy McMorran, Jolene Wiegers, Thomas C Wiegers, Carolyn J Mattingly<br />
<em>Nucleic Acids Research</em> (2018-09-24) <a href="https://doi.org/gf8qb7">https://doi.org/gf8qb7</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gky868">10.1093/nar/gky868</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30247620">30247620</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323936">PMC6323936</a></p>
</div>
<div id="ref-1ByMfX8Y1">
<p>49. <strong>CARD 2017: expansion and model-centric curation of the comprehensive antibiotic resistance database</strong><br />
Baofeng Jia, Amogelang R. Raphenya, Brian Alcock, Nicholas Waglechner, Peiyao Guo, Kara K. Tsang, Briony A. Lago, Biren M. Dave, Sheldon Pereira, Arjun N. Sharma, … Andrew G. McArthur<br />
<em>Nucleic Acids Research</em> (2016-10-26) <a href="https://doi.org/f9wbjs">https://doi.org/f9wbjs</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gkw1004">10.1093/nar/gkw1004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27789705">27789705</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5210516">PMC5210516</a></p>
</div>
<div id="ref-1FZWpEoss">
<p>50. <strong>OMIM.org: leveraging knowledge across phenotype-gene relationships.</strong><br />
Joanna S Amberger, Carol A Bocchini, Alan F Scott, Ada Hamosh<br />
<em>Nucleic acids research</em> (2019-01-08) <a href="https://www.ncbi.nlm.nih.gov/pubmed/30445645">https://www.ncbi.nlm.nih.gov/pubmed/30445645</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gky1151">10.1093/nar/gky1151</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30445645">30445645</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323937">PMC6323937</a></p>
</div>
<div id="ref-i7KpvzCo">
<p>51. <strong>LPTK: a linguistic pattern-aware dependency tree kernel approach for the BioCreative VI CHEMPROT task</strong><br />
Neha Warikoo, Yung-Chun Chang, Wen-Lian Hsu<br />
<em>Database</em> (2018-01-01) <a href="https://doi.org/gfhjr6">https://doi.org/gfhjr6</a><br />
DOI: <a href="https://doi.org/10.1093/database/bay108">10.1093/database/bay108</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30346607">30346607</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6196310">PMC6196310</a></p>
</div>
<div id="ref-3j1T67vB">
<p>52. <strong>DTMiner: identification of potential disease targets through biomedical literature mining</strong><br />
Dong Xu, Meizhuo Zhang, Yanping Xie, Fan Wang, Ming Chen, Kenny Q. Zhu, Jia Wei<br />
<em>Bioinformatics</em> (2016-08-09) <a href="https://doi.org/f9nw36">https://doi.org/f9nw36</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btw503">10.1093/bioinformatics/btw503</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27506226">27506226</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5181534">PMC5181534</a></p>
</div>
<div id="ref-iiQkIqUX">
<p>53. <strong>Exploiting graph kernels for high performance biomedical relation extraction</strong><br />
Nagesh C. Panyam, Karin Verspoor, Trevor Cohn, Kotagiri Ramamohanarao<br />
<em>Journal of Biomedical Semantics</em> (2018-01-30) <a href="https://doi.org/gf49nn">https://doi.org/gf49nn</a><br />
DOI: <a href="https://doi.org/10.1186/s13326-017-0168-3">10.1186/s13326-017-0168-3</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29382397">29382397</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5791373">PMC5791373</a></p>
</div>
<div id="ref-66vfJAIo">
<p>54. <strong>iSimp in BioC standard format: enhancing the interoperability of a sentence simplification system.</strong><br />
Yifan Peng, Catalina O Tudor, Manabu Torii, Cathy H Wu, K Vijay-Shanker<br />
<em>Database : the journal of biological databases and curation</em> (2014-05-21) <a href="https://www.ncbi.nlm.nih.gov/pubmed/24850848">https://www.ncbi.nlm.nih.gov/pubmed/24850848</a><br />
DOI: <a href="https://doi.org/10.1093/database/bau038">10.1093/database/bau038</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24850848">24850848</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4028706">PMC4028706</a></p>
</div>
<div id="ref-15I4QE3J">
<p>55. <strong>BELMiner: adapting a rule-based relation extraction system to extract biological expression language statements from bio-medical literature evidence sentences</strong><br />
K. E. Ravikumar, Majid Rastegar-Mojarad, Hongfang Liu<br />
<em>Database</em> (2017-01-01) <a href="https://doi.org/gf7rbx">https://doi.org/gf7rbx</a><br />
DOI: <a href="https://doi.org/10.1093/database/baw156">10.1093/database/baw156</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28365720">28365720</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5467463">PMC5467463</a></p>
</div>
<div id="ref-7PCrlbDi">
<p>56. <strong>A generalizable NLP framework for fast development of pattern-based biomedical relation extraction systems</strong><br />
Yifan Peng, Manabu Torii, Cathy H Wu, K Vijay-Shanker<br />
<em>BMC Bioinformatics</em> (2014-08-23) <a href="https://doi.org/f6rndz">https://doi.org/f6rndz</a><br />
DOI: <a href="https://doi.org/10.1186/1471-2105-15-285">10.1186/1471-2105-15-285</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25149151">25149151</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4262219">PMC4262219</a></p>
</div>
<div id="ref-J0VF6x1n">
<p>57. <strong>Construction of phosphorylation interaction networks by text mining of full-length articles using the eFIP system</strong><br />
Catalina O. Tudor, Karen E. Ross, Gang Li, K. Vijay-Shanker, Cathy H. Wu, Cecilia N. Arighi<br />
<em>Database</em> (2015-01-01) <a href="https://doi.org/gf8fpt">https://doi.org/gf8fpt</a><br />
DOI: <a href="https://doi.org/10.1093/database/bav020">10.1093/database/bav020</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25833953">25833953</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4381107">PMC4381107</a></p>
</div>
<div id="ref-1HnOwZ1Xq">
<p>58. <strong>miRTex: A Text Mining System for miRNA-Gene Relation Extraction</strong><br />
Gang Li, Karen E. Ross, Cecilia N. Arighi, Yifan Peng, Cathy H. Wu, K. Vijay-Shanker<br />
<em>PLOS Computational Biology</em> (2015-09-25) <a href="https://doi.org/f75mwb">https://doi.org/f75mwb</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1004391">10.1371/journal.pcbi.1004391</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26407127">26407127</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4583433">PMC4583433</a></p>
</div>
<div id="ref-OnvaFHG9">
<p>59. <strong>LimTox: a web tool for applied text mining of adverse event and toxicity associations of compounds, drugs and genes</strong><br />
Andres Cañada, Salvador Capella-Gutierrez, Obdulia Rabal, Julen Oyarzabal, Alfonso Valencia, Martin Krallinger<br />
<em>Nucleic Acids Research</em> (2017-05-22) <a href="https://doi.org/gf479h">https://doi.org/gf479h</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gkx462">10.1093/nar/gkx462</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28531339">28531339</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5570141">PMC5570141</a></p>
</div>
<div id="ref-dRQuIwpJ">
<p>60. <strong>DiMeX: A Text Mining System for Mutation-Disease Association Extraction</strong><br />
A. S. M. Ashique Mahmood, Tsung-Jung Wu, Raja Mazumder, K. Vijay-Shanker<br />
<em>PLOS ONE</em> (2016-04-13) <a href="https://doi.org/f8xktj">https://doi.org/f8xktj</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pone.0152725">10.1371/journal.pone.0152725</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27073839">27073839</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4830514">PMC4830514</a></p>
</div>
<div id="ref-23i6gRBE">
<p>61. <strong>Automated extraction of mutation data from the literature: application of MuteXt to G protein-coupled receptors and nuclear hormone receptors</strong><br />
F. Horn, A. L. Lau, F. E. Cohen<br />
<em>Bioinformatics</em> (2004-01-22) <a href="https://doi.org/d7cjgj">https://doi.org/d7cjgj</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btg449">10.1093/bioinformatics/btg449</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/14990452">14990452</a></p>
</div>
<div id="ref-1avvFjJ9">
<p>62. <strong>Large-scale extraction of accurate drug-disease treatment pairs from biomedical literature for drug repurposing</strong><br />
Rong Xu, QuanQiu Wang<br />
<em>BMC Bioinformatics</em> (2013-06-06) <a href="https://doi.org/gb8v3k">https://doi.org/gb8v3k</a><br />
DOI: <a href="https://doi.org/10.1186/1471-2105-14-181">10.1186/1471-2105-14-181</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23742147">23742147</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3702428">PMC3702428</a></p>
</div>
<div id="ref-KEkjqdB0">
<p>63. <strong>RLIMS-P 2.0: A Generalizable Rule-Based Information Extraction System for Literature Mining of Protein Phosphorylation Information</strong><br />
Manabu Torii, Cecilia N. Arighi, Gang Li, Qinghua Wang, Cathy H. Wu, K. Vijay-Shanker<br />
<em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> (2015-01-01) <a href="https://doi.org/gf8fpv">https://doi.org/gf8fpv</a><br />
DOI: <a href="https://doi.org/10.1109/tcbb.2014.2372765">10.1109/tcbb.2014.2372765</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26357075">26357075</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4568560">PMC4568560</a></p>
</div>
<div id="ref-jg0TGCov">
<p>64. <strong>PKDE4J: Entity and relation extraction for public knowledge discovery</strong><br />
Min Song, Won Chul Kim, Dahee Lee, Go Eun Heo, Keun Young Kang<br />
<em>Journal of Biomedical Informatics</em> (2015-10) <a href="https://doi.org/f7v7jj">https://doi.org/f7v7jj</a><br />
DOI: <a href="https://doi.org/10.1016/j.jbi.2015.08.008">10.1016/j.jbi.2015.08.008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26277115">26277115</a></p>
</div>
<div id="ref-1EvoylLWK">
<p>65. <strong>PhpSyntaxTree tool</strong><br />
A Eisenbach, M Eisenbach<br />
(2006)</p>
</div>
<div id="ref-10i1qMFbL">
<p>66. <strong>Spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing</strong><br />
Matthew Honnibal, Ines Montani<br />
<em>To appear</em> (2017)</p>
</div>
<div id="ref-iihNCsNX">
<p>67. <strong>STRING v9.1: protein-protein interaction networks, with increased coverage and integration</strong><br />
Andrea Franceschini, Damian Szklarczyk, Sune Frankild, Michael Kuhn, Milan Simonovic, Alexander Roth, Jianyi Lin, Pablo Minguez, Peer Bork, Christian von Mering, Lars J. Jensen<br />
<em>Nucleic Acids Research</em> (2012-11-29) <a href="https://doi.org/gf5kcd">https://doi.org/gf5kcd</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gks1094">10.1093/nar/gks1094</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23203871">23203871</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3531103">PMC3531103</a></p>
</div>
<div id="ref-DGlWGDEt">
<p>68. <strong>A comprehensive and quantitative comparison of text-mining in 15 million full-text articles versus their corresponding abstracts</strong><br />
David Westergaard, Hans-Henrik Stærfeldt, Christian Tønsberg, Lars Juhl Jensen, Søren Brunak<br />
<em>PLOS Computational Biology</em> (2018-02-15) <a href="https://doi.org/gcx747">https://doi.org/gcx747</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1005962">10.1371/journal.pcbi.1005962</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29447159">29447159</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5831415">PMC5831415</a></p>
</div>
<div id="ref-pLAIFXqP">
<p>69. <strong>STITCH 4: integration of protein–chemical interactions with user data</strong><br />
Michael Kuhn, Damian Szklarczyk, Sune Pletscher-Frankild, Thomas H. Blicher, Christian von Mering, Lars J. Jensen, Peer Bork<br />
<em>Nucleic Acids Research</em> (2013-11-28) <a href="https://doi.org/f5shb4">https://doi.org/f5shb4</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gkt1207">10.1093/nar/gkt1207</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24293645">24293645</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3964996">PMC3964996</a></p>
</div>
<div id="ref-CSiMoOrI">
<p>70. <strong>A global network of biomedical relationships derived from text</strong><br />
Bethany Percha, Russ B Altman<br />
<em>Bioinformatics</em> (2018-02-27) <a href="https://doi.org/gc3ndk">https://doi.org/gc3ndk</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bty114">10.1093/bioinformatics/bty114</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29490008">29490008</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6061699">PMC6061699</a></p>
</div>
<div id="ref-IGXdryzB">
<p>71. <strong>CoCoScore: context-aware co-occurrence scoring for text mining applications using distant supervision</strong><br />
Alexander Junge, Lars Juhl Jensen<br />
<em>Bioinformatics</em> (2019-06-14) <a href="https://doi.org/gf4789">https://doi.org/gf4789</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btz490">10.1093/bioinformatics/btz490</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31199464">31199464</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6956794">PMC6956794</a></p>
</div>
<div id="ref-ETC6lm7S">
<p>72. <strong>A new method for prioritizing drug repositioning candidates extracted by literature-based discovery</strong><br />
Majid Rastegar-Mojarad, Ravikumar Komandur Elayavilli, Dingcheng Li, Rashmi Prasad, Hongfang Liu<br />
<em>2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</em> (2015-11) <a href="https://doi.org/gf479j">https://doi.org/gf479j</a><br />
DOI: <a href="https://doi.org/10.1109/bibm.2015.7359766">10.1109/bibm.2015.7359766</a></p>
</div>
<div id="ref-AdKPf5EO">
<p>73. <strong>Literature Mining for the Discovery of Hidden Connections between Drugs, Genes and Diseases</strong><br />
Raoul Frijters, Marianne van Vugt, Ruben Smeets, René van Schaik, Jacob de Vlieg, Wynand Alkema<br />
<em>PLoS Computational Biology</em> (2010-09-23) <a href="https://doi.org/bhrw7x">https://doi.org/bhrw7x</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1000943">10.1371/journal.pcbi.1000943</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20885778">20885778</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2944780">PMC2944780</a></p>
</div>
<div id="ref-q9Fhy8eq">
<p>74. <strong>STRING v10: protein–protein interaction networks, integrated over the tree of life</strong><br />
Damian Szklarczyk, Andrea Franceschini, Stefan Wyder, Kristoffer Forslund, Davide Heller, Jaime Huerta-Cepas, Milan Simonovic, Alexander Roth, Alberto Santos, Kalliopi P. Tsafou, … Christian von Mering<br />
<em>Nucleic Acids Research</em> (2014-10-28) <a href="https://doi.org/f64rfn">https://doi.org/f64rfn</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gku1003">10.1093/nar/gku1003</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25352553">25352553</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4383874">PMC4383874</a></p>
</div>
<div id="ref-10tWTMIaV">
<p>75. <strong>Text Mining Genotype-Phenotype Relationships from Biomedical Literature for Database Curation and Precision Medicine</strong><br />
Ayush Singhal, Michael Simmons, Zhiyong Lu<br />
<em>PLOS Computational Biology</em> (2016-11-30) <a href="https://doi.org/f9gz4b">https://doi.org/f9gz4b</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1005017">10.1371/journal.pcbi.1005017</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27902695">27902695</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5130168">PMC5130168</a></p>
</div>
<div id="ref-16As8893j">
<p>76. <strong>Overview of the biocreative vi chemical-protein interaction track</strong><br />
Martin Krallinger, Obdulia Rabal, Saber A Akhondi, others<br />
<em>Proceedings of the sixth biocreative challenge evaluation workshop</em> (2017) <a href="https://www.semanticscholar.org/paper/Overview-of-the-BioCreative-VI-chemical-protein-Krallinger-Rabal/eed781f498b563df5a9e8a241c67d63dd1d92ad5">https://www.semanticscholar.org/paper/Overview-of-the-BioCreative-VI-chemical-protein-Krallinger-Rabal/eed781f498b563df5a9e8a241c67d63dd1d92ad5</a></p>
</div>
<div id="ref-6wNuLZWb">
<p>77. <strong>BioCreative V CDR task corpus: a resource for chemical disease relation extraction</strong><br />
Jiao Li, Yueping Sun, Robin J. Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Peter Davis, Carolyn J. Mattingly, Thomas C. Wiegers, Zhiyong Lu<br />
<em>Database</em> (2016) <a href="https://doi.org/gf5hfw">https://doi.org/gf5hfw</a><br />
DOI: <a href="https://doi.org/10.1093/database/baw068">10.1093/database/baw068</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27161011">27161011</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4860626">PMC4860626</a></p>
</div>
<div id="ref-L9IIm3Zd">
<p>78. <strong>RelEx–Relation extraction using dependency parse trees</strong><br />
K. Fundel, R. Kuffner, R. Zimmer<br />
<em>Bioinformatics</em> (2006-12-01) <a href="https://doi.org/cz7q4d">https://doi.org/cz7q4d</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btl616">10.1093/bioinformatics/btl616</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/17142812">17142812</a></p>
</div>
<div id="ref-luGt8luc">
<p>79. <strong>CoMAGC: a corpus with multi-faceted annotations of gene-cancer relations</strong><br />
Hee-Jin Lee, Sang-Hyung Shim, Mi-Ryoung Song, Hyunju Lee, Jong C Park<br />
<em>BMC Bioinformatics</em> (2013) <a href="https://doi.org/gb8v5s">https://doi.org/gb8v5s</a><br />
DOI: <a href="https://doi.org/10.1186/1471-2105-14-323">10.1186/1471-2105-14-323</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24225062">24225062</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3833657">PMC3833657</a></p>
</div>
<div id="ref-1B0lnkj35">
<p>80. <strong>Text Mining for Protein Docking</strong><br />
Varsha D. Badal, Petras J. Kundrotas, Ilya A. Vakser<br />
<em>PLOS Computational Biology</em> (2015-12-09) <a href="https://doi.org/gcvj3b">https://doi.org/gcvj3b</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1004630">10.1371/journal.pcbi.1004630</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26650466">26650466</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4674139">PMC4674139</a></p>
</div>
<div id="ref-GeCe9qfW">
<p>81. <strong>Automatic extraction of gene-disease associations from literature using joint ensemble learning</strong><br />
Balu Bhasuran, Jeyakumar Natarajan<br />
<em>PLOS ONE</em> (2018-07-26) <a href="https://doi.org/gdx63f">https://doi.org/gdx63f</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pone.0200699">10.1371/journal.pone.0200699</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30048465">30048465</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6061985">PMC6061985</a></p>
</div>
<div id="ref-hbAqN08A">
<p>82. <strong>Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research</strong><br />
Àlex Bravo, Janet Piñero, Núria Queralt-Rosinach, Michael Rautschka, Laura I Furlong<br />
<em>BMC Bioinformatics</em> (2015-02-21) <a href="https://doi.org/f7kn8s">https://doi.org/f7kn8s</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-015-0472-9">10.1186/s12859-015-0472-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25886734">25886734</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4466840">PMC4466840</a></p>
</div>
<div id="ref-vDFZcSf9">
<p>83. <strong>Deep learning</strong><br />
Ian Goodfellow, Yoshua Bengio, Aaron Courville<br />
<em>The MIT Press</em> (2016)<br />
ISBN: <a href="https://worldcat.org/isbn/0262035618,%209780262035613">0262035618, 9780262035613</a></p>
</div>
<div id="ref-BeijBSRE">
<p>84. <strong>Deep learning</strong><br />
Yann LeCun, Yoshua Bengio, Geoffrey Hinton<br />
<em>Nature</em> (2015-05) <a href="https://doi.org/bmqp">https://doi.org/bmqp</a><br />
DOI: <a href="https://doi.org/10.1038/nature14539">10.1038/nature14539</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26017442">26017442</a></p>
</div>
<div id="ref-x4dbEYer">
<p>85. <strong>Long Short-Term Memory</strong><br />
Sepp Hochreiter, Jürgen Schmidhuber<br />
<em>Neural Computation</em> (1997-11) <a href="https://doi.org/bxd65w">https://doi.org/bxd65w</a><br />
DOI: <a href="https://doi.org/10.1162/neco.1997.9.8.1735">10.1162/neco.1997.9.8.1735</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/9377276">9377276</a></p>
</div>
<div id="ref-kCSge2o8">
<p>86. <strong>Deep learning for pharmacovigilance: recurrent neural network architectures for labeling adverse drug reactions in Twitter posts</strong><br />
Anne Cocos, Alexander G Fiks, Aaron J Masino<br />
<em>Journal of the American Medical Informatics Association</em> (2017-02-22) <a href="https://doi.org/gbp9nj">https://doi.org/gbp9nj</a><br />
DOI: <a href="https://doi.org/10.1093/jamia/ocw180">10.1093/jamia/ocw180</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28339747">28339747</a></p>
</div>
<div id="ref-hEblZ1j5">
<p>87. <strong>Semantic Relations in Compound Nouns: Perspectives from Inter-Annotator Agreement</strong><br />
Yadav Prabha, Jezek Elisabetta, Bouillon Pierrette, Callahan Tiffany J., Bada Michael, Hunter Lawrence E., Cohen K. Bretonnel<br />
<em>Studies in Health Technology and Informatics</em> (2017) <a href="https://doi.org/ggmk8t">https://doi.org/ggmk8t</a><br />
DOI: <a href="https://doi.org/10.3233/978-1-61499-830-3-644">10.3233/978-1-61499-830-3-644</a></p>
</div>
<div id="ref-8lfvAUz7">
<p>88. <strong>Cross-Sentence N-ary Relation Extraction with Graph LSTMs</strong><br />
Nanyun Peng, Hoifung Poon, Chris Quirk, Kristina Toutanova, Wen-tau Yih<br />
<em>arXiv</em> (2017-08-12) <a href="https://arxiv.org/abs/1708.03743v1">https://arxiv.org/abs/1708.03743v1</a></p>
</div>
<div id="ref-8NrcroGt">
<p>89. <strong>Drug drug interaction extraction from biomedical literature using syntax convolutional neural network</strong><br />
Zhehuan Zhao, Zhihao Yang, Ling Luo, Hongfei Lin, Jian Wang<br />
<em>Bioinformatics</em> (2016-07-27) <a href="https://doi.org/f9nsq7">https://doi.org/f9nsq7</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btw486">10.1093/bioinformatics/btw486</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27466626">27466626</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5181565">PMC5181565</a></p>
</div>
<div id="ref-k4sSP5gN">
<p>90. <strong>N-ary Relation Extraction using Graph State LSTM</strong><br />
Linfeng Song, Yue Zhang, Zhiguo Wang, Daniel Gildea<br />
<em>arXiv</em> (2018-08-28) <a href="https://arxiv.org/abs/1808.09101v1">https://arxiv.org/abs/1808.09101v1</a></p>
</div>
<div id="ref-1F5aZYjOB">
<p>91. <strong>A neural joint model for entity and relation extraction from biomedical text</strong><br />
Fei Li, Meishan Zhang, Guohong Fu, Donghong Ji<br />
<em>BMC Bioinformatics</em> (2017-03-31) <a href="https://doi.org/gcgnx2">https://doi.org/gcgnx2</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-017-1609-9">10.1186/s12859-017-1609-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28359255">28359255</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5374588">PMC5374588</a></p>
</div>
<div id="ref-YYBiIF26">
<p>92. <strong>The problem of learning long-term dependencies in recurrent networks</strong><br />
Y. Bengio, P. Frasconi, P. Simard<br />
<em>IEEE International Conference on Neural Networks</em> <a href="https://doi.org/d7zs24">https://doi.org/d7zs24</a><br />
DOI: <a href="https://doi.org/10.1109/icnn.1993.298725">10.1109/icnn.1993.298725</a></p>
</div>
<div id="ref-6PiFh6Y2">
<p>93. <strong>Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) Network</strong><br />
Alex Sherstinsky<br />
<em>arXiv</em> (2018-08-09) <a href="https://arxiv.org/abs/1808.03314v5">https://arxiv.org/abs/1808.03314v5</a><br />
DOI: <a href="https://doi.org/10.1016/j.physd.2019.132306">10.1016/j.physd.2019.132306</a></p>
</div>
<div id="ref-FoztezBR">
<p>94. <strong>On the difficulty of training Recurrent Neural Networks</strong><br />
Razvan Pascanu, Tomas Mikolov, Yoshua Bengio<br />
<em>arXiv</em> (2012-11-21) <a href="https://arxiv.org/abs/1211.5063v2">https://arxiv.org/abs/1211.5063v2</a></p>
</div>
<div id="ref-anpoBunY">
<p>95. <strong>Revisiting Unreasonable Effectiveness of Data in Deep Learning Era</strong><br />
Chen Sun, Abhinav Shrivastava, Saurabh Singh, Abhinav Gupta<br />
<em>arXiv</em> (2017-07-10) <a href="https://arxiv.org/abs/1707.02968v2">https://arxiv.org/abs/1707.02968v2</a></p>
</div>
<div id="ref-1GhHIDxuW">
<p>96. <strong>Efficient Estimation of Word Representations in Vector Space</strong><br />
Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean<br />
<em>arXiv</em> (2013-01-16) <a href="https://arxiv.org/abs/1301.3781v3">https://arxiv.org/abs/1301.3781v3</a></p>
</div>
<div id="ref-u5iJzbp9">
<p>97. <strong>Distributed Representations of Words and Phrases and their Compositionality</strong><br />
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, Jeffrey Dean<br />
<em>arXiv</em> (2013-10-16) <a href="https://arxiv.org/abs/1310.4546v1">https://arxiv.org/abs/1310.4546v1</a></p>
</div>
<div id="ref-TNHJioqT">
<p>98. <strong>Deep learning for extracting protein-protein interactions from biomedical literature</strong><br />
Yifan Peng, Zhiyong Lu<br />
<em>arXiv</em> (2017-06-05) <a href="https://arxiv.org/abs/1706.01556v2">https://arxiv.org/abs/1706.01556v2</a></p>
</div>
<div id="ref-HS4ARwmZ">
<p>99. <strong>Knowledge-guided convolutional networks for chemical-disease relation extraction</strong><br />
Huiwei Zhou, Chengkun Lang, Zhuang Liu, Shixian Ning, Yingyu Lin, Lei Du<br />
<em>BMC Bioinformatics</em> (2019-05-21) <a href="https://doi.org/gf45zn">https://doi.org/gf45zn</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-019-2873-7">10.1186/s12859-019-2873-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31113357">31113357</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6528333">PMC6528333</a></p>
</div>
<div id="ref-1H4LpFrU0">
<p>100. <strong>Extraction of protein–protein interactions (PPIs) from the literature by deep convolutional neural networks with various feature embeddings</strong><br />
Sung-Pil Choi<br />
<em>Journal of Information Science</em> (2016-11-01) <a href="https://doi.org/gcv8bn">https://doi.org/gcv8bn</a><br />
DOI: <a href="https://doi.org/10.1177/0165551516673485">10.1177/0165551516673485</a></p>
</div>
<div id="ref-5LOkzCNK">
<p>101. <strong>Extracting chemical–protein relations with ensembles of SVM and deep learning models</strong><br />
Yifan Peng, Anthony Rios, Ramakanth Kavuluru, Zhiyong Lu<br />
<em>Database</em> (2018-01-01) <a href="https://doi.org/gf479f">https://doi.org/gf479f</a><br />
DOI: <a href="https://doi.org/10.1093/database/bay073">10.1093/database/bay073</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30020437">30020437</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6051439">PMC6051439</a></p>
</div>
<div id="ref-19fr9ZRrA">
<p>102. <strong>Expanding a Database-derived Biomedical Knowledge Graph via Multi-relation Extraction from Biomedical Abstracts</strong><br />
David N. Nicholson, Daniel S. Himmelstein, Casey S. Greene<br />
<em>Cold Spring Harbor Laboratory</em> (2019-08-08) <a href="https://doi.org/gf6qxh">https://doi.org/gf6qxh</a><br />
DOI: <a href="https://doi.org/10.1101/730085">10.1101/730085</a></p>
</div>
<div id="ref-EHeTvZht">
<p>103. <strong>Distant supervision for relation extraction without labeled data</strong><br />
Mike Mintz, Steven Bills, Rion Snow, Dan Jurafsky<br />
<em>Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - ACL-IJCNLP ’09</em> (2009) <a href="https://doi.org/fg9q43">https://doi.org/fg9q43</a><br />
DOI: <a href="https://doi.org/10.3115/1690219.1690287">10.3115/1690219.1690287</a></p>
</div>
<div id="ref-xWET58su">
<p>104. <strong>Introduction to Semi-Supervised Learning</strong><br />
Xiaojin Zhu, Andrew B. Goldberg<br />
<em>Synthesis Lectures on Artificial Intelligence and Machine Learning</em> (2009-01) <a href="https://doi.org/bq7pm2">https://doi.org/bq7pm2</a><br />
DOI: <a href="https://doi.org/10.2200/s00196ed1v01y200906aim006">10.2200/s00196ed1v01y200906aim006</a></p>
</div>
<div id="ref-12JtL2o6T">
<p>105. <strong>A Survey on Transfer Learning</strong><br />
Sinno Jialin Pan, Qiang Yang<br />
<em>IEEE Transactions on Knowledge and Data Engineering</em> (2010-10) <a href="https://doi.org/bc4vws">https://doi.org/bc4vws</a><br />
DOI: <a href="https://doi.org/10.1109/tkde.2009.191">10.1109/tkde.2009.191</a></p>
</div>
<div id="ref-YRDXK4f4">
<p>106. <strong>A survey of transfer learning</strong><br />
Karl Weiss, Taghi M. Khoshgoftaar, DingDing Wang<br />
<em>Journal of Big Data</em> (2016-05-28) <a href="https://doi.org/gfkr2w">https://doi.org/gfkr2w</a><br />
DOI: <a href="https://doi.org/10.1186/s40537-016-0043-6">10.1186/s40537-016-0043-6</a></p>
</div>
<div id="ref-hNMqMImK">
<p>107. <strong>Exploring Semi-supervised Variational Autoencoders for Biomedical Relation Extraction</strong><br />
Yijia Zhang, Zhiyong Lu<br />
<em>arXiv</em> (2019-01-18) <a href="https://arxiv.org/abs/1901.06103v1">https://arxiv.org/abs/1901.06103v1</a></p>
</div>
<div id="ref-WYud0jQT">
<p>108. <strong>Large-scale extraction of gene interactions from full-text literature using DeepDive</strong><br />
Emily K. Mallory, Ce Zhang, Christopher Ré, Russ B. Altman<br />
<em>Bioinformatics</em> (2015-09-03) <a href="https://doi.org/gb5g7b">https://doi.org/gb5g7b</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btv476">10.1093/bioinformatics/btv476</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26338771">26338771</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4681986">PMC4681986</a></p>
</div>
<div id="ref-vzoBuh4l">
<p>109. <strong>Snorkel</strong><br />
Alexander Ratner, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, Christopher Ré<br />
<em>Proceedings of the VLDB Endowment</em> (2017-11-01) <a href="https://doi.org/ch44">https://doi.org/ch44</a><br />
DOI: <a href="https://doi.org/10.14778/3157794.3157797">10.14778/3157794.3157797</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29770249">29770249</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5951191">PMC5951191</a></p>
</div>
<div id="ref-9Jo1af7Z">
<p>110. <strong>Snorkel MeTaL</strong><br />
Alex Ratner, Braden Hancock, Jared Dunnmon, Roger Goldman, Christopher Ré<br />
<em>Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning - DEEM’18</em> (2018) <a href="https://doi.org/gf3xk7">https://doi.org/gf3xk7</a><br />
DOI: <a href="https://doi.org/10.1145/3209889.3209898">10.1145/3209889.3209898</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30931438">30931438</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6436830">PMC6436830</a></p>
</div>
<div id="ref-kvlZD1mv">
<p>111. <strong>Learning protein protein interaction extraction using distant supervision</strong><br />
Philippe Thomas, Illés Solt, Roman Klinger, Ulf Leser<br />
(2011-01)</p>
</div>
<div id="ref-Kry87kzn">
<p>112. <strong>Robust Distant Supervision Relation Extraction via Deep Reinforcement Learning</strong><br />
Pengda Qin, Weiran Xu, William Yang Wang<br />
<em>arXiv</em> (2018-05-24) <a href="https://arxiv.org/abs/1805.09927v1">https://arxiv.org/abs/1805.09927v1</a></p>
</div>
<div id="ref-M5UWoN93">
<p>113. <strong>DSGAN: Generative Adversarial Training for Distant Supervision Relation Extraction</strong><br />
Pengda Qin, Weiran Xu, William Yang Wang<br />
<em>arXiv</em> (2018-05-24) <a href="https://arxiv.org/abs/1805.09929v1">https://arxiv.org/abs/1805.09929v1</a></p>
</div>
<div id="ref-xy08BzDf">
<p>114. <strong>Noise Reduction Methods for Distantly Supervised Biomedical Relation Extraction</strong><br />
Gang Li, Cathy Wu, K. Vijay-Shanker<br />
<em>BioNLP 2017</em> (2017) <a href="https://doi.org/ggmk8s">https://doi.org/ggmk8s</a><br />
DOI: <a href="https://doi.org/10.18653/v1/w17-2323">10.18653/v1/w17-2323</a></p>
</div>
<div id="ref-DWpAeBxB">
<p>115. <strong>BioInfer: a corpus for information extraction in the biomedical domain</strong><br />
Sampo Pyysalo, Filip Ginter, Juho Heimonen, Jari Björne, Jorma Boberg, Jouni Järvinen, Tapio Salakoski<br />
<em>BMC Bioinformatics</em> (2007-02-09) <a href="https://doi.org/b7bhhc">https://doi.org/b7bhhc</a><br />
DOI: <a href="https://doi.org/10.1186/1471-2105-8-50">10.1186/1471-2105-8-50</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/17291334">17291334</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1808065">PMC1808065</a></p>
</div>
<div id="ref-szMMEMdC">
<p>116. <strong>Learning language in logic - genic interaction extraction challenge</strong><br />
C. Nédellec<br />
<em>Proceedings of the learning language in logic 2005 workshop at the international conference on machine learning</em> (2005)</p>
</div>
<div id="ref-115pgEuOr">
<p>117. <strong>Mining medline: Abstracts, sentences, or phrases?</strong><br />
Jing Ding, Daniel Berleant, Dan Nettleton, Eve Syrkin Wurtele<br />
<em>Pacific symposium on biocomputing</em> (2002) <a href="http://helix-web.stanford.edu/psb02/ding.pdf">http://helix-web.stanford.edu/psb02/ding.pdf</a></p>
</div>
<div id="ref-1Du6MinB8">
<p>118. <strong>Concept annotation in the CRAFT corpus</strong><br />
Michael Bada, Miriam Eckert, Donald Evans, Kristin Garcia, Krista Shipley, Dmitry Sitnikov, William A Baumgartner Jr, K Bretonnel Cohen, Karin Verspoor, Judith A Blake, Lawrence E Hunter<br />
<em>BMC Bioinformatics</em> (2012-07-09) <a href="https://doi.org/gb8vdr">https://doi.org/gb8vdr</a><br />
DOI: <a href="https://doi.org/10.1186/1471-2105-13-161">10.1186/1471-2105-13-161</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22776079">22776079</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3476437">PMC3476437</a></p>
</div>
<div id="ref-10nDTiETi">
<p>119. <strong>GRAM: Graph-based Attention Model for Healthcare Representation Learning</strong><br />
Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F. Stewart, Jimeng Sun<br />
<em>arXiv</em> (2016-11-21) <a href="https://arxiv.org/abs/1611.07012v3">https://arxiv.org/abs/1611.07012v3</a></p>
</div>
<div id="ref-YyPaovQ0">
<p>120. <strong>miRNA-Disease Association Prediction with Collaborative Matrix Factorization</strong><br />
Zhen Shen, You-Hua Zhang, Kyungsook Han, Asoke K. Nandi, Barry Honig, De-Shuang Huang<br />
<em>Complexity</em> (2017) <a href="https://doi.org/ggmrpm">https://doi.org/ggmrpm</a><br />
DOI: <a href="https://doi.org/10.1155/2017/2498957">10.1155/2017/2498957</a></p>
</div>
<div id="ref-j7KrVyi8">
<p>121. <strong>Deep Residual Learning for Image Recognition</strong><br />
Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun<br />
<em>arXiv</em> (2015-12-10) <a href="https://arxiv.org/abs/1512.03385v1">https://arxiv.org/abs/1512.03385v1</a></p>
</div>
<div id="ref-DSiHGDz9">
<p>122. <strong>Representation Learning on Graphs: Methods and Applications</strong><br />
William L. Hamilton, Rex Ying, Jure Leskovec<br />
<em>arXiv</em> (2017-09-17) <a href="https://arxiv.org/abs/1709.05584v3">https://arxiv.org/abs/1709.05584v3</a></p>
</div>
<div id="ref-18ZTxo1gJ">
<p>123. <strong>Signed laplacian embedding for supervised dimension reduction</strong><br />
Chen Gong, Dacheng Tao, Jie Yang, Keren Fu<br />
<em>Proceedings of the twenty-eighth aaai conference on artificial intelligence</em> (2014) <a href="http://dl.acm.org/citation.cfm?id=2892753.2892809">http://dl.acm.org/citation.cfm?id=2892753.2892809</a></p>
</div>
<div id="ref-u6NlpEUq">
<p>124. <strong>A Semi-NMF-PCA Unified Framework for Data Clustering</strong><br />
Kais Allab, Lazhar Labiod, Mohamed Nadif<br />
<em>IEEE Transactions on Knowledge and Data Engineering</em> (2017-01-01) <a href="https://doi.org/f9hm9g">https://doi.org/f9hm9g</a><br />
DOI: <a href="https://doi.org/10.1109/tkde.2016.2606098">10.1109/tkde.2016.2606098</a></p>
</div>
<div id="ref-dylXYFm6">
<p>125. <strong>Partially supervised graph embedding for positive unlabelled feature selection</strong><br />
Yufei Han, Yun Shen<br />
<em>Proceedings of the twenty-fifth international joint conference on artificial intelligence</em> (2016) <a href="http://dl.acm.org/citation.cfm?id=3060832.3060837">http://dl.acm.org/citation.cfm?id=3060832.3060837</a><br />
ISBN: <a href="https://worldcat.org/isbn/978-1-57735-770-4">978-1-57735-770-4</a></p>
</div>
<div id="ref-9F3iyg8e">
<p>126. <strong>GraRep</strong><br />
Shaosheng Cao, Wei Lu, Qiongkai Xu<br />
<em>Proceedings of the 24th ACM International on Conference on Information and Knowledge Management - CIKM ’15</em> (2015) <a href="https://doi.org/gf8rgf">https://doi.org/gf8rgf</a><br />
DOI: <a href="https://doi.org/10.1145/2806416.2806512">10.1145/2806416.2806512</a></p>
</div>
<div id="ref-E5xHFo4P">
<p>127. <strong>Improved Knowledge Base Completion by Path-Augmented TransR Model</strong><br />
Wenhao Huang, Ge Li, Zhi Jin<br />
<em>arXiv</em> (2016-10-06) <a href="https://arxiv.org/abs/1610.04073v1">https://arxiv.org/abs/1610.04073v1</a></p>
</div>
<div id="ref-13cvwdrYY">
<p>128. <strong>A Global Geometric Framework for Nonlinear Dimensionality Reduction</strong><br />
J. B. Tenenbaum<br />
<em>Science</em> (2000-12-22) <a href="https://doi.org/cz8wgk">https://doi.org/cz8wgk</a><br />
DOI: <a href="https://doi.org/10.1126/science.290.5500.2319">10.1126/science.290.5500.2319</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11125149">11125149</a></p>
</div>
<div id="ref-MxPEnWF1">
<p>129. <strong>Laplacian Eigenmaps for Dimensionality Reduction and Data Representation</strong><br />
Mikhail Belkin, Partha Niyogi<br />
<em>Neural Computation</em> (2003-06) <a href="https://doi.org/bbr9cw">https://doi.org/bbr9cw</a><br />
DOI: <a href="https://doi.org/10.1162/089976603321780317">10.1162/089976603321780317</a></p>
</div>
<div id="ref-sSbTaHau">
<p>130. <strong>Principal component analysis</strong><br />
Svante Wold, Kim Esbensen, Paul Geladi<br />
<em>Chemometrics and Intelligent Laboratory Systems</em> (1987-08) <a href="https://doi.org/bm8dnf">https://doi.org/bm8dnf</a><br />
DOI: <a href="https://doi.org/10.1016/0169-7439(87)80084-9">10.1016/0169-7439(87)80084-9</a></p>
</div>
<div id="ref-H0ez30Pz">
<p>131. <strong>The approximation of one matrix by another of lower rank</strong><br />
Carl Eckart, Gale Young<br />
<em>Psychometrika</em> (1936-09) <a href="https://doi.org/c2frtd">https://doi.org/c2frtd</a><br />
DOI: <a href="https://doi.org/10.1007/bf02288367">10.1007/bf02288367</a></p>
</div>
<div id="ref-TFsQrgwM">
<p>132. <strong>Network embedding as matrix factorization: Unifying deepwalk, line, pte, and node2vec</strong><br />
Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Kuansan Wang, Jie Tang<br />
<em>Proceedings of the eleventh acm international conference on web search and data mining</em> (2018) <a href="https://doi.org/10.1145/3159652.3159706">https://doi.org/10.1145/3159652.3159706</a><br />
DOI: <a href="https://doi.org/10.1145/3159652.3159706">10.1145/3159652.3159706</a> · ISBN: <a href="https://worldcat.org/isbn/9781450355810">9781450355810</a></p>
</div>
<div id="ref-Z5VAJJmP">
<p>133. <strong>A Survey of Collaborative Filtering Techniques</strong><br />
Xiaoyuan Su, Taghi M. Khoshgoftaar<br />
<em>Advances in Artificial Intelligence</em> (2009) <a href="https://doi.org/fk9jjg">https://doi.org/fk9jjg</a><br />
DOI: <a href="https://doi.org/10.1155/2009/421425">10.1155/2009/421425</a></p>
</div>
<div id="ref-OJXYxm8W">
<p>134. <strong>Graph Embedding on Biomedical Networks: Methods, Applications, and Evaluations</strong><br />
Xiang Yue, Zhen Wang, Jingong Huang, Srinivasan Parthasarathy, Soheil Moosavinasab, Yungui Huang, Simon M. Lin, Wen Zhang, Ping Zhang, Huan Sun<br />
<em>arXiv</em> (2019-06-12) <a href="https://arxiv.org/abs/1906.05017v3">https://arxiv.org/abs/1906.05017v3</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btz718">10.1093/bioinformatics/btz718</a></p>
</div>
<div id="ref-KzDGRrSP">
<p>135. <strong>GLEE: Geometric Laplacian Eigenmap Embedding</strong><br />
Leo Torres, Kevin S Chan, Tina Eliassi-Rad<br />
<em>arXiv</em> (2019-05-23) <a href="https://arxiv.org/abs/1905.09763v2">https://arxiv.org/abs/1905.09763v2</a></p>
</div>
<div id="ref-FE8pyO0l">
<p>136. <strong>Vicus: Exploiting local structures to improve network-based analysis of biological data</strong><br />
Bo Wang, Lin Huang, Yuke Zhu, Anshul Kundaje, Serafim Batzoglou, Anna Goldenberg<br />
<em>PLOS Computational Biology</em> (2017-10-12) <a href="https://doi.org/gb368p">https://doi.org/gb368p</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1005621">10.1371/journal.pcbi.1005621</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29023470">29023470</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5638230">PMC5638230</a></p>
</div>
<div id="ref-mGBbZq62">
<p>137. <strong>Translating embeddings for modeling multi-relational data</strong><br />
Antoine Bordes, Nicolas Usunier, Alberto García-Durán, Jason Weston, Oksana Yakhnenko<br />
<em>NIPS</em> (2013)</p>
</div>
<div id="ref-nprR5cVj">
<p>138. <strong>Knowledge graph embedding by translating on hyperplanes</strong><br />
Zhen Wang, Jianwen Zhang, Jianlin Feng, Zheng Chen<br />
<em>Proceedings of the twenty-eighth aaai conference on artificial intelligence</em> (2014) <a href="http://dl.acm.org/citation.cfm?id=2893873.2894046">http://dl.acm.org/citation.cfm?id=2893873.2894046</a></p>
</div>
<div id="ref-R8kotaKY">
<p>139. <strong>Learning entity and relation embeddings for knowledge graph completion</strong><br />
Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, Xuan Zhu<br />
<em>Proceedings of the twenty-ninth aaai conference on artificial intelligence</em> (2015) <a href="http://dl.acm.org/citation.cfm?id=2886521.2886624">http://dl.acm.org/citation.cfm?id=2886521.2886624</a><br />
ISBN: <a href="https://worldcat.org/isbn/0-262-51129-0">0-262-51129-0</a></p>
</div>
<div id="ref-BRGxlTb9">
<p>140. <strong>PrTransH: Embedding Probabilistic Medical Knowledge from Real World EMR Data</strong><br />
Linfeng Li, Peng Wang, Yao Wang, Jinpeng Jiang, Buzhou Tang, Jun Yan, Shenghui Wang, Yuting Liu<br />
<em>arXiv</em> (2019-09-02) <a href="https://arxiv.org/abs/1909.00672v1">https://arxiv.org/abs/1909.00672v1</a></p>
</div>
<div id="ref-7BUncUx3">
<p>141. <strong>DeepWalk: Online Learning of Social Representations</strong><br />
Bryan Perozzi, Rami Al-Rfou, Steven Skiena<br />
<em>arXiv</em> (2014-03-26) <a href="https://arxiv.org/abs/1403.6652v2">https://arxiv.org/abs/1403.6652v2</a><br />
DOI: <a href="https://doi.org/10.1145/2623330.2623732">10.1145/2623330.2623732</a></p>
</div>
<div id="ref-PD4udqRe">
<p>142. <strong>node2vec: Scalable Feature Learning for Networks</strong><br />
Aditya Grover, Jure Leskovec<br />
<em>arXiv</em> (2016-07-03) <a href="https://arxiv.org/abs/1607.00653v1">https://arxiv.org/abs/1607.00653v1</a></p>
</div>
<div id="ref-BatC4UOA">
<p>143. <strong>struc2vec: Learning Node Representations from Structural Identity</strong><br />
Leonardo F. R. Ribeiro, Pedro H. P. Savarese, Daniel R. Figueiredo<br />
<em>arXiv</em> (2017-04-11) <a href="https://arxiv.org/abs/1704.03165v3">https://arxiv.org/abs/1704.03165v3</a><br />
DOI: <a href="https://doi.org/10.1145/3097983.3098061">10.1145/3097983.3098061</a></p>
</div>
<div id="ref-1AeZs6xaT">
<p>144. <strong>metapath2vec</strong><br />
Yuxiao Dong, Nitesh V. Chawla, Ananthram Swami<br />
<em>Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD ’17</em> (2017) <a href="https://doi.org/gfsqzn">https://doi.org/gfsqzn</a><br />
DOI: <a href="https://doi.org/10.1145/3097983.3098036">10.1145/3097983.3098036</a></p>
</div>
<div id="ref-1G1nukcFt">
<p>145. <strong>edge2vec: Representation learning using edge semantics for biomedical knowledge discovery</strong><br />
Zheng Gao, Gang Fu, Chunping Ouyang, Satoshi Tsutsui, Xiaozhong Liu, Jeremy Yang, Christopher Gessner, Brian Foote, David Wild, Qi Yu, Ying Ding<br />
<em>arXiv</em> (2018-09-07) <a href="https://arxiv.org/abs/1809.02269v3">https://arxiv.org/abs/1809.02269v3</a></p>
</div>
<div id="ref-eSGflyQ5">
<p>146. <strong>Learning Graph Embeddings from WordNet-based Similarity Measures</strong><br />
Andrey Kutuzov, Mohammad Dorgham, Oleksiy Oliynyk, Chris Biemann, Alexander Panchenko<br />
<em>arXiv</em> (2018-08-16) <a href="https://arxiv.org/abs/1808.05611v4">https://arxiv.org/abs/1808.05611v4</a></p>
</div>
<div id="ref-bt1KIf4U">
<p>147. <strong>Learning to Make Predictions on Graphs with Autoencoders</strong><br />
Phi Vu Tran<br />
<em>arXiv</em> (2018-02-23) <a href="https://arxiv.org/abs/1802.08352v2">https://arxiv.org/abs/1802.08352v2</a><br />
DOI: <a href="https://doi.org/10.1109/DSAA.2018.00034">10.1109/dsaa.2018.00034</a></p>
</div>
<div id="ref-hjIIetVM">
<p>148. <strong>Variational Graph Auto-Encoders</strong><br />
Thomas N. Kipf, Max Welling<br />
<em>arXiv</em> (2016-11-21) <a href="https://arxiv.org/abs/1611.07308v1">https://arxiv.org/abs/1611.07308v1</a></p>
</div>
<div id="ref-1A6Dhbwkr">
<p>149. <strong>Adversarially Regularized Graph Autoencoder for Graph Embedding</strong><br />
Shirui Pan, Ruiqi Hu, Guodong Long, Jing Jiang, Lina Yao, Chengqi Zhang<br />
<em>arXiv</em> (2018-02-13) <a href="https://arxiv.org/abs/1802.04407v2">https://arxiv.org/abs/1802.04407v2</a></p>
</div>
<div id="ref-DZT65ZRY">
<p>150. <strong>Deep Learning in Neural Networks: An Overview</strong><br />
Juergen Schmidhuber<br />
<em>arXiv</em> (2014-04-30) <a href="https://arxiv.org/abs/1404.7828v4">https://arxiv.org/abs/1404.7828v4</a><br />
DOI: <a href="https://doi.org/10.1016/j.neunet.2014.09.003">10.1016/j.neunet.2014.09.003</a></p>
</div>
<div id="ref-1ErNQZjBt">
<p>151. <strong>Autoencoders, unsupervised learning and deep architectures</strong><br />
Pierre Baldi<br />
<em>Proceedings of the 2011 international conference on unsupervised and transfer learning workshop - volume 27</em> (2011)</p>
</div>
<div id="ref-YVOAlp8C">
<p>152. <strong>A Comparative Study for Unsupervised Network Representation Learning</strong><br />
Megha Khosla, Vinay Setty, Avishek Anand<br />
<em>arXiv</em> (2019-03-19) <a href="https://arxiv.org/abs/1903.07902v5">https://arxiv.org/abs/1903.07902v5</a><br />
DOI: <a href="https://doi.org/10.1109/TKDE.2019.2951398">10.1109/tkde.2019.2951398</a></p>
</div>
<div id="ref-1EP2NrAhl">
<p>153. <strong>Neural networks for link prediction in realistic biomedical graphs: a multi-dimensional evaluation of graph embedding-based approaches</strong><br />
Gamal Crichton, Yufan Guo, Sampo Pyysalo, Anna Korhonen<br />
<em>BMC Bioinformatics</em> (2018-05-21) <a href="https://doi.org/ggkm7q">https://doi.org/ggkm7q</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-018-2163-9">10.1186/s12859-018-2163-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29783926">29783926</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5963080">PMC5963080</a></p>
</div>
<div id="ref-17R6q0KTd">
<p>154. <strong>Network-based integration of multi-omics data for prioritizing cancer genes</strong><br />
Christos Dimitrakopoulos, Sravanth Kumar Hindupur, Luca Häfliger, Jonas Behr, Hesam Montazeri, Michael N Hall, Niko Beerenwinkel<br />
<em>Bioinformatics</em> (2018-03-14) <a href="https://doi.org/gc6953">https://doi.org/gc6953</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bty148">10.1093/bioinformatics/bty148</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29547932">29547932</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6041755">PMC6041755</a></p>
</div>
<div id="ref-aLsdEzlV">
<p>155. <strong>Safe Medicine Recommendation via Medical Knowledge Graph Embedding</strong><br />
Meng Wang, Mengyue Liu, Jun Liu, Sen Wang, Guodong Long, Buyue Qian<br />
<em>arXiv</em> (2017-10-16) <a href="https://arxiv.org/abs/1710.05980v2">https://arxiv.org/abs/1710.05980v2</a></p>
</div>
<div id="ref-8vj5v8un">
<p>156. <strong>GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination</strong><br />
Junyuan Shang, Cao Xiao, Tengfei Ma, Hongyan Li, Jimeng Sun<br />
<em>Proceedings of the AAAI Conference on Artificial Intelligence</em> (2019-07-17) <a href="https://doi.org/ggkm7r">https://doi.org/ggkm7r</a><br />
DOI: <a href="https://doi.org/10.1609/aaai.v33i01.33011126">10.1609/aaai.v33i01.33011126</a></p>
</div>
<div id="ref-otY29wFV">
<p>157. <strong>Heterogeneous network embedding for identifying symptom candidate genes</strong><br />
Kuo Yang, Ning Wang, Guangming Liu, Ruyu Wang, Jian Yu, Runshun Zhang, Jianxin Chen, Xuezhong Zhou<br />
<em>Journal of the American Medical Informatics Association</em> (2018-10-23) <a href="https://doi.org/gfg6nr">https://doi.org/gfg6nr</a><br />
DOI: <a href="https://doi.org/10.1093/jamia/ocy117">10.1093/jamia/ocy117</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30357378">30357378</a></p>
</div>
<div id="ref-6O3BO6WO">
<p>158. <strong>Predicting Protein–Protein Interactions from Multimodal Biological Data Sources via Nonnegative Matrix Tri-Factorization</strong><br />
Hua Wang, Heng Huang, Chris Ding, Feiping Nie<br />
<em>Journal of Computational Biology</em> (2013-04) <a href="https://doi.org/f4thrx">https://doi.org/f4thrx</a><br />
DOI: <a href="https://doi.org/10.1089/cmb.2012.0273">10.1089/cmb.2012.0273</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23509857">23509857</a></p>
</div>
<div id="ref-Y2RTnbCe">
<p>159. <strong>Protein functional properties prediction in sparsely-label PPI networks through regularized non-negative matrix factorization</strong><br />
Qingyao Wu, Zhenyu Wang, Chunshan Li, Yunming Ye, Yueping Li, Ning Sun<br />
<em>BMC Systems Biology</em> (2015) <a href="https://doi.org/gb5tvr">https://doi.org/gb5tvr</a><br />
DOI: <a href="https://doi.org/10.1186/1752-0509-9-s1-s9">10.1186/1752-0509-9-s1-s9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25708164">25708164</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4331684">PMC4331684</a></p>
</div>
<div id="ref-1F18ycwfS">
<p>160. <strong>HMDD v3.0: a database for experimentally supported human microRNA–disease associations</strong><br />
Zhou Huang, Jiangcheng Shi, Yuanxu Gao, Chunmei Cui, Shan Zhang, Jianwei Li, Yuan Zhou, Qinghua Cui<br />
<em>Nucleic Acids Research</em> (2018-10-26) <a href="https://doi.org/ggmrph">https://doi.org/ggmrph</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gky1010">10.1093/nar/gky1010</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30364956">30364956</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323994">PMC6323994</a></p>
</div>
<div id="ref-1DjgsuPV2">
<p>161. <strong>Predicting MiRNA-Disease Association by Latent Feature Extraction with Positive Samples</strong><br />
Kai Che, Maozu Guo, Chunyu Wang, Xiaoyan Liu, Xi Chen<br />
<em>Genes</em> (2019-01-24) <a href="https://doi.org/ggmrpr">https://doi.org/ggmrpr</a><br />
DOI: <a href="https://doi.org/10.3390/genes10020080">10.3390/genes10020080</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30682853">30682853</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6410147">PMC6410147</a></p>
</div>
<div id="ref-hZ2R5BRj">
<p>162. <strong>NPCMF: Nearest Profile-based Collaborative Matrix Factorization method for predicting miRNA-disease associations</strong><br />
Ying-Lian Gao, Zhen Cui, Jin-Xing Liu, Juan Wang, Chun-Hou Zheng<br />
<em>BMC Bioinformatics</em> (2019-06-24) <a href="https://doi.org/ggmrpn">https://doi.org/ggmrpn</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-019-2956-5">10.1186/s12859-019-2956-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31234797">31234797</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6591872">PMC6591872</a></p>
</div>
<div id="ref-4xcJzyPc">
<p>163. <strong>RCMF: a robust collaborative matrix factorization method to predict miRNA-disease associations</strong><br />
Zhen Cui, Jin-Xing Liu, Ying-Lian Gao, Chun-Hou Zheng, Juan Wang<br />
<em>BMC Bioinformatics</em> (2019-12) <a href="https://doi.org/ggmrpp">https://doi.org/ggmrpp</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-019-3260-0">10.1186/s12859-019-3260-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31874608">31874608</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6929455">PMC6929455</a></p>
</div>
<div id="ref-icSe8Yyw">
<p>164. <strong>LWPCMF: Logistic Weighted Profile-based Collaborative Matrix Factorization for Predicting MiRNA-Disease Associations</strong><br />
Meng-Meng Yin, Zhen Cui, Ming-Ming Gao, Jin-Xing Liu, Ying-Lian Gao<br />
<em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> (2019) <a href="https://doi.org/ggmrpk">https://doi.org/ggmrpk</a><br />
DOI: <a href="https://doi.org/10.1109/tcbb.2019.2937774">10.1109/tcbb.2019.2937774</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31478868">31478868</a></p>
</div>
<div id="ref-6FrpIkNZ">
<p>165. <strong>Protein-protein interaction prediction via Collective Matrix Factorization</strong><br />
Qian Xu, Evan Wei Xiang, Qiang Yang<br />
<em>2010 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</em> (2010-12) <a href="https://doi.org/csnv5m">https://doi.org/csnv5m</a><br />
DOI: <a href="https://doi.org/10.1109/bibm.2010.5706537">10.1109/bibm.2010.5706537</a></p>
</div>
<div id="ref-6PISrkV5">
<p>166. <strong>A network embedding model for pathogenic genes prediction by multi-path random walking on heterogeneous network</strong><br />
Bo Xu, Yu Liu, Shuo Yu, Lei Wang, Jie Dong, Hongfei Lin, Zhihao Yang, Jian Wang, Feng Xia<br />
<em>BMC Medical Genomics</em> (2019-12) <a href="https://doi.org/ggmrpq">https://doi.org/ggmrpq</a><br />
DOI: <a href="https://doi.org/10.1186/s12920-019-0627-z">10.1186/s12920-019-0627-z</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31865919">31865919</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6927107">PMC6927107</a></p>
</div>
<div id="ref-taI1UUAE">
<p>167. <strong>Predicting gene-disease associations from the heterogeneous network using graph embedding</strong><br />
Xiaochan Wang, Yuchong Gong, Jing Yi, Wen Zhang<br />
<em>2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)</em> (2019-11) <a href="https://doi.org/ggmrpj">https://doi.org/ggmrpj</a><br />
DOI: <a href="https://doi.org/10.1109/bibm47256.2019.8983134">10.1109/bibm47256.2019.8983134</a></p>
</div>
<div id="ref-qbHGtxhA">
<p>168. <strong>Network embedding-based representation learning for single cell RNA-seq data</strong><br />
Xiangyu Li, Weizheng Chen, Yang Chen, Xuegong Zhang, Jin Gu, Michael Q. Zhang<br />
<em>Nucleic Acids Research</em> (2017-08-28) <a href="https://doi.org/ggmrpg">https://doi.org/ggmrpg</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gkx750">10.1093/nar/gkx750</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28977434">28977434</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5737094">PMC5737094</a></p>
</div>
<div id="ref-QQtRw08H">
<p>169. <strong>Neuro-symbolic representation learning on biological knowledge graphs</strong><br />
Mona Alshahrani, Mohammad Asif Khan, Omar Maddouri, Akira R Kinjo, Núria Queralt-Rosinach, Robert Hoehndorf<br />
<em>Bioinformatics</em> (2017-04-25) <a href="https://doi.org/gbv6vm">https://doi.org/gbv6vm</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btx275">10.1093/bioinformatics/btx275</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28449114">28449114</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860058">PMC5860058</a></p>
</div>
<div id="ref-8qB2oCgy">
<p>170. <strong>Deep Learning the Protein Function in Protein Interaction Networks</strong><br />
Kire Trivodaliev, Martin Josifoski, Slobodan Kalajdziski<br />
<em>Communications in Computer and Information Science</em> (2018) <a href="https://doi.org/ggmrpd">https://doi.org/ggmrpd</a><br />
DOI: <a href="https://doi.org/10.1007/978-3-030-00825-3_16">10.1007/978-3-030-00825-3_16</a></p>
</div>
<div id="ref-RYW74Wvh">
<p>171. <strong>Detection of protein complexes from multiple protein interaction networks using graph embedding</strong><br />
Xiaoxia Liu, Zhihao Yang, Shengtian Sang, Hongfei Lin, Jian Wang, Bo Xu<br />
<em>Artificial Intelligence in Medicine</em> (2019-05) <a href="https://doi.org/ggmrpf">https://doi.org/ggmrpf</a><br />
DOI: <a href="https://doi.org/10.1016/j.artmed.2019.04.001">10.1016/j.artmed.2019.04.001</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31164203">31164203</a></p>
</div>
<div id="ref-NnOS86ev">
<p>172. <strong>Large-scale structural and textual similarity-based mining of knowledge graph to predict drug–drug interactions</strong><br />
Ibrahim Abdelaziz, Achille Fokoue, Oktie Hassanzadeh, Ping Zhang, Mohammad Sadoghi<br />
<em>Journal of Web Semantics</em> (2017-05) <a href="https://doi.org/gcrwk3">https://doi.org/gcrwk3</a><br />
DOI: <a href="https://doi.org/10.1016/j.websem.2017.06.002">10.1016/j.websem.2017.06.002</a></p>
</div>
<div id="ref-11ua4nEkY">
<p>173. <strong>Matrix Factorization-Based Prediction of Novel Drug Indications by Integrating Genomic Space</strong><br />
Wen Dai, Xi Liu, Yibo Gao, Lin Chen, Jianglong Song, Di Chen, Kuo Gao, Yongshi Jiang, Yiping Yang, Jianxin Chen, Peng Lu<br />
<em>Computational and Mathematical Methods in Medicine</em> (2015) <a href="https://doi.org/gb58g8">https://doi.org/gb58g8</a><br />
DOI: <a href="https://doi.org/10.1155/2015/275045">10.1155/2015/275045</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26078775">26078775</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4452507">PMC4452507</a></p>
</div>
<div id="ref-sj2fr8fp">
<p>174. <strong>Abstract</strong><br />
eLife Sciences Publications, Ltd<br />
<a href="https://doi.org/gf4fdb">https://doi.org/gf4fdb</a><br />
DOI: <a href="https://doi.org/10.7554/elife.26726.001">10.7554/elife.26726.001</a></p>
</div>
<div id="ref-S0MrOfj0">
<p>175. <strong>Drug-Target Interaction Prediction with Graph Regularized Matrix Factorization</strong><br />
Ali Ezzat, Peilin Zhao, Min Wu, Xiao-Li Li, Chee-Keong Kwoh<br />
<em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> (2017-05-01) <a href="https://doi.org/ggmrrp">https://doi.org/ggmrrp</a><br />
DOI: <a href="https://doi.org/10.1109/tcbb.2016.2530062">10.1109/tcbb.2016.2530062</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26890921">26890921</a></p>
</div>
<div id="ref-HOrwJFzW">
<p>176. <strong>Predicting Drug-Target Interaction Using Deep Matrix Factorization</strong><br />
Hafez Eslami Manoochehri, Mehrdad Nourani<br />
<em>2018 IEEE Biomedical Circuits and Systems Conference (BioCAS)</em> (2018-10) <a href="https://doi.org/ggmrrn">https://doi.org/ggmrrn</a><br />
DOI: <a href="https://doi.org/10.1109/biocas.2018.8584817">10.1109/biocas.2018.8584817</a></p>
</div>
<div id="ref-Z391qdG0">
<p>177. <strong>Network-based prediction of drug–target interactions using an arbitrary-order proximity embedded deep forest</strong><br />
Xiangxiang Zeng, Siyi Zhu, Yuan Hou, Pengyue Zhang, Lang Li, Jing Li, L Frank Huang, Stephen J Lewis, Ruth Nussinov, Feixiong Cheng<br />
<em>Bioinformatics</em> (2020-01-23) <a href="https://doi.org/ggmrrk">https://doi.org/ggmrrk</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btaa010">10.1093/bioinformatics/btaa010</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31971579">31971579</a></p>
</div>
<div id="ref-dbgPwLaZ">
<p>178. <strong>DrPOCS: Drug Repositioning Based on Projection Onto Convex Sets</strong><br />
Yin-Ying Wang, Chunfeng Cui, Liqun Qi, Hong Yan, Xing-Ming Zhao<br />
<em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> (2019-01-01) <a href="https://doi.org/ggmrrq">https://doi.org/ggmrrq</a><br />
DOI: <a href="https://doi.org/10.1109/tcbb.2018.2830384">10.1109/tcbb.2018.2830384</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29993698">29993698</a></p>
</div>
<div id="ref-94kKAy9w">
<p>179. <strong>Neighborhood Regularized Logistic Matrix Factorization for Drug-Target Interaction Prediction</strong><br />
Yong Liu, Min Wu, Chunyan Miao, Peilin Zhao, Xiao-Li Li<br />
<em>PLOS Computational Biology</em> (2016-02-12) <a href="https://doi.org/ggmrrw">https://doi.org/ggmrrw</a><br />
DOI: <a href="https://doi.org/10.1371/journal.pcbi.1004760">10.1371/journal.pcbi.1004760</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26872142">26872142</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4752318">PMC4752318</a></p>
</div>
<div id="ref-oKdMo9U9">
<p>180. <strong>Predicting drug-target interactions by dual-network integrated logistic matrix factorization</strong><br />
Ming Hao, Stephen H. Bryant, Yanli Wang<br />
<em>Scientific Reports</em> (2017-01-12) <a href="https://doi.org/ggmrrj">https://doi.org/ggmrrj</a><br />
DOI: <a href="https://doi.org/10.1038/srep40376">10.1038/srep40376</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28079135">28079135</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5227688">PMC5227688</a></p>
</div>
<div id="ref-16FEYidu2">
<p>181. <strong>Drug–Disease Association and Drug-Repositioning Predictions in Complex Diseases Using Causal Inference–Probabilistic Matrix Factorization</strong><br />
Jihong Yang, Zheng Li, Xiaohui Fan, Yiyu Cheng<br />
<em>Journal of Chemical Information and Modeling</em> (2014-08-22) <a href="https://doi.org/f6hpb4">https://doi.org/f6hpb4</a><br />
DOI: <a href="https://doi.org/10.1021/ci500340n">10.1021/ci500340n</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25116798">25116798</a></p>
</div>
<div id="ref-18YRZaX7n">
<p>182. <strong>Predicting drug-disease associations by using similarity constrained matrix factorization</strong><br />
Wen Zhang, Xiang Yue, Weiran Lin, Wenjian Wu, Ruoqi Liu, Feng Huang, Feng Liu<br />
<em>BMC Bioinformatics</em> (2018-06-19) <a href="https://doi.org/ggmrrt">https://doi.org/ggmrrt</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-018-2220-4">10.1186/s12859-018-2220-4</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29914348">29914348</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6006580">PMC6006580</a></p>
</div>
<div id="ref-19E33rJiu">
<p>183. <strong>Deep mining heterogeneous networks of biomedical linked data to predict novel drug–target associations</strong><br />
Nansu Zong, Hyeoneui Kim, Victoria Ngo, Olivier Harismendy<br />
<em>Bioinformatics</em> (2017-04-18) <a href="https://doi.org/gbqjgx">https://doi.org/gbqjgx</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/btx160">10.1093/bioinformatics/btx160</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28430977">28430977</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5860112">PMC5860112</a></p>
</div>
<div id="ref-dR3gjJXP">
<p>184. <strong>Scalable and Accurate Drug–target Prediction Based on Heterogeneous Bio-linked Network Mining</strong><br />
Nansu Zong, Rachael Sze Nga Wong, Victoria Ngo, Yue Yu, Ning Li<br />
<em>Cold Spring Harbor Laboratory</em> (2019-02-03) <a href="https://doi.org/ggmrrm">https://doi.org/ggmrrm</a><br />
DOI: <a href="https://doi.org/10.1101/539643">10.1101/539643</a></p>
</div>
<div id="ref-za8DCIPS">
<p>185. <strong>Drug Similarity Integration Through Attentive Multi-view Graph Auto-Encoders</strong><br />
Tengfei Ma, Cao Xiao, Jiayu Zhou, Fei Wang<br />
<em>arXiv</em> (2018-04-28) <a href="https://arxiv.org/abs/1804.10850v1">https://arxiv.org/abs/1804.10850v1</a></p>
</div>
<div id="ref-1BT2OTuxL">
<p>186. <strong>Modeling polypharmacy side effects with graph convolutional networks</strong><br />
Marinka Zitnik, Monica Agrawal, Jure Leskovec<br />
<em>arXiv</em> (2018-02-02) <a href="https://arxiv.org/abs/1802.00543v2">https://arxiv.org/abs/1802.00543v2</a><br />
DOI: <a href="https://doi.org/10.1093/bioinformatics/bty294">10.1093/bioinformatics/bty294</a></p>
</div>
<div id="ref-111FgvD8J">
<p>187. <strong>DrugBank: a knowledgebase for drugs, drug actions and drug targets</strong><br />
David S. Wishart, Craig Knox, An Chi Guo, Dean Cheng, Savita Shrivastava, Dan Tzur, Bijaya Gautam, Murtaza Hassanali<br />
<em>Nucleic Acids Research</em> (2007-11-29) <a href="https://doi.org/d3qqpj">https://doi.org/d3qqpj</a><br />
DOI: <a href="https://doi.org/10.1093/nar/gkm958">10.1093/nar/gkm958</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18048412">18048412</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2238889">PMC2238889</a></p>
</div>
<div id="ref-14fs7pzn0">
<p>188. <strong>The human disease network</strong><br />
K.-I. Goh, M. E. Cusick, D. Valle, B. Childs, M. Vidal, A.-L. Barabasi<br />
<em>Proceedings of the National Academy of Sciences</em> (2007-05-14) <a href="https://doi.org/bt6qvc">https://doi.org/bt6qvc</a><br />
DOI: <a href="https://doi.org/10.1073/pnas.0701361104">10.1073/pnas.0701361104</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/17502601">17502601</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1885563">PMC1885563</a></p>
</div>
<div id="ref-245Px4P3">
<p>189. <strong>Evaluation of knowledge graph embedding approaches for drug-drug interaction prediction in realistic settings</strong><br />
Remzi Celebi, Huseyin Uyar, Erkan Yasar, Ozgur Gumus, Oguz Dikenelli, Michel Dumontier<br />
<em>BMC Bioinformatics</em> (2019-12) <a href="https://doi.org/ggmrrv">https://doi.org/ggmrrv</a><br />
DOI: <a href="https://doi.org/10.1186/s12859-019-3284-5">10.1186/s12859-019-3284-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31852427">31852427</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6921491">PMC6921491</a></p>
</div>
<div id="ref-WMEox1CM">
<p>190. <strong>Drug-Drug Interaction Prediction Based on Knowledge Graph Embeddings and Convolutional-LSTM Network</strong><br />
Md. Rezaul Karim, Michael Cochez, Joao Bosco Jares, Mamtaz Uddin, Oya Beyan, Stefan Decker<br />
<em>Proceedings of the 10th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics - BCB ’19</em> (2019) <a href="https://doi.org/ggmrrs">https://doi.org/ggmrrs</a><br />
DOI: <a href="https://doi.org/10.1145/3307339.3342161">10.1145/3307339.3342161</a></p>
</div>
<div id="ref-xNv4Rkif">
<p>191. <strong>Mining Electronic Health Records using Linked Data.</strong><br />
David J Odgers, Michel Dumontier<br />
<em>AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science</em> (2015-03-23) <a href="https://www.ncbi.nlm.nih.gov/pubmed/26306276">https://www.ncbi.nlm.nih.gov/pubmed/26306276</a><br />
PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26306276">26306276</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4525267">PMC4525267</a></p>
</div>
<div id="ref-mrfQbq3g">
<p>192. <strong>Applying linked data principles to represent patient’s electronic health records at Mayo clinic</strong><br />
Jyotishman Pathak, Richard C. Kiefer, Christopher G. Chute<br />
<em>Proceedings of the 2nd ACM SIGHIT symposium on International health informatics - IHI ’12</em> (2012) <a href="https://doi.org/fzm2p7">https://doi.org/fzm2p7</a><br />
DOI: <a href="https://doi.org/10.1145/2110363.2110415">10.1145/2110363.2110415</a></p>
</div>
<div id="ref-xU6Ims3W">
<p>193. <strong>PDD Graph: Bridging Electronic Medical Records and Biomedical Knowledge Graphs via Entity Linking</strong><br />
Meng Wang, Jiaheng Zhang, Jun Liu, Wei Hu, Sen Wang, Xue Li, Wenqiang Liu<br />
<em>arXiv</em> (2017-07-17) <a href="https://arxiv.org/abs/1707.05340v2">https://arxiv.org/abs/1707.05340v2</a></p>
</div>
<div id="ref-UuF5A9Pu">
<p>194. <strong>Diagnosis Code Assignment Using Sparsity-Based Disease Correlation Embedding</strong><br />
Sen Wang, Xiaojun Chang, Xue Li, Guodong Long, Lina Yao, Quan Z. Sheng<br />
<em>IEEE Transactions on Knowledge and Data Engineering</em> (2016-12-01) <a href="https://doi.org/f9cgtv">https://doi.org/f9cgtv</a><br />
DOI: <a href="https://doi.org/10.1109/tkde.2016.2605687">10.1109/tkde.2016.2605687</a></p>
</div>
<div id="ref-OCnhKscH">
<p>195. <strong>EMR-based medical knowledge representation and inference via Markov random fields and distributed representation learning</strong><br />
Chao Zhao, Jingchi Jiang, Yi Guan<br />
<em>arXiv</em> (2017-09-20) <a href="https://arxiv.org/abs/1709.06908v1">https://arxiv.org/abs/1709.06908v1</a></p>
</div>
<div id="ref-Exfv0f4l">
<p>196. <strong>Attention Is All You Need</strong><br />
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin<br />
<em>arXiv</em> (2017-06-12) <a href="https://arxiv.org/abs/1706.03762v5">https://arxiv.org/abs/1706.03762v5</a></p>
</div>
<div id="ref-haHzVaaz">
<p>197. <strong>Neural Machine Translation by Jointly Learning to Align and Translate</strong><br />
Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio<br />
<em>arXiv</em> (2014-09-01) <a href="https://arxiv.org/abs/1409.0473v7">https://arxiv.org/abs/1409.0473v7</a></p>
</div>
<div id="ref-QNJ3b5bY">
<p>198. <strong>Learning the Graphical Structure of Electronic Health Records with Graph Convolutional Transformer</strong><br />
Edward Choi, Zhen Xu, Yujia Li, Michael W. Dusenberry, Gerardo Flores, Yuan Xue, Andrew M. Dai<br />
<em>arXiv</em> (2019-06-11) <a href="https://arxiv.org/abs/1906.04716v3">https://arxiv.org/abs/1906.04716v3</a></p>
</div>
</div>
<!-- default theme -->

<style>
    /* import google fonts */
    @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
    @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

    /* -------------------------------------------------- */
    /* global */
    /* -------------------------------------------------- */

    /* all elements */
    * {
        /* force sans-serif font unless specified otherwise */
        font-family: "Open Sans", "Helvetica", sans-serif;

        /* prevent text inflation on some mobile browsers */
        -webkit-text-size-adjust: none !important;
        -moz-text-size-adjust: none !important;
        -o-text-size-adjust: none !important;
        text-size-adjust: none !important;
    }

    @media only screen {
        /* "page" element */
        body {
            position: relative;
            box-sizing: border-box;
            font-size: 12pt;
            line-height: 1.5;
            max-width: 8.5in;
            margin: 20px auto;
            padding: 40px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* "page" element */
        body {
            padding: 20px;
            margin: 0;
            border-radius: 0;
            border: none;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
            background: none;
        }
    }

    /* -------------------------------------------------- */
    /* headings */
    /* -------------------------------------------------- */

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
        margin: 20px 0;
        padding: 0;
        font-weight: bold;
    }

    /* biggest heading */
    h1 {
        margin: 40px 0;
        text-align: center;
    }

    /* second biggest heading */
    h2 {
        margin-top: 30px;
        padding-bottom: 5px;
        border-bottom: solid 1px #bdbdbd;
    }

    /* -------------------------------------------------- */
    /* manuscript header */
    /* -------------------------------------------------- */

    /* manuscript title */
    header > h1 {
        margin: 0;
    }

    /* manuscript title caption text (ie "automatically generated on") */
    header + p {
        text-align: center;
        margin-top: 10px;
    }

    /* -------------------------------------------------- */
    /* text elements */
    /* -------------------------------------------------- */

    /* links */
    a {
        color: #2196f3;
    }

    /* normal links (not empty, not button link, not syntax highlighting link) */
    a:not(:empty):not(.button):not(.sourceLine) {
        padding-left: 1px;
        padding-right: 1px;
    }

    /* superscripts and subscripts */
    sub,
    sup {
        /* prevent from affecting line height */
        line-height: 0;
    }

    /* unordered and ordered lists*/
    ul,
    ol {
        padding-left: 20px;
    }

    /* class for styling text semibold */
    .semibold {
        font-weight: 600;
    }

    /* class for styling elements horizontally left aligned */
    .left {
        display: block;
        text-align: left;
        margin-left: auto;
        margin-right: 0;
        justify-content: left;
    }

    /* class for styling elements horizontally centered */
    .center {
        display: block;
        text-align: center;
        margin-left: auto;
        margin-right: auto;
        justify-content: center;
    }

    /* class for styling elements horizontally right aligned */
    .right {
        display: block;
        text-align: right;
        margin-left: 0;
        margin-right: auto;
        justify-content: right;
    }

    /* -------------------------------------------------- */
    /* section elements */
    /* -------------------------------------------------- */

    /* horizontal divider line */
    hr {
        border: none;
        height: 1px;
        background: #bdbdbd;
    }

    /* paragraphs, horizontal dividers, figures, tables, code */
    p,
    hr,
    figure,
    table,
    pre {
        /* treat all as "paragraphs", with consistent vertical margins */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* figures */
    /* -------------------------------------------------- */

    /* figure */
    figure {
        max-width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure caption */
    figcaption {
        padding: 0;
        padding-top: 10px;
    }

    /* figure image element */
    figure img {
        max-width: 100%;
        display: block;
        margin-left: auto;
        margin-right: auto;
    }

    /* figure auto-number */
    img + figcaption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* tables */
    /* -------------------------------------------------- */

    /* table */
    table {
        border-collapse: collapse;
        border-spacing: 0;
        width: 100%;
        margin-left: auto;
        margin-right: auto;
    }

    /* table cells */
    th,
    td {
        border: solid 1px #bdbdbd;
        padding: 10px;
        /* squash table if too wide for page by forcing line breaks */
        word-break: break-all;
        word-break: break-word;
    }

    /* header row and even rows */
    th,
    tr:nth-child(2n) {
        background-color: #fafafa;
    }

    /* odd rows */
    tr:nth-child(2n + 1) {
        background-color: #ffffff;
    }

    /* table caption */
    caption {
        text-align: left;
        padding: 0;
        padding-bottom: 10px;
    }

    /* table auto-number */
    table > caption > span:first-of-type,
    div.table_wrapper > table > caption > span:first-of-type {
        font-weight: bold;
        margin-right: 5px;
    }

    /* -------------------------------------------------- */
    /* code */
    /* -------------------------------------------------- */

    /* multi-line code block */
    pre {
        padding: 10px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
        break-inside: avoid;
        text-align: left;
    }

    /* inline code, ie code within normal text */
    :not(pre) > code {
        padding: 0 4px;
        background-color: #eeeeee;
        color: #000000;
        border-radius: 5px;
    }

    /* code text */
    /* apply all children, to reach syntax highlighting sub-elements */
    code,
    code * {
        /* force monospace font */
        font-family: "Source Code Pro", "Courier New", monospace;
    }

    /* -------------------------------------------------- */
    /* quotes */
    /* -------------------------------------------------- */

    /* quoted text */
    blockquote {
        margin: 0;
        padding: 0;
        border-left: 4px solid #bdbdbd;
        padding-left: 16px;
        break-inside: avoid;
    }

    /* -------------------------------------------------- */
    /* banners */
    /* -------------------------------------------------- */

    /* info banners */
    .banner {
        box-sizing: border-box;
        display: block;
        position: relative;
        width: 100%;
        margin-top: 20px;
        margin-bottom: 20px;
        padding: 20px;
        text-align: center;
    }

    /* paragraph in banner */
    .banner > p {
        margin: 0;
    }

    /* -------------------------------------------------- */
    /* highlight colors */
    /* -------------------------------------------------- */

    .white {
        background: #ffffff;
    }
    .lightgrey {
        background: #eeeeee;
    }
    .grey {
        background: #757575;
    }
    .darkgrey {
        background: #424242;
    }
    .black {
        background: #000000;
    }
    .lightred {
        background: #ffcdd2;
    }
    .lightyellow {
        background: #ffecb3;
    }
    .lightgreen {
        background: #dcedc8;
    }
    .lightblue {
        background: #e3f2fd;
    }
    .lightpurple {
        background: #f3e5f5;
    }
    .red {
        background: #f44336;
    }
    .orange {
        background: #ff9800;
    }
    .yellow {
        background: #ffeb3b;
    }
    .green {
        background: #4caf50;
    }
    .blue {
        background: #2196f3;
    }
    .purple {
        background: #9c27b0;
    }
    .white,
    .lightgrey,
    .lightred,
    .lightyellow,
    .lightgreen,
    .lightblue,
    .lightpurple,
    .orange,
    .yellow,
    .white a,
    .lightgrey a,
    .lightred a,
    .lightyellow a,
    .lightgreen a,
    .lightblue a,
    .lightpurple a,
    .orange a,
    .yellow a {
        color: #000000;
    }
    .grey,
    .darkgrey,
    .black,
    .red,
    .green,
    .blue,
    .purple,
    .grey a,
    .darkgrey a,
    .black a,
    .red a,
    .green a,
    .blue a,
    .purple a {
        color: #ffffff;
    }

    /* -------------------------------------------------- */
    /* buttons */
    /* -------------------------------------------------- */

    /* class for styling links like buttons */
    .button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        margin: 5px;
        padding: 10px 20px;
        font-size: 0.75em;
        font-weight: 600;
        text-transform: uppercase;
        text-decoration: none;
        letter-spacing: 1px;
        background: none;
        color: #2196f3;
        border: solid 1px #bdbdbd;
        border-radius: 5px;
    }

    /* buttons when hovered */
    .button:hover:not([disabled]),
    .icon_button:hover:not([disabled]) {
        cursor: pointer;
        background: #f5f5f5;
    }

    /* buttons when disabled */
    .button[disabled],
    .icon_button[disabled] {
        opacity: 0.35;
        pointer-events: none;
    }

    /* class for styling buttons containg only single icon */
    .icon_button {
        display: inline-flex;
        justify-content: center;
        align-items: center;
        text-decoration: none;
        margin: 0;
        padding: 0;
        background: none;
        border-radius: 5px;
        border: none;
        width: 20px;
        height: 20px;
        min-width: 20px;
        min-height: 20px;
    }

    /* icon button inner svg image */
    .icon_button > svg {
        height: 16px;
    }

    /* -------------------------------------------------- */
    /* icons */
    /* -------------------------------------------------- */

    /* class for styling icons inline with text */
    .inline_icon {
        height: 1em;
        position: relative;
        top: 0.125em;
    }

    /* -------------------------------------------------- */
    /* print control */
    /* -------------------------------------------------- */

    @media print {
        @page {
            /* suggested printing margin */
            margin: 0.5in;
        }

        /* document and "page" elements */
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
        }

        /* "page" element */
        body {
            font-size: 11pt !important;
            line-height: 1.35;
        }

        /* all headings */
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            margin: 15px 0;
        }

        /* heading 1 */
        h1 {
            font-size: 1.75em;
        }

        /* heading 2 */
        h2 {
            font-size: 1.25em;
            margin-top: 0;
        }

        /* heading 3 */
        h3 {
            font-size: 1.10em;
        }

        /* figures and tables */
        figure, table {
            font-size: 0.85em;
        }

        /* table cells */
        th,
        td {
            padding: 5px;
        }

        /* shrink font awesome icons */
        i.fas,
        i.fab,
        i.far,
        i.fal {
            transform: scale(0.85);
        }

        /* decrease banner margins */
        .banner {
            margin-top: 15px;
            margin-bottom: 15px;
            padding: 15px;
        }

        /* class for centering an element vertically on its own page */
        .page_center {
            margin: auto;
            width: 100%;
            height: 100%;
            display: flex;
            align-items: center;
            vertical-align: middle;
            break-before: page;
            break-after: page;
        }

        /* always insert a page break before the element */
        .page_break_before {
            break-before: page;
        }

        /* always insert a page break after the element */
        .page_break_after {
            break-after: page;
        }

        /* avoid page break before the element */
        .page_break_before_avoid {
            break-before: avoid;
        }

        /* avoid page break after the element */
        .page_break_after_avoid {
            break-after: avoid;
        }

        /* avoid page break inside the element */
        .page_break_inside_avoid {
            break-inside: avoid;
        }
    }

    /* -------------------------------------------------- */
    /* override pandoc css quirks */
    /* -------------------------------------------------- */

    .sourceCode {
        /* prevent unsightly overflow in wide code blocks */
        overflow: auto !important;
    }

    div.sourceCode {
        /* prevent background fill on top-most code block  container */
        background: none !important;
    }

    .sourceCode * {
        /* force consistent line spacing */
        line-height: 1.5 !important;
    }

    div.sourceCode {
        /* style code block margins same as <pre> element */
        margin-top: 20px;
        margin-bottom: 20px;
    }

    /* -------------------------------------------------- */
    /* mathjax */
    /* -------------------------------------------------- */

    /* mathjax containers */
    .math.display > span:not(.MathJax_Preview) {
        /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
        display: flex !important;
        overflow-x: auto !important;
        overflow-y: hidden !important;
        justify-content: center;
        align-items: center;
        margin: 0 !important;
    }

    /* right click menu */
    .MathJax_Menu {
        border-radius: 5px !important;
        border: solid 1px #bdbdbd !important;
        box-shadow: none !important;
    }

    /* equation auto-number */
    span[id^="eq:"] > span.math.display + span {
        font-weight: 600;
    }

    /* equation */
    span[id^="eq:"] > span.math.display > span {
        /* nudge to make room for equation auto-number */
        margin-right: 40px !important;
    }

    /* -------------------------------------------------- */
    /* table scroll plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* table wrapper */
        .table_wrapper {
            /* show scrollbar on tables if necessary to prevent overflow */
            overflow: auto;
            width: 100%;
            margin: 20px 0;
        }

        /* table within table wrapper */
        .table_wrapper table,
        .table_wrapper table * {
            /* don't break table words */
            word-break: normal !important;
        }

        .table_wrapper > table {
            /* move margins from table to table_wrapper to allow margin collapsing */
            margin: 0;
        }
    }

    /* -------------------------------------------------- */
    /* anchors plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anchor button */
        .anchor {
            opacity: 0;
            margin-left: 5px;
        }

        /* anchor buttons within <h2>'s */
        h2 .anchor {
            margin-left: 10px;
        }

        /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
        *:hover > .anchor,
        .anchor:hover,
        .anchor:focus {
            opacity: 1;
        }

        /* anchor button when hovered */
        .anchor:hover {
            cursor: pointer;
        }
    }

    /* always show anchor button on devices with no mouse/hover ability */
    @media (hover: none) {
        .anchor {
            opacity: 1;
        }
    }

    /* always hide anchor button on print */
    @media only print {
        .anchor {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* accordion plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* accordion arrow button */
        .accordion_arrow {
            margin-right: 10px;
        }

        /* arrow icon when <h2> data-collapsed attribute true */
        h2[data-collapsed="true"] > .accordion_arrow > svg {
            transform: rotate(-90deg);
        }

        /* all elements (except <h2>'s) when data-collapsed attribute true */
        *:not(h2)[data-collapsed="true"] {
            display: none;
        }

        /* accordion arrow button when hovered and <h2>'s when hovered */
        .accordion_arrow:hover,
        h2[data-collapsed="true"]:hover,
        h2[data-collapsed="false"]:hover {
            cursor: pointer;
        }
    }

    /* always hide accordion arrow button on print */
    @media only print {
        .accordion_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* tooltips plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* tooltip container */
        #tooltip {
            position: absolute;
            width: 50%;
            min-width: 240px;
            max-width: 75%;
            z-index: 1;
        }

        /* tooltip content */
        #tooltip_content {
            margin-bottom: 5px;
            padding: 20px;
            border-radius: 5px;
            border: solid 1px #bdbdbd;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            background: #ffffff;
            word-break: break-word;
        }

        /* tooltip copy of paragraphs and figures */
        #tooltip_content > p,
        #tooltip_content > figure {
            margin: 0;
            max-height: 320px;
            overflow-y: auto;
        }

        /* tooltip copy of <img> */
        #tooltip_content > figure > img {
            max-height: 260px;
        }

        /* navigation bar */
        #tooltip_nav_bar {
            margin-top: 10px;
            text-align: center;
        }

        /* navigation bar previous/next buton */
        #tooltip_nav_bar > .icon_button {
            position: relative;
            top: 3px;
        }

        /* navigation bar previous button */
        #tooltip_nav_bar > .icon_button:first-of-type {
            margin-right: 5px;
        }

        /* navigation bar next button */
        #tooltip_nav_bar > .icon_button:last-of-type {
            margin-left: 5px;
        }
    }

    /* always hide tooltip on print */
    @media only print {
        #tooltip {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* jump to first plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* jump button */
        .jump_arrow {
            position: relative;
            top: 0.125em;
            margin-right: 5px;
        }
    }

    /* always hide jump button on print */
    @media only print {
        .jump_arrow {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* link highlight plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* anything with data-highlighted attribute true */
        [data-highlighted="true"] {
            background: #ffeb3b;
        }

        /* anything with data-selected attribute true */
        [data-selected="true"] {
            background: #ff8a65 !important;
        }

        /* animation definition for glow */
        @keyframes highlight_glow {
            0% {
                background: none;
            }
            10% {
                background: #bbdefb;
            }
            100% {
                background: none;
            }
        }

        /* anything with data-glow attribute true */
        [data-glow="true"] {
            animation: highlight_glow 2s;
        }
    }

    /* -------------------------------------------------- */
    /* table of contents plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* toc panel */
        #toc_panel {
            box-sizing: border-box;
            position: fixed;
            top: 0;
            left: 0;
            background: #ffffff;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
            z-index: 2;
        }

        /* toc panel when closed */
        #toc_panel[data-open="false"] {
            min-width: 60px;
            width: 60px;
            height: 60px;
            border-right: solid 1px #bdbdbd;
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc panel when open */
        #toc_panel[data-open="true"] {
            min-width: 260px;
            max-width: 480px;
            /* keep panel edge consistent distance away from "page" edge */
            width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
            bottom: 0;
            border-right: solid 1px #bdbdbd;
        }

        /* toc panel header */
        #toc_header {
            box-sizing: border-box;
            display: flex;
            flex-direction: row;
            align-items: center;
            height: 60px;
            margin: 0;
            padding: 20px;
        }

        /* toc panel header when hovered */
        #toc_header:hover {
            cursor: pointer;
        }

        /* toc panel header when panel open */
        #toc_panel[data-open="true"] > #toc_header {
            border-bottom: solid 1px #bdbdbd;
        }

        /* toc open/close header button */
        #toc_button {
            margin-right: 20px;
        }

        /* hide toc list and header text when closed */
        #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
        #toc_panel[data-open="false"] > #toc_list {
            display: none;
        }

        /* toc list of entries */
        #toc_list {
            box-sizing: border-box;
            width: 100%;
            padding: 20px;
            position: absolute;
            top: calc(60px + 1px);
            bottom: 0;
            overflow: auto;
        }

        /* toc entry, link to section in document */
        .toc_link {
            display: block;
            padding: 5px;
            position: relative;
            font-weight: 600;
            text-decoration: none;
        }

        /* toc entry when hovered or when "viewed" */
        .toc_link:hover,
        .toc_link[data-viewing="true"] {
            background: #f5f5f5;
        }

        /* toc entry, level 1 indentation */
        .toc_link[data-level="1"] {
            margin-left: 0;
        }

        /* toc entry, level 2 indentation */
        .toc_link[data-level="2"] {
            margin-left: 20px;
        }

        /* toc entry, level 3 indentation */
        .toc_link[data-level="3"] {
            margin-left: 40px;
        }

        /* toc entry, level 4 indentation */
        .toc_link[data-level="4"] {
            margin-left: 60px;
        }

        /* toc entry bullets */
        #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
            position: absolute;
            left: -15px;
            top: -1px;
            font-size: 1.5em;
        }

        /* toc entry, level 2 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
            content: "\2022";
        }

        /* toc entry, level 3 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
            content: "\25AB";
        }

        /* toc entry, level 4 bullet */
        #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
            content: "-";
        }
    }

    /* when on screen < 8.5in wide */
    @media only screen and (max-width: 8.5in) {
        /* push <body> ("page") element down to make room for toc icon */
        .toc_body_nudge {
            padding-top: 60px;
        }

        /* toc icon when panel closed and not hovered */
        #toc_panel[data-open="false"]:not(:hover) {
            background: rgba(255, 255, 255, 0.75);
        }
    }

    /* always hide toc panel on print */
    @media only print {
        #toc_panel {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* lightbox plugin */
    /* -------------------------------------------------- */

    @media only screen {
        /* regular <img> in document when hovered */
        .lightbox_document_img:hover {
            cursor: pointer;
        }

        .body_no_scroll {
            overflow: hidden !important;
        }

        /* screen overlay */
        #lightbox_overlay {
            display: flex;
            flex-direction: column;
            position: fixed;
            left: 0;
            top: 0;
            right: 0;
            bottom: 0;
            background: rgba(0, 0, 0, 0.75);
            z-index: 3;
        }

        /* middle area containing lightbox image */
        #lightbox_image_container {
            flex-grow: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            overflow: hidden;
            position: relative;
            padding: 20px;
        }

        /* bottom area containing caption */
        #lightbox_bottom_container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100px;
            min-height: 100px;
            max-height: 100px;
            background: rgba(0, 0, 0, 0.5);
        }

        /* image number info text box */
        #lightbox_number_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            left: 2px;
            top: 0;
            z-index: 4;
        }

        /* zoom info text box */
        #lightbox_zoom_info {
            position: absolute;
            color: #ffffff;
            font-weight: 600;
            right: 2px;
            top: 0;
            z-index: 4;
        }

        /* copy of image caption */
        #lightbox_caption {
            box-sizing: border-box;
            display: inline-block;
            width: 100%;
            max-height: 100%;
            padding: 10px 0;
            text-align: center;
            overflow-y: auto;
            color: #ffffff;
        }

        /* navigation previous/next button */
        .lightbox_button {
            width: 100px;
            height: 100%;
            min-width: 100px;
            min-height: 100%;
            color: #ffffff;
        }

        /* navigation previous/next button when hovered */
        .lightbox_button:hover {
            background: none !important;
        }

        /* navigation button icon */
        .lightbox_button > svg {
            height: 25px;
        }

        /* figure auto-number */
        #lightbox_caption > span:first-of-type {
            font-weight: bold;
            margin-right: 5px;
        }

        /* lightbox image when hovered */
        #lightbox_img:hover {
            cursor: grab;
        }

        /* lightbox image when grabbed */
        #lightbox_img:active {
            cursor: grabbing;
        }
    }

    /* when on screen < 480px wide */
    @media only screen and (max-width: 480px) {
        /* make navigation buttons skinnier on small screens to make more room for caption text */
        .lightbox_button {
            width: 50px;
            min-width: 50px;
        }
    }

    /* always hide lightbox on print */
    @media only print {
        #lightbox_overlay {
            display: none;
        }
    }

    /* -------------------------------------------------- */
    /* hypothesis (annotations) plugin */
    /* -------------------------------------------------- */

    /* side panel */
    .annotator-frame {
        width: 280px !important;
        z-index: 0 !important;
    }

    /* match highlight color to rest of theme */
    .annotator-highlights-always-on .annotator-hl {
        background-color: #ffeb3b !important;
    }

    /* match focused color to rest of theme */
    .annotator-hl.annotator-hl-focused {
        background-color: #ff8a65 !important;
    }

    /* match bucket bar color to rest of theme */
    .annotator-bucket-bar {
        background: #f5f5f5 !important;
    }

    /* always hide toolbar and tooltip on print */
    @media only print {
        .annotator-frame {
            display: none !important;
        }

        hypothesis-adder {
            display: none !important;
        }
    }
</style>
<!-- table scroll plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows tables that are too wide to fit within
        // the page to have a scrollbar instead of being squashed to fit.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tableScroll';

        // default plugin options
        const options = {
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // wrap each table in a container
            const tables = document.querySelectorAll('table');
            for (const table of tables)
                wrapElement(table).classList.add('table_wrapper');
            // table_wrapper CSS class in theme file provides scroll
            // functionality
        }

        // wrap element in div and return div
        function wrapElement(element) {
            const parent = element.parentNode;
            const wrapper = document.createElement('div');
            parent.replaceChild(wrapper, element);
            wrapper.appendChild(element);
            return wrapper;
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- anchors plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds an anchor next to each of a certain type
        // of element that provides a human-readable url to that specific
        // item/position in the document (eg "manuscript.html#abstract"). It
        // also makes it such that scrolling out of view of a target removes
        // its identifier from the url.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'anchors';

        // default plugin options
        const options = {
            // which types of elements to add anchors next to, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3, figure, table',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // add anchor to each element of specified types
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements)
                addAnchor(element);

            // attach scroll listener to window
            window.addEventListener('scroll', onScroll);
        }

        // when window is scrolled
        function onScroll() {
            // if url has hash and user has scrolled out of view of hash
            // target, remove hash from url
            const target = getHashTarget();
            if (target) {
                if (
                    target.getBoundingClientRect().top > window.innerHeight ||
                    target.getBoundingClientRect().bottom < 0
                )
                    history.pushState(null, null, ' ');
            }
        }

        // add anchor to element
        function addAnchor(element) {
            let withId; // element with unique id
            let addTo; // element to add anchor button to

            // if figure or table, modify withId and addTo to get expected
            // elements
            if (element.tagName.toLowerCase() === 'figure') {
                withId = element.querySelector('img');
                addTo = element.querySelector('figcaption');
            } else if (element.tagName.toLowerCase() === 'table') {
                withId =
                    element.previousElementSibling ||
                    element.parentNode.previousElementSibling;
                addTo = element.querySelector('caption');
            }

            withId = withId || element;
            addTo = addTo || element;
            const id = withId.id || withId.name || null;

            // do not add anchor if element doesn't have assigned id.
            // id is generated by pandoc and is assumed to be unique and
            // human-readable
            if (!id)
                return;

            // create anchor button
            const anchor = document.createElement('a');
            anchor.innerHTML = document.querySelector('.icon_link').innerHTML;
            anchor.title = 'Link to this part of the document';
            anchor.classList.add('icon_button', 'anchor');
            anchor.dataset.ignore = 'true';
            anchor.href = '#' + id;
            addTo.appendChild(anchor);
        }

        // get element that is target of link or url hash
        function getHashTarget() {
            const hash = window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector(
                '[id="' + id + '"], [name="' + id + '"]'
            );
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (hash.indexOf('#fig:') === 0)
                target = target.parentNode;
            if (hash.indexOf('#tbl:') === 0)
                target = target.nextElementSibling;

            return target;
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- link icon -->

<template class="icon_link">
    <!-- modified from: https://fontawesome.com/icons/link -->
    <svg width="16" height="16" viewBox="0 0 512 512">
        <path
            fill="currentColor"
            d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
        ></path>
    </svg>
</template>
<!-- accordion plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin allows sections of content under <h2> headings
        // to be collapsible.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'accordion';

        // default plugin options
        const options = {
            // whether to always start expanded ('false'), always start
            // collapsed ('true'), or start collapsed when screen small ('auto')
            startCollapsed: 'auto',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <h2> heading
            const headings = document.querySelectorAll('h2');
            for (const heading of headings) {
                addArrow(heading);

                // start expanded/collapsed based on option
                if (
                    options.startCollapsed === 'true' ||
                    (options.startCollapsed === 'auto' && isSmallScreen())
                )
                    collapseHeading(heading);
                else
                    expandHeading(heading);
            }

            // attach hash change listener to window
            window.addEventListener('hashchange', onHashChange);
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                goToElement(target);
        }

        // add arrow to heading
        function addArrow(heading) {
            // add arrow button
            const arrow = document.createElement('button');
            arrow.innerHTML = document.querySelector(
                '.icon_angle_down'
            ).innerHTML;
            arrow.classList.add('icon_button', 'accordion_arrow');
            heading.insertBefore(arrow, heading.firstChild);

            // attach click listener to heading and button
            heading.addEventListener('click', onHeadingClick);
            arrow.addEventListener('click', onArrowClick);
        }

        // determine if on mobile-like device with small screen
        function isSmallScreen() {
            return Math.min(window.innerWidth, window.innerHeight) < 480;
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get element that is target of hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector(
                '[id="' + id + '"], [name="' + id + '"]'
            );
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (hash.indexOf('#fig:') === 0)
                target = target.parentNode;
            if (hash.indexOf('#tbl:') === 0)
                target = target.nextElementSibling;

            return target;
        }

        // when <h2> heading is clicked
        function onHeadingClick(event) {
            // only collapse if <h2> itself is target of click (eg, user did
            // not click on anchor within <h2>)
            if (event.target === this)
                toggleCollapse(this);
        }

        // when arrow button is clicked
        function onArrowClick() {
            toggleCollapse(this.parentNode);
        }

        // collapse section if expanded, expand if collapsed
        function toggleCollapse(heading) {
            if (heading.dataset.collapsed === 'false')
                collapseHeading(heading);
            else
                expandHeading(heading);
        }

        // elements to exclude from collapse, such as table of contents panel,
        // hypothesis panel, etc
        const exclude = '#toc_panel, div.annotator-frame, #lightbox_overlay';

        // collapse section
        function collapseHeading(heading) {
            heading.setAttribute('data-collapsed', 'true');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'true');
        }

        // expand section
        function expandHeading(heading) {
            heading.setAttribute('data-collapsed', 'false');
            const children = getChildren(heading);
            for (const child of children)
                child.setAttribute('data-collapsed', 'false');
        }

        // get list of elements between this <h2> and next <h2> or <h1>
        // ("children" of the <h2> section)
        function getChildren(heading) {
            return nextUntil(heading, 'h2, h1', exclude);
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get list of elements after a start element up to element matching
        // query
        function nextUntil(element, query, exclude) {
            const elements = [];
            while (element = element.nextElementSibling, element) {
                if (element.matches(query))
                    break;
                if (!element.matches(exclude))
                    elements.push(element);
            }
            return elements;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
    <!-- modified from: https://fontawesome.com/icons/angle-down -->
    <svg width="16" height="16" viewBox="0 0 448 512">
        <path
            fill="currentColor"
            d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
        ></path>
    </svg>
</template>
<!-- tooltips plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when the user hovers or
        // focuses a link to a citation or figure, a tooltip appears with a
        // preview of the reference content, along with arrows to navigate
        // between instances of the same reference in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tooltips';

        // default plugin options
        const options = {
            // whether user must click off to close tooltip instead of just
            // un-hovering
            clickClose: 'false',
            // delay (in ms) between opening and closing tooltip
            delay: '100',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach hover and focus listeners to link
                link.addEventListener('mouseover', onLinkHover);
                link.addEventListener('mouseleave', onLinkUnhover);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('touchend', onLinkTouch);
            }

            // attach mouse, key, and resize listeners to window
            window.addEventListener('mousedown', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('keyup', onKeyUp);
            window.addEventListener('resize', onResize);
        }

        // when link is hovered
        function onLinkHover() {
            // function to open tooltip
            const delayOpenTooltip = function() {
                openTooltip(this);
            }.bind(this);

            // run open function after delay
            this.openTooltipTimer = window.setTimeout(
                delayOpenTooltip,
                options.delay
            );
        }

        // when mouse leaves link
        function onLinkUnhover() {
            // cancel opening tooltip
            window.clearTimeout(this.openTooltipTimer);

            // don't close on unhover if option specifies
            if (options.clickClose === 'true')
                return;

            // function to close tooltip
            const delayCloseTooltip = function() {
                // if tooltip open and if mouse isn't over tooltip, close
                const tooltip = document.getElementById('tooltip');
                if (tooltip && !tooltip.matches(':hover'))
                    closeTooltip();
            };

            // run close function after delay
            this.closeTooltipTimer = window.setTimeout(
                delayCloseTooltip,
                options.delay
            );
        }

        // when link is focused (tabbed to)
        function onLinkFocus(event) {
            openTooltip(this);
        }

        // when link is touched on touch screen
        function onLinkTouch(event) {
            // attempt to force hover state on first tap always, and trigger
            // regular link click (and navigation) on second tap
            if (event.target === document.activeElement)
                event.target.click();
            else {
                document.activeElement.blur();
                event.target.focus();
            }
            if (event.cancelable)
                event.preventDefault();
            event.stopPropagation();
            return false;
        }

        // when mouse is clicked anywhere in window
        function onClick(event) {
            closeTooltip();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'tooltip_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'tooltip_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeTooltip();
                    break;
            }
        }

        // when window is resized or zoomed
        function onResize() {
            closeTooltip();
        }

        // get all links of types we wish to handle
        function getLinks() {
            const queries = [];
            // exclude buttons, anchor links, toc links, etc
            const exclude =
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            queries.push('a[href^="#ref-"]' + exclude); // citation links
            queries.push('a[href^="#fig:"]' + exclude); // figure links
            const query = queries.join(', ');
            return document.querySelectorAll(query);
        }

        // get links with same target, get index of link in set, get total
        // same links
        function getSameLinks(link) {
            const sameLinks = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    sameLinks.push(otherLink);
            }

            return {
                elements: sameLinks,
                index: sameLinks.indexOf(link),
                total: sameLinks.length
            };
        }

        // open tooltip
        function openTooltip(link) {
            // delete tooltip if it exists, start fresh
            closeTooltip();

            // make tooltip element
            const tooltip = makeTooltip(link);

            // if source couldn't be found and tooltip not made, exit
            if (!tooltip)
                return;

            // make navbar elements
            const navBar = makeNavBar(link);
            if (navBar)
                tooltip.firstElementChild.appendChild(navBar);

            // attach tooltip to page
            document.body.appendChild(tooltip);

            // position tooltip
            const position = function() {
                positionTooltip(link);
            };
            position();

            // if tooltip contains images, position again after they've loaded
            const imgs = tooltip.querySelectorAll('img');
            for (const img of imgs)
                img.addEventListener('load', position);
        }

        // close (delete) tooltip
        function closeTooltip() {
            const tooltip = document.getElementById('tooltip');
            if (tooltip)
                tooltip.remove();
        }

        // make tooltip
        function makeTooltip(link) {
            // get target element that link points to
            const source = getSource(link);

            // if source can't be found, exit
            if (!source)
                return;

            // create new tooltip
            const tooltip = document.createElement('div');
            tooltip.id = 'tooltip';
            const tooltipContent = document.createElement('div');
            tooltipContent.id = 'tooltip_content';
            tooltip.appendChild(tooltipContent);

            // make copy of source node and put in tooltip
            const sourceCopy = makeCopy(source);
            tooltipContent.appendChild(sourceCopy);

            // attach mouse event listeners
            tooltip.addEventListener('click', onTooltipClick);
            tooltip.addEventListener('mousedown', onTooltipClick);
            tooltip.addEventListener('touchstart', onTooltipClick);
            tooltip.addEventListener('mouseleave', onTooltipUnhover);

            // (for interaction with lightbox plugin)
            // transfer click on tooltip copied img to original img
            const sourceImg = source.querySelector('img');
            const sourceCopyImg = sourceCopy.querySelector('img');
            if (sourceImg && sourceCopyImg) {
                const clickImg = function() {
                    sourceImg.click();
                    closeTooltip();
                };
                sourceCopyImg.addEventListener('click', clickImg);
            }

            return tooltip;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // when tooltip is clicked
        function onTooltipClick(event) {
            // when user clicks on tooltip, stop click from transferring
            // outside of tooltip (eg, click off to close tooltip, or eg click
            // off to unhighlight same refs)
            event.stopPropagation();
        }

        // when tooltip is unhovered
        function onTooltipUnhover(event) {
            if (options.clickClose === 'true')
                return;

            // make sure new mouse/touch/focus no longer over tooltip or any
            // element within it
            const tooltip = document.getElementById('tooltip');
            if (!tooltip)
                return;
            if (this.contains(event.relatedTarget))
                return;

            closeTooltip();
        }

        // make nav bar to go betwen prev/next instances of same reference
        function makeNavBar(link) {
            // find other links to the same source
            const sameLinks = getSameLinks(link);

            // don't show nav bar when singular reference
            if (sameLinks.total <= 1)
                return;

            // find prev/next links with same target
            const prevLink = getPrevLink(link, sameLinks);
            const nextLink = getNextLink(link, sameLinks);

            // create nav bar
            const navBar = document.createElement('div');
            navBar.id = 'tooltip_nav_bar';
            const text = sameLinks.index + 1 + ' of ' + sameLinks.total;

            // create nav bar prev/next buttons
            const prevButton = document.createElement('button');
            const nextButton = document.createElement('button');
            prevButton.id = 'tooltip_prev_button';
            nextButton.id = 'tooltip_next_button';
            prevButton.title =
                'Jump to the previous occurence of this item in the document [←]';
            nextButton.title =
                'Jump to the next occurence of this item in the document [→]';
            prevButton.classList.add('icon_button');
            nextButton.classList.add('icon_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;
            navBar.appendChild(prevButton);
            navBar.appendChild(document.createTextNode(text));
            navBar.appendChild(nextButton);

            // attach click listeners to buttons
            prevButton.addEventListener('click', function() {
                onPrevNextClick(link, prevLink);
            });
            nextButton.addEventListener('click', function() {
                onPrevNextClick(link, nextLink);
            });

            return navBar;
        }

        // get previous link with same target
        function getPrevLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if < 1
            let index;
            if (sameLinks.index - 1 >= 0)
                index = sameLinks.index - 1;
            else
                index = sameLinks.total - 1;
            return sameLinks.elements[index];
        }

        // get next link with same target
        function getNextLink(link, sameLinks) {
            if (!sameLinks)
                sameLinks = getSameLinks(link);
            // wrap index to other side if > total
            let index;
            if (sameLinks.index + 1 <= sameLinks.total - 1)
                index = sameLinks.index + 1;
            else
                index = 0;
            return sameLinks.elements[index];
        }

        // get element that is target of link or url hash
        function getSource(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector(
                '[id="' + id + '"], [name="' + id + '"]'
            );
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (hash.indexOf('#ref-') === 0)
                target = target.querySelector('p');
            else if (hash.indexOf('#fig:') === 0)
                target = target.parentNode;
            else if (hash.indexOf('#tbl:') === 0)
                return;

            return target;
        }

        // when prev/next arrow button is clicked
        function onPrevNextClick(link, prevNextLink) {
            if (link && prevNextLink)
                goToElement(prevNextLink, window.innerHeight * 0.5);
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // determine position to place tooltip based on link position in
        // viewport and tooltip size
        function positionTooltip(link, left, top) {
            const tooltipElement = document.getElementById('tooltip');
            if (!tooltipElement)
                return;

            // get convenient vars for position/dimensions of
            // link/tooltip/page/view
            link = getRectInPage(link);
            const tooltip = getRectInPage(tooltipElement);
            const view = getRectInPage();

            // horizontal positioning
            if (left)
                // use explicit value
                left = left;
            else if (link.left + tooltip.width < view.right)
                // fit tooltip to right of link
                left = link.left;
            else if (link.right - tooltip.width > view.left)
                // fit tooltip to left of link
                left = link.right - tooltip.width;
            // center tooltip in view
            else
                left = (view.right - view.left) / 2 - tooltip.width / 2;

            // vertical positioning
            if (top)
                // use explicit value
                top = top;
            else if (link.top - tooltip.height > view.top)
                // fit tooltip above link
                top = link.top - tooltip.height;
            else if (link.bottom + tooltip.height < view.bottom)
                // fit tooltip below link
                top = link.bottom;
            else {
                // center tooltip in view
                top = view.top + view.height / 2 - tooltip.height / 2;
                // nudge off of link to left/right if possible
                if (link.right + tooltip.width < view.right)
                    left = link.right;
                else if (link.left - tooltip.width > view.left)
                    left = link.left - tooltip.width;
            }

            tooltipElement.style.left = left + 'px';
            tooltipElement.style.top = top + 'px';
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get position of element relative to page
        function getRectInPage(element) {
            const rect = getRectInView(element);
            const body = getRectInView(document.body);

            const newRect = {};
            newRect.left = rect.left - body.left;
            newRect.top = rect.top - body.top;
            newRect.right = rect.right - body.left;
            newRect.bottom = rect.bottom - body.top;
            newRect.width = rect.width;
            newRect.height = rect.height;

            return newRect;
        }

        // (for interaction with accordion plugin)
        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // (for interaction with accordion plugin)
        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- jump to first plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin adds a button next to each reference entry,
        // figure, and table that jumps the page to the first occurrence of a
        // link to that item in the manuscript.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'jumpToFirst';

        // default plugin options
        const options = {
            // whether to add buttons next to reference entries
            references: 'true',
            // whether to add buttons next to figures
            figures: 'true',
            // whether to add buttons next to tables
            tables: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            if (options.references !== 'false')
                makeReferenceButtons();
            if (options.figures !== 'false')
                makeFigureButtons();
            if (options.tables !== 'false')
                makeTableButtons();
        }

        // when jump button clicked
        function onButtonClick() {
            const first = getFirstOccurrence(this.dataset.id);
            if (!first)
                return;

            // update url hash so navigating "back" in history will return
            // user to jump button
            window.location.hash = this.dataset.id;
            // scroll to link
            window.setTimeout(function() {
                goToElement(first, window.innerHeight * 0.5);
            }, 0);
        }

        // get first occurence of link to item in document
        function getFirstOccurrence(id) {
            let query = 'a';
            query += '[href="#' + id + '"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelector(query);
        }

        // add button next to each reference entry
        function makeReferenceButtons() {
            const references = document.querySelectorAll('div[id^="ref-"]');
            for (const reference of references) {
                // get reference id and element to add button to
                const id = reference.id;
                const container = reference.firstElementChild;
                const first = getFirstOccurrence(id);

                // if can't find link to reference, ignore
                if (!first)
                    continue;

                // make jump button
                let button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this reference in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.innerHTML = button.outerHTML + container.innerHTML;
                button = container.firstElementChild;
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeFigureButtons() {
            const figures = document.querySelectorAll('img[id^="fig:"]');
            for (const figure of figures) {
                // get figure id and element to add button to
                const id = figure.id;
                const container = figure.nextElementSibling;
                const first = getFirstOccurrence(id);

                // if can't find link to figure, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this figure in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // add button next to each figure
        function makeTableButtons() {
            const tables = document.querySelectorAll('a[name^="tbl:"]');
            for (const table of tables) {
                // get ref id and element to add button to
                const id = table.name;
                const container = table.nextElementSibling.querySelector(
                    'caption'
                );
                const first = getFirstOccurrence(id);

                // if can't find link to table, ignore
                if (!first)
                    continue;

                // make jump button
                const button = document.createElement('button');
                button.classList.add('icon_button', 'jump_arrow');
                button.title =
                    'Jump to the first occurence of this table in the document';
                button.innerHTML = document.querySelector(
                    '.icon_angle_double_up'
                ).innerHTML;
                button.dataset.id = id;
                button.dataset.ignore = 'true';
                container.insertBefore(button, container.firstElementChild);
                button.addEventListener('click', onButtonClick);
            }
        }

        // scroll to and focus element
        function goToElement(element, offset) {
            // expand accordion section if collapsed
            expandElement(element);
            const y =
                getRectInView(element).top -
                getRectInView(document.documentElement).top -
                (offset || 0);
            // trigger any function listening for "onscroll" event
            window.dispatchEvent(new Event('scroll'));
            window.scrollTo(0, y);
            document.activeElement.blur();
            element.focus();
        }

        // get position/dimensions of element or viewport
        function getRectInView(element) {
            let rect = {};
            rect.left = 0;
            rect.top = 0;
            rect.right = document.documentElement.clientWidth;
            rect.bottom = document.documentElement.clientHeight;
            let style = {};

            if (element instanceof HTMLElement) {
                rect = element.getBoundingClientRect();
                style = window.getComputedStyle(element);
            }

            const margin = {};
            margin.left = parseFloat(style.marginLeftWidth) || 0;
            margin.top = parseFloat(style.marginTopWidth) || 0;
            margin.right = parseFloat(style.marginRightWidth) || 0;
            margin.bottom = parseFloat(style.marginBottomWidth) || 0;

            const border = {};
            border.left = parseFloat(style.borderLeftWidth) || 0;
            border.top = parseFloat(style.borderTopWidth) || 0;
            border.right = parseFloat(style.borderRightWidth) || 0;
            border.bottom = parseFloat(style.borderBottomWidth) || 0;

            const newRect = {};
            newRect.left = rect.left + margin.left + border.left;
            newRect.top = rect.top + margin.top + border.top;
            newRect.right = rect.right + margin.right + border.right;
            newRect.bottom = rect.bottom + margin.bottom + border.bottom;
            newRect.width = newRect.right - newRect.left;
            newRect.height = newRect.bottom - newRect.top;

            return newRect;
        }

        // get closest element before specified element that matches query
        function firstBefore(element, query) {
            while (
                element &&
                element !== document.body &&
                !element.matches(query)
            )
                element = element.previousElementSibling || element.parentNode;

            return element;
        }

        // check if element is part of collapsed heading
        function isCollapsed(element) {
            while (element && element !== document.body) {
                if (element.dataset.collapsed === 'true')
                    return true;
                element = element.parentNode;
            }
            return false;
        }

        // (for interaction with accordion plugin)
        // expand heading containing element if necesary
        function expandElement(element) {
            if (isCollapsed(element)) {
                const heading = firstBefore(element, 'h2');
                if (heading)
                    heading.click();
            }
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
    <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
    <svg width="16" height="16" viewBox="0 0 320 512">
        <path
            fill="currentColor"
            d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
        ></path>
    </svg>
</template>
<!-- link highlight plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user hovers or
        // focuses a link, other links that have the same target will be
        // highlighted. It also makes it such that when clicking a link, the
        // target of the link (eg reference, figure, table) is briefly
        // highlighted.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'linkHighlight';

        // default plugin options
        const options = {
            // whether to also highlight links that go to external urls
            externalLinks: 'false',
            // whether user must click off to unhighlight instead of just
            // un-hovering
            clickUnhighlight: 'false',
            // whether to also highlight links that are unique
            highlightUnique: 'true',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            const links = getLinks();
            for (const link of links) {
                // attach mouse and focus listeners to link
                link.addEventListener('mouseenter', onLinkFocus);
                link.addEventListener('focus', onLinkFocus);
                link.addEventListener('mouseleave', onLinkUnhover);
            }

            // attach click and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('hashchange', onHashChange);

            // run hash change on window load in case user has navigated
            // directly to hash
            onHashChange();
        }

        // when link is focused (tabbed to) or hovered
        function onLinkFocus() {
            highlight(this);
        }

        // when link is unhovered
        function onLinkUnhover() {
            if (options.clickUnhighlight !== 'true')
                unhighlightAll();
        }

        // when the mouse is clicked anywhere in window
        function onClick(event) {
            unhighlightAll();
        }

        // when hash (eg manuscript.html#introduction) changes
        function onHashChange() {
            const target = getHashTarget();
            if (target)
                glowElement(target);
        }

        // get element that is target of link or url hash
        function getHashTarget(link) {
            const hash = link ? link.hash : window.location.hash;
            const id = hash.slice(1);
            let target = document.querySelector(
                '[id="' + id + '"], [name="' + id + '"]'
            );
            if (!target)
                return;

            // if figure or table, modify target to get expected element
            if (hash.indexOf('#fig:') === 0)
                target = target.parentNode;
            else if (hash.indexOf('#tbl:') === 0)
                target = target.nextElementSibling.querySelector('caption');

            return target;
        }

        // start glow sequence on an element
        function glowElement(element) {
            const startGlow = function() {
                onGlowEnd();
                element.dataset.glow = 'true';
                element.addEventListener('animationend', onGlowEnd);
            };
            const onGlowEnd = function() {
                element.removeAttribute('data-glow');
                element.removeEventListener('animationend', onGlowEnd);
            };
            startGlow();
        }

        // highlight link and all others with same target
        function highlight(link) {
            // force unhighlight all to start fresh
            unhighlightAll();

            // get links with same target
            if (!link)
                return;
            const sameLinks = getSameLinks(link);

            // if link unique and option is off, exit and don't highlight
            if (sameLinks.length <= 1 && options.highlightUnique !== 'true')
                return;

            // highlight all same links, and "select" (special highlight) this
            // one
            for (const sameLink of sameLinks) {
                if (sameLink === link)
                    sameLink.setAttribute('data-selected', 'true');
                else
                    sameLink.setAttribute('data-highlighted', 'true');
            }
        }

        // unhighlight all links
        function unhighlightAll() {
            const links = getLinks();
            for (const link of links) {
                link.setAttribute('data-selected', 'false');
                link.setAttribute('data-highlighted', 'false');
            }
        }

        // get links with same target
        function getSameLinks(link) {
            const results = [];
            const links = getLinks();
            for (const otherLink of links) {
                if (
                    otherLink.getAttribute('href') === link.getAttribute('href')
                )
                    results.push(otherLink);
            }
            return results;
        }

        // get all links of types we wish to handle
        function getLinks() {
            let query = 'a';
            if (options.externalLinks !== 'true')
                query += '[href^="#"]';
            // exclude buttons, anchor links, toc links, etc
            query +=
                ':not(.button):not(.icon_button):not(.anchor):not(.toc_link)';
            return document.querySelectorAll(query);
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>
<!-- table of contents plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin provides a "table of contents" (toc) panel on
        // the side of the document that allows the user to conveniently
        // navigate between sections of the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'tableOfContents';

        // default plugin options
        const options = {
            // which types of elements to add links for, in
            // "document.querySelector" format
            typesQuery: 'h1, h2, h3',
            // whether default behavior is to be closed ('false'), open
            // ('true'), or only open when screen wide enough to fit panel
            // ('auto'). note: still always starts closed when page loads.
            open: 'auto',
            // if list item is more than this many characters, text will be
            // truncated
            charLimit: '50',
            // whether or not to show bullets next to each toc item
            bullets: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // make toc panel and populate with entries (links to document
            // sections)
            const panel = makePanel();
            if (!panel)
                return;
            makeEntries(panel);
            document.body.insertBefore(panel, document.body.firstChild);

            closePanel();

            // attach click, scroll, and hash change listeners to window
            window.addEventListener('click', onClick);
            window.addEventListener('touchstart', onClick);
            window.addEventListener('scroll', onScroll);
            window.addEventListener('hashchange', onScroll);
            window.addEventListener('keyup', onKeyUp);
            onScroll();

            // add class to push document body down out of way of toc button
            document.body.classList.add('toc_body_nudge');
        }

        // determine if screen wide enough to fit toc panel
        function isSmallScreen() {
            // in default theme:
            // 816px = 8.5in = width of "page" (<body>) element
            // 260px = min width of toc panel (*2 for both sides of <body>)
            return window.innerWidth < 816 + 260 * 2;
        }

        // open/close panel based on option and screen size
        function openOrClosePanel() {
            if (
                options.open === 'true' ||
                (options.open === 'auto' && !isSmallScreen())
            )
                openPanel();
            else
                closePanel();
        }

        // when mouse is clicked anywhere in window
        function onClick() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                openOrClosePanel();
        }

        // when window is scrolled or hash changed
        function onScroll() {
            highlightViewed();
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            // close on esc
            if (event.key === 'Escape')
                closePanel();
        }

        // find entry of currently viewed document section in toc and highlight
        function highlightViewed() {
            const firstId = getFirstInView(options.typesQuery);

            // get toc entries (links), unhighlight all, then highlight viewed
            const list = document.getElementById('toc_list');
            if (!firstId || !list)
                return;
            const links = list.querySelectorAll('a');
            for (const link of links)
                link.dataset.viewing = 'false';
            const link = list.querySelector('a[href="#' + firstId + '"]');
            if (!link)
                return;
            link.dataset.viewing = 'true';
        }

        // get first or previous toc listed element in top half of view
        function getFirstInView(query) {
            // get all elements matching query and with id
            const elements = document.querySelectorAll(query);
            const elementsWithIds = [];
            for (const element of elements) {
                if (element.id)
                    elementsWithIds.push(element);
            }


            // get first or previous element in top half of view
            for (let i = 0; i < elementsWithIds.length; i++) {
                const element = elementsWithIds[i];
                const prevElement = elementsWithIds[Math.max(0, i - 1)];
                if (element.getBoundingClientRect().top >= 0) {
                    if (
                        element.getBoundingClientRect().top <
                        window.innerHeight / 2
                    )
                        return element.id;
                    else
                        return prevElement.id;
                }
            }
        }

        // make panel
        function makePanel() {
            // create panel
            const panel = document.createElement('div');
            panel.id = 'toc_panel';
            if (options.bullets === 'true')
                panel.dataset.bullets = 'true';

            // create header
            const header = document.createElement('div');
            header.id = 'toc_header';

            // create toc button
            const button = document.createElement('button');
            button.id = 'toc_button';
            button.innerHTML = document.querySelector(
                '.icon_th_list'
            ).innerHTML;
            button.classList.add('icon_button');

            // create header text
            const text = document.createElement('h3');
            text.innerHTML = 'Table of Contents';

            // create container for toc list
            const list = document.createElement('div');
            list.id = 'toc_list';

            // attach click listeners
            panel.addEventListener('click', onPanelClick);
            header.addEventListener('click', onHeaderClick);
            button.addEventListener('click', onButtonClick);

            // attach elements
            header.appendChild(button);
            header.appendChild(text);
            panel.appendChild(header);
            panel.appendChild(list);

            return panel;
        }

        // create toc entries (links) to each element of the specified types
        function makeEntries(panel) {
            const elements = document.querySelectorAll(options.typesQuery);
            for (const element of elements) {
                // do not add link if element doesn't have assigned id
                if (!element.id)
                    continue;

                // create link/list item
                const link = document.createElement('a');
                link.classList.add('toc_link');
                switch (element.tagName.toLowerCase()) {
                    case 'h1':
                        link.dataset.level = '1';
                        break;
                    case 'h2':
                        link.dataset.level = '2';
                        break;
                    case 'h3':
                        link.dataset.level = '3';
                        break;
                    case 'h4':
                        link.dataset.level = '4';
                        break;
                }
                link.title = element.innerText;
                let text = element.innerText;
                if (text.length > options.charLimit)
                    text = text.slice(0, options.charLimit) + '...';
                link.innerHTML = text;
                link.href = '#' + element.id;
                link.addEventListener('click', onLinkClick);

                // attach link
                panel.querySelector('#toc_list').appendChild(link);
            }
        }

        // when panel is clicked
        function onPanelClick(event) {
            // stop click from propagating to window/document and closing panel
            event.stopPropagation();
        }

        // when header itself is clicked
        function onHeaderClick(event) {
            togglePanel();
        }

        // when button is clicked
        function onButtonClick(event) {
            togglePanel();
            // stop header underneath button from also being clicked
            event.stopPropagation();
        }

        // when link is clicked
        function onLinkClick() {
            openOrClosePanel();
        }

        // open panel if closed, close if opened
        function togglePanel() {
            const panel = document.getElementById('toc_panel');
            if (!panel)
                return;

            if (panel.dataset.open === 'true')
                closePanel();
            else
                openPanel();
        }

        // open panel
        function openPanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'true';
        }

        // close panel
        function closePanel() {
            const panel = document.getElementById('toc_panel');
            if (panel)
                panel.dataset.open = 'false';
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- th list icon -->

<template class="icon_th_list">
    <!-- modified from: https://fontawesome.com/icons/th-list -->
    <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
        <path
            fill="currentColor"
            d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
            tabindex="-1"
        ></path>
    </svg>
</template>
<!-- lightbox plugin -->

<script>
    (function() {
        // /////////////////////////
        // DESCRIPTION
        // /////////////////////////

        // This Manubot plugin makes it such that when a user clicks on an
        // image, the image fills the screen and the user can pan/drag/zoom
        // the image and navigate between other images in the document.

        // /////////////////////////
        // OPTIONS
        // /////////////////////////

        // plugin name prefix for url parameters
        const pluginName = 'lightbox';

        // default plugin options
        const options = {
            // list of possible zoom/scale factors
            zoomSteps:
                '0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1,' +
                '1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8',
            // whether to fit image to view ('fit'), display at 100% and shrink
            // if necessary ('shrink'), or always display at 100% ('100')
            defaultZoom: 'fit',
            // whether to zoom in/out toward center of view ('true') or mouse
            // ('false')
            centerZoom: 'false',
            // whether plugin is on or not
            enabled: 'true'
        };

        // change options above, or override with url parameter, eg:
        // 'manuscript.html?pluginName-enabled=false'

        // /////////////////////////
        // SCRIPT
        // /////////////////////////

        // start script
        function start() {
            // run through each <img> element
            const imgs = document.querySelectorAll('figure > img');
            let count = 1;
            for (const img of imgs) {
                img.classList.add('lightbox_document_img');
                img.dataset.number = count;
                img.dataset.total = imgs.length;
                img.addEventListener('click', openLightbox);
                count++;
            }

            // attach mouse and key listeners to window
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('keyup', onKeyUp);
        }

        // when mouse is moved anywhere in window
        function onWindowMouseMove(event) {
            window.mouseX = event.clientX;
            window.mouseY = event.clientY;
        }

        // when key pressed
        function onKeyUp(event) {
            if (!event || !event.key)
                return;

            switch (event.key) {
                // trigger click of prev button
                case 'ArrowLeft':
                    const prevButton = document.getElementById(
                        'lightbox_prev_button'
                    );
                    if (prevButton)
                        prevButton.click();
                    break;
                // trigger click of next button
                case 'ArrowRight':
                    const nextButton = document.getElementById(
                        'lightbox_next_button'
                    );
                    if (nextButton)
                        nextButton.click();
                    break;
                // close on esc
                case 'Escape':
                    closeLightbox();
                    break;
            }
        }

        // open lightbox
        function openLightbox() {
            const lightbox = makeLightbox(this);
            if (!lightbox)
                return;

            blurBody(lightbox);
            document.body.appendChild(lightbox);
        }

        // make lightbox
        function makeLightbox(img) {
            // delete lightbox if it exists, start fresh
            closeLightbox();

            // create screen overlay containing lightbox
            const overlay = document.createElement('div');
            overlay.id = 'lightbox_overlay';

            // create image info boxes
            const numberInfo = document.createElement('div');
            const zoomInfo = document.createElement('div');
            numberInfo.id = 'lightbox_number_info';
            zoomInfo.id = 'lightbox_zoom_info';

            // create container for image
            const imageContainer = document.createElement('div');
            imageContainer.id = 'lightbox_image_container';
            const lightboxImg = makeLightboxImg(
                img,
                imageContainer,
                numberInfo,
                zoomInfo
            );
            imageContainer.appendChild(lightboxImg);

            // create bottom container for caption and navigation buttons
            const bottomContainer = document.createElement('div');
            bottomContainer.id = 'lightbox_bottom_container';
            const caption = makeCaption(img);
            const prevButton = makePrevButton(img);
            const nextButton = makeNextButton(img);
            bottomContainer.appendChild(prevButton);
            bottomContainer.appendChild(caption);
            bottomContainer.appendChild(nextButton);

            // attach top middle and bottom to overlay
            overlay.appendChild(numberInfo);
            overlay.appendChild(zoomInfo);
            overlay.appendChild(imageContainer);
            overlay.appendChild(bottomContainer);

            return overlay;
        }

        // make <img> object that is intuitively draggable and zoomable
        function makeLightboxImg(
            sourceImg,
            container,
            numberInfoBox,
            zoomInfoBox
        ) {
            // create copy of source <img>
            const img = sourceImg.cloneNode(true);
            img.classList.remove('lightbox_document_img');
            img.removeAttribute('id');
            img.removeAttribute('width');
            img.removeAttribute('height');
            img.style.position = 'unset';
            img.style.margin = '0';
            img.style.padding = '0';
            img.style.width = '';
            img.style.height = '';
            img.style.minWidth = '';
            img.style.minHeight = '';
            img.style.maxWidth = '';
            img.style.maxHeight = '';
            img.id = 'lightbox_img';

            // build sorted list of unique zoomSteps, always including a 100%
            let zoomSteps = [];
            const optionsZooms = options.zoomSteps.split(/[^0-9.]/);
            for (const optionZoom of optionsZooms) {
                const newZoom = parseFloat(optionZoom);
                if (newZoom && !zoomSteps.includes(newZoom))
                    zoomSteps.push(newZoom);
            }
            if (!zoomSteps.includes(1))
                zoomSteps.push(1);
            zoomSteps = zoomSteps.sort(function sortNumber(a, b) {
                return a - b;
            });

            // <img> object property variables
            let zoom = 1;
            let translateX = 0;
            let translateY = 0;
            let clickMouseX = undefined;
            let clickMouseY = undefined;
            let clickTranslateX = undefined;
            let clickTranslateY = undefined;

            updateNumberInfo();

            // update image numbers displayed in info box
            function updateNumberInfo() {
                numberInfoBox.innerHTML =
                    sourceImg.dataset.number + ' of ' + sourceImg.dataset.total;
            }

            // update zoom displayed in info box
            function updateZoomInfo() {
                let zoomInfo = zoom * 100;
                if (!Number.isInteger(zoomInfo))
                    zoomInfo = zoomInfo.toFixed(2);
                zoomInfoBox.innerHTML = zoomInfo + '%';
            }

            // move to closest zoom step above current zoom
            const zoomIn = function() {
                for (const zoomStep of zoomSteps) {
                    if (zoomStep > zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                updateTransform();
            };

            // move to closest zoom step above current zoom
            const zoomOut = function() {
                zoomSteps.reverse();
                for (const zoomStep of zoomSteps) {
                    if (zoomStep < zoom) {
                        zoom = zoomStep;
                        break;
                    }
                }
                zoomSteps.reverse();

                updateTransform();
            };

            // update display of <img> based on scale/translate properties
            const updateTransform = function() {
                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                // get new width/height after scale
                const rect = img.getBoundingClientRect();
                // limit translate
                translateX = Math.max(translateX, -rect.width / 2);
                translateX = Math.min(translateX, rect.width / 2);
                translateY = Math.max(translateY, -rect.height / 2);
                translateY = Math.min(translateY, rect.height / 2);

                // set transform
                img.style.transform =
                    'translate(' +
                    (translateX || 0) +
                    'px,' +
                    (translateY || 0) +
                    'px) scale(' +
                    (zoom || 1) +
                    ')';

                updateZoomInfo();
            };

            // fit <img> to container
            const fit = function() {
                // no x/y offset, 100% zoom by default
                translateX = 0;
                translateY = 0;
                zoom = 1;

                // widths of <img> and container
                const imgWidth = img.naturalWidth;
                const imgHeight = img.naturalHeight;
                const containerWidth = parseFloat(
                    window.getComputedStyle(container).width
                );
                const containerHeight = parseFloat(
                    window.getComputedStyle(container).height
                );

                // how much zooming is needed to fit <img> to container
                const xRatio = imgWidth / containerWidth;
                const yRatio = imgHeight / containerHeight;
                const maxRatio = Math.max(xRatio, yRatio);
                const newZoom = 1 / maxRatio;

                // fit <img> to container according to option
                if (options.defaultZoom === 'shrink') {
                    if (maxRatio > 1)
                        zoom = newZoom;
                } else if (options.defaultZoom === 'fit')
                    zoom = newZoom;

                updateTransform();
            };

            // when mouse wheel is rolled anywhere in container
            const onContainerWheel = function(event) {
                if (!event)
                    return;

                // let ctrl + mouse wheel to zoom behave as normal
                if (event.ctrlKey)
                    return;

                // prevent normal scroll behavior
                event.preventDefault();
                event.stopPropagation();

                // point around which to scale img
                const viewRect = container.getBoundingClientRect();
                const viewX = (viewRect.left + viewRect.right) / 2;
                const viewY = (viewRect.top + viewRect.bottom) / 2;
                const originX = options.centerZoom === 'true' ? viewX : mouseX;
                const originY = options.centerZoom === 'true' ? viewY : mouseY;

                // get point on image under origin
                const oldRect = img.getBoundingClientRect();
                const oldPercentX = (originX - oldRect.left) / oldRect.width;
                const oldPercentY = (originY - oldRect.top) / oldRect.height;

                // increment/decrement zoom
                if (event.deltaY < 0)
                    zoomIn();
                if (event.deltaY > 0)
                    zoomOut();

                // get offset between previous image point and origin
                const newRect = img.getBoundingClientRect();
                const offsetX =
                    originX - (newRect.left + newRect.width * oldPercentX);
                const offsetY =
                    originY - (newRect.top + newRect.height * oldPercentY);

                // translate image to keep image point under origin
                translateX += offsetX;
                translateY += offsetY;

                // perform translate
                updateTransform();
            };

            // when container is clicked
            function onContainerClick(event) {
                // if container itself is target of click, and not other
                // element above it
                if (event.target === this)
                    closeLightbox();
            }

            // when mouse button is pressed on image
            const onImageMouseDown = function(event) {
                // store original mouse position relative to image
                clickMouseX = window.mouseX;
                clickMouseY = window.mouseY;
                clickTranslateX = translateX;
                clickTranslateY = translateY;
                event.stopPropagation();
                event.preventDefault();
            };

            // when mouse button is released anywhere in window
            const onWindowMouseUp = function(event) {
                // reset original mouse position
                clickMouseX = undefined;
                clickMouseY = undefined;
                clickTranslateX = undefined;
                clickTranslateY = undefined;

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mouseup', onWindowMouseUp);
            };

            // when mouse is moved anywhere in window
            const onWindowMouseMove = function(event) {
                if (
                    clickMouseX === undefined ||
                    clickMouseY === undefined ||
                    clickTranslateX === undefined ||
                    clickTranslateY === undefined
                )
                    return;

                // offset image based on original and current mouse position
                translateX = clickTranslateX + window.mouseX - clickMouseX;
                translateY = clickTranslateY + window.mouseY - clickMouseY;
                updateTransform();
                event.preventDefault();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('mousemove', onWindowMouseMove);
            };

            // when window is resized
            const onWindowResize = function(event) {
                fit();

                // remove global listener if lightbox removed from document
                if (!document.body.contains(container))
                    window.removeEventListener('resize', onWindowResize);
            };

            // attach the necessary event listeners
            img.addEventListener('dblclick', fit);
            img.addEventListener('mousedown', onImageMouseDown);
            container.addEventListener('wheel', onContainerWheel);
            container.addEventListener('mousedown', onContainerClick);
            container.addEventListener('touchstart', onContainerClick);
            window.addEventListener('mouseup', onWindowMouseUp);
            window.addEventListener('mousemove', onWindowMouseMove);
            window.addEventListener('resize', onWindowResize);

            // run fit() after lightbox atttached to document and <img> Loaded
            // so needed container and img dimensions available
            img.addEventListener('load', fit);

            return img;
        }

        // make caption
        function makeCaption(img) {
            const caption = document.createElement('div');
            caption.id = 'lightbox_caption';
            const captionSource = img.nextElementSibling;
            if (captionSource.tagName.toLowerCase() === 'figcaption') {
                const captionCopy = makeCopy(captionSource);
                caption.innerHTML = captionCopy.innerHTML;
            }

            caption.addEventListener('touchstart', function(event) {
                event.stopPropagation();
            });

            return caption;
        }

        // make carbon copy of html dom element
        function makeCopy(source) {
            const sourceCopy = source.cloneNode(true);

            // delete elements marked with ignore (eg anchor and jump buttons)
            const deleteFromCopy = sourceCopy.querySelectorAll(
                '[data-ignore="true"]'
            );
            for (const element of deleteFromCopy)
                element.remove();

            // delete certain element attributes
            const attributes = [
                'id',
                'data-collapsed',
                'data-selected',
                'data-highlighted',
                'data-glow'
            ];
            for (const attribute of attributes) {
                sourceCopy.removeAttribute(attribute);
                const elements = sourceCopy.querySelectorAll(
                    '[' + attribute + ']'
                );
                for (const element of elements)
                    element.removeAttribute(attribute);
            }

            return sourceCopy;
        }

        // make button to jump to previous image in document
        function makePrevButton(img) {
            const prevButton = document.createElement('button');
            prevButton.id = 'lightbox_prev_button';
            prevButton.title = 'Jump to the previous image in the document [←]';
            prevButton.classList.add('icon_button', 'lightbox_button');
            prevButton.innerHTML = document.querySelector(
                '.icon_caret_left'
            ).innerHTML;

            // attach click listeners to button
            prevButton.addEventListener('click', function() {
                getPrevImg(img).click();
            });

            return prevButton;
        }

        // make button to jump to next image in document
        function makeNextButton(img) {
            const nextButton = document.createElement('button');
            nextButton.id = 'lightbox_next_button';
            nextButton.title = 'Jump to the next image in the document [→]';
            nextButton.classList.add('icon_button', 'lightbox_button');
            nextButton.innerHTML = document.querySelector(
                '.icon_caret_right'
            ).innerHTML;

            // attach click listeners to button
            nextButton.addEventListener('click', function() {
                getNextImg(img).click();
            });

            return nextButton;
        }

        // get previous image in document
        function getPrevImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if < 1
            if (index - 1 >= 0)
                index--;
            else
                index = imgs.length - 1;
            return imgs[index];
        }

        // get next image in document
        function getNextImg(img) {
            const imgs = document.querySelectorAll('.lightbox_document_img');

            // find index of provided img
            let index;
            for (index = 0; index < imgs.length; index++) {
                if (imgs[index] === img)
                    break;
            }


            // wrap index to other side if > total
            if (index + 1 <= imgs.length - 1)
                index++;
            else
                index = 0;
            return imgs[index];
        }

        // close lightbox
        function closeLightbox() {
            focusBody();

            const lightbox = document.getElementById('lightbox_overlay');
            if (lightbox)
                lightbox.remove();
        }

        // make all elements behind lightbox non-focusable
        function blurBody(overlay) {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.tabIndex = -1;
            document.body.classList.add('body_no_scroll');
        }

        // make all elements focusable again
        function focusBody() {
            const all = document.querySelectorAll('*');
            for (const element of all)
                element.removeAttribute('tabIndex');
            document.body.classList.remove('body_no_scroll');
        }

        // load options from url parameters
        function loadOptions() {
            const url = window.location.search;
            const params = new URLSearchParams(url);
            for (const optionName of Object.keys(options)) {
                const paramName = pluginName + '-' + optionName;
                const param = params.get(paramName);
                if (param !== '' && param !== null)
                    options[optionName] = param;
            }
        }
        loadOptions();

        // start script when document is finished loading
        if (options.enabled === 'true')
            window.addEventListener('load', start);
    })();
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
    <!-- modified from: https://fontawesome.com/icons/caret-left -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
        ></path>
    </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
    <!-- modified from: https://fontawesome.com/icons/caret-right -->
    <svg width="16" height="16" viewBox="0 0 192 512">
        <path
            fill="currentColor"
            d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
        ></path>
    </svg>
</template>
<!-- math plugin configuration -->

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        "CommonHTML": { linebreaks: { automatic: true } },
        "HTML-CSS": { linebreaks: { automatic: true } },
        "SVG": { linebreaks: { automatic: true } },
        "fast-preview": { disabled: true }
    });
</script>

<!-- math plugin -->

<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML'>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'MathJax' allows the proper rendering of
    // math/equations written in LaTeX.

    // https://www.mathjax.org/
</script>
<!-- annotations plugin configuration -->

<script>
    window.hypothesisConfig = function() {
        return {
            branding: {
                accentColor: '#2196f3',
                appBackgroundColor: '#f8f8f8',
                ctaBackgroundColor: '#f8f8f8',
                ctaTextColor: '#000000',
                selectionFontFamily: 'Open Sans, Helvetica, sans serif',
                annotationFontFamily: 'Open Sans, Helvetica, sans serif'
            }
        };
    };
</script>

<!-- annotations plugin -->

<script src='https://hypothes.is/embed.js'>
    // /////////////////////////
    // DESCRIPTION
    // /////////////////////////

    // This third-party plugin 'Hypothesis' allows public annotation of the
    // manuscript.

    // https://web.hypothes.is/
</script>
<!-- analytics plugin -->

<!-- copy and paste code from Google Analytics or similar service here -->
</body>
</html>
